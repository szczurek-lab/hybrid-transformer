{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from accelerate import init_empty_weights\n",
    "from transformers import GPT2Tokenizer, GPT2Config, GPT2Model\n",
    "\n",
    "from accelerate import init_empty_weights\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from accelerate import load_checkpoint_and_dispatch\n",
    "\n",
    "from accelerate import infer_auto_device_map, init_empty_weights\n",
    "from transformers import AutoConfig, AutoModelForCausalLM"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T08:31:58.580263887Z",
     "start_time": "2023-12-06T08:31:58.537210740Z"
    }
   },
   "id": "5555b5d6b0819be7"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "checkpoint = 'gpt2'\n",
    "dtype = 'float32'\n",
    "\n",
    "config = GPT2Config.from_pretrained(checkpoint)\n",
    "with init_empty_weights():\n",
    "    model = GPT2Model(config)\n",
    "\n",
    "model.tie_weights()\n",
    "device_map = infer_auto_device_map(model, no_split_module_classes=[\"GPT2Block\"], dtype=dtype)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T08:49:02.547474810Z",
     "start_time": "2023-12-06T08:49:02.319920517Z"
    }
   },
   "id": "435f136445bef02e"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "GPT2Model(\n  (wte): Embedding(50257, 768)\n  (wpe): Embedding(1024, 768)\n  (drop): Dropout(p=0.1, inplace=False)\n  (h): ModuleList(\n    (0-11): 12 x GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2Attention(\n        (c_attn): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT2Model.from_pretrained"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T08:49:03.529053458Z",
     "start_time": "2023-12-06T08:49:03.489291930Z"
    }
   },
   "id": "404f48d504e38d06"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'': 0}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_map"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T08:49:08.442611511Z",
     "start_time": "2023-12-06T08:49:08.403399233Z"
    }
   },
   "id": "e965fc56527d05c9"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aizdebski/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 13\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01maccelerate\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m infer_auto_device_map, init_empty_weights\n\u001B[1;32m     11\u001B[0m image_processor \u001B[38;5;241m=\u001B[39m AutoImageProcessor\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenai/imagegpt-small\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 13\u001B[0m device_map \u001B[38;5;241m=\u001B[39m infer_auto_device_map(\u001B[43mmodel\u001B[49m, no_split_module_classes\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPT2Block\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     14\u001B[0m model \u001B[38;5;241m=\u001B[39m ImageGPTForCausalImageModeling\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenai/imagegpt-small\u001B[39m\u001B[38;5;124m\"\u001B[39m, device_map \u001B[38;5;241m=\u001B[39m device_map)\n\u001B[1;32m     16\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"openai/imagegpt-small\")\n",
    "\n",
    "device_map = infer_auto_device_map(model, no_split_module_classes=[\"GPT2Block\"])\n",
    "model = ImageGPTForCausalImageModeling.from_pretrained(\"openai/imagegpt-small\", device_map = device_map)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-05T14:17:16.584774152Z"
    }
   },
   "id": "589b38aed1962e55"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Accelerator.__init__() got an unexpected keyword argument 'distributed_type'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m accelerator \u001B[38;5;241m=\u001B[39m \u001B[43mAccelerator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdistributed_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m device \u001B[38;5;241m=\u001B[39m accelerator\u001B[38;5;241m.\u001B[39mdevice\n\u001B[1;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[0;31mTypeError\u001B[0m: Accelerator.__init__() got an unexpected keyword argument 'distributed_type'"
     ]
    }
   ],
   "source": [
    "\n",
    "accelerator = Accelerator(distributed_type=True)\n",
    "device = accelerator.device\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T14:06:41.396644742Z",
     "start_time": "2023-12-05T14:06:41.333286688Z"
    }
   },
   "id": "5f6da2258e3c723f"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<DistributedType.NO: 'NO'>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelerator.distributed_type"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T14:06:33.492878570Z",
     "start_time": "2023-12-05T14:06:33.490055145Z"
    }
   },
   "id": "940accf67e379266"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aizdebski/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "An issue was found when launching the training: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/aizdebski/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/torch/multiprocessing/spawn.py\", line 74, in _wrap\n    fn(i, *args)\n  File \"/home/aizdebski/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/accelerate/utils/launch.py\", line 562, in __call__\n    self.launcher(*args)\nTypeError: training_loop() takes 1 positional argument but 3 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mProcessRaisedException\u001B[0m                    Traceback (most recent call last)",
      "File \u001B[0;32m~/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/accelerate/launchers.py:186\u001B[0m, in \u001B[0;36mnotebook_launcher\u001B[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 186\u001B[0m     \u001B[43mstart_processes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlauncher\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnprocs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_processes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfork\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ProcessRaisedException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:202\u001B[0m, in \u001B[0;36mstart_processes\u001B[0;34m(fn, args, nprocs, join, daemon, start_method)\u001B[0m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001B[39;00m\n\u001B[0;32m--> 202\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:163\u001B[0m, in \u001B[0;36mProcessContext.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    162\u001B[0m msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m original_trace\n\u001B[0;32m--> 163\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m ProcessRaisedException(msg, error_index, failed_process\u001B[38;5;241m.\u001B[39mpid)\n",
      "\u001B[0;31mProcessRaisedException\u001B[0m: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/aizdebski/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/torch/multiprocessing/spawn.py\", line 74, in _wrap\n    fn(i, *args)\n  File \"/home/aizdebski/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/accelerate/utils/launch.py\", line 562, in __call__\n    self.launcher(*args)\nTypeError: training_loop() takes 1 positional argument but 3 were given\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01maccelerate\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m notebook_launcher\n\u001B[1;32m      5\u001B[0m args \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfp16\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m42\u001B[39m, \u001B[38;5;241m64\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m \u001B[43mnotebook_launcher\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_loop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_processes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/accelerate/launchers.py:196\u001B[0m, in \u001B[0;36mnotebook_launcher\u001B[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes)\u001B[0m\n\u001B[1;32m    189\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    190\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCUDA has been initialized before the `notebook_launcher` could create a forked subprocess. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    191\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis likely stems from an outside import causing issues once the `notebook_launcher()` is called. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    192\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease review your imports and test them when running the `notebook_launcher()` to identify \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    193\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhich one is problematic and causing CUDA to be initialized.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    194\u001B[0m                 ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    195\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 196\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn issue was found when launching the training: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;66;03m# No need for a distributed launch otherwise as it's either CPU, GPU or MPS.\u001B[39;00m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_mps_available():\n",
      "\u001B[0;31mRuntimeError\u001B[0m: An issue was found when launching the training: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/aizdebski/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/torch/multiprocessing/spawn.py\", line 74, in _wrap\n    fn(i, *args)\n  File \"/home/aizdebski/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/accelerate/utils/launch.py\", line 562, in __call__\n    self.launcher(*args)\nTypeError: training_loop() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from accelerate import notebook_launcher\n",
    "\n",
    "\n",
    "\n",
    "args = (\"fp16\", 42, 64)\n",
    "notebook_launcher(training_loop, args, num_processes=2)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T14:09:10.903150646Z",
     "start_time": "2023-12-05T14:09:09.251372988Z"
    }
   },
   "id": "b98ad2f2b86e07af"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def training_loop(model):\n",
    "    accelerator = Accelerator(num_processes=4)\n",
    "    model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T14:09:07.025234396Z",
     "start_time": "2023-12-05T14:09:07.022757660Z"
    }
   },
   "id": "b8bd9e2df09a8e99"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:13:53.894517423Z",
     "start_time": "2023-12-06T09:13:52.896560871Z"
    }
   },
   "id": "aa65188c188655ad"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:13:55.125647430Z",
     "start_time": "2023-12-06T09:13:55.093656736Z"
    }
   },
   "id": "e0b2f70b198522ae"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:13:59.632019316Z",
     "start_time": "2023-12-06T09:13:59.590688909Z"
    }
   },
   "id": "652fc59ec146fa4e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:13:59.893221423Z",
     "start_time": "2023-12-06T09:13:59.890688756Z"
    }
   },
   "id": "2682b83380782857"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "t = torch.cuda.get_device_properties(1).total_memory\n",
    "r = torch.cuda.memory_reserved(1)\n",
    "a = torch.cuda.memory_allocated(1)\n",
    "f = r-a  # free inside reserved"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:14:09.837886084Z",
     "start_time": "2023-12-06T09:14:09.794919965Z"
    }
   },
   "id": "6f93a627be95a1fc"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:14:11.330580541Z",
     "start_time": "2023-12-06T09:14:11.289915208Z"
    }
   },
   "id": "9995736642bb553e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:14:49.096822540Z",
     "start_time": "2023-12-06T09:14:49.055862092Z"
    }
   },
   "id": "a3e2436208b40f74"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:14:53.978933914Z",
     "start_time": "2023-12-06T09:14:53.938099835Z"
    }
   },
   "id": "7606facf78999843"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:15:02.031604282Z",
     "start_time": "2023-12-06T09:15:01.990975488Z"
    }
   },
   "id": "b444711f4d8a8c9c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:15:39.089629330Z",
     "start_time": "2023-12-06T09:15:39.045232456Z"
    }
   },
   "id": "fc6ef11fb916a0c4"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'NVIDIA GeForce RTX 2080 Ti'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:15:52.332205641Z",
     "start_time": "2023-12-06T09:15:52.293531938Z"
    }
   },
   "id": "e65eb4c527021908"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:16:22.477271183Z",
     "start_time": "2023-12-06T09:16:22.435000088Z"
    }
   },
   "id": "743c7cc1d686210a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(1027211264, 11546394624)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.mem_get_info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:17:26.835056692Z",
     "start_time": "2023-12-06T09:17:26.796182985Z"
    }
   },
   "id": "a4bc7b3158089eca"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pynvml\n",
    "\n",
    "def get_free_memory(gpu_index):\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(int(gpu_index))\n",
    "    mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    print('Memory Usage:')\n",
    "    print(f\"Free: {mem_info.free // 1024 ** 3 } gb\")\n",
    "    return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:50:36.864018686Z",
     "start_time": "2023-12-06T09:50:36.821935890Z"
    }
   },
   "id": "7675b5575573e46b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage:\n",
      "Free: 7 gb\n"
     ]
    }
   ],
   "source": [
    "get_free_memory(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:50:37.991336294Z",
     "start_time": "2023-12-06T09:50:37.949432Z"
    }
   },
   "id": "28cddbec1356c20d"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:24:23.015656394Z",
     "start_time": "2023-12-06T09:24:22.090748937Z"
    }
   },
   "id": "be6fd9651f00c7f5"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aizdebski/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading vocab.json: 100%|██████████████| 1.04M/1.04M [00:00<00:00, 2.38MB/s]\n",
      "Downloading merges.txt: 100%|████████████████| 456k/456k [00:00<00:00, 1.41MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 4.06MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 548M/548M [00:04<00:00, 111MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:22:20.721905078Z",
     "start_time": "2023-12-06T09:22:11.608882507Z"
    }
   },
   "id": "1bb74e91cd735ee4"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[ 0.1629, -0.2166, -0.1410,  ..., -0.2619, -0.0819,  0.0092],\n         [ 0.4628,  0.0248, -0.0785,  ..., -0.0859,  0.5122, -0.3939],\n         [-0.0644,  0.1551, -0.6306,  ...,  0.2488,  0.3691,  0.0833],\n         ...,\n         [-0.5591, -0.4490, -1.4540,  ...,  0.1650, -0.1302, -0.3740],\n         [ 0.1400, -0.3875, -0.7916,  ..., -0.1780,  0.1824,  0.2185],\n         [ 0.1721, -0.2420, -0.1124,  ..., -0.1068,  0.1205, -0.3213]]],\n       grad_fn=<ViewBackward0>), past_key_values=((tensor([[[[-1.0719,  2.4170,  0.9660,  ..., -0.4787, -0.3316,  1.7925],\n          [-2.2897,  2.5424,  0.8317,  ..., -0.5299, -2.4828,  1.3537],\n          [-2.2856,  2.7125,  2.4725,  ..., -1.4911, -1.8427,  1.6493],\n          ...,\n          [-3.3203,  2.3325,  2.7061,  ..., -1.1569, -1.5586,  2.4076],\n          [-2.9917,  2.2701,  2.1742,  ..., -0.8670, -1.6410,  1.9237],\n          [-2.5066,  2.6139,  2.1347,  ..., -0.0627, -2.0542,  1.6568]],\n\n         [[ 0.4796, -0.1131, -1.4854,  ...,  1.1607,  1.8412,  1.3682],\n          [-0.7273, -1.1362, -1.0850,  ..., -0.6736,  3.2618,  0.2099],\n          [-1.4441, -3.0647, -4.1612,  ..., -1.4788,  3.2718, -0.2803],\n          ...,\n          [ 0.8515, -0.1599,  0.1157,  ..., -0.8959,  4.1178,  0.7133],\n          [-0.0769, -1.7673, -1.1207,  ..., -1.6276,  3.1095,  1.0237],\n          [-0.9118, -0.3267, -2.0409,  ..., -0.3527,  1.1626,  0.3733]],\n\n         [[-0.2338, -0.8688,  1.6542,  ..., -1.5964, -1.5636,  1.0931],\n          [ 0.3698,  0.4929,  1.4155,  ..., -2.0162, -1.0246,  1.9822],\n          [ 0.4509,  1.0144,  0.1189,  ..., -3.1880,  0.4529,  1.3746],\n          ...,\n          [ 0.3303,  0.8695, -0.6507,  ..., -2.7196,  0.2950,  1.9827],\n          [ 0.5777,  0.4363,  1.1029,  ..., -3.2317,  0.9627,  2.1703],\n          [-0.2861, -0.2032,  0.7289,  ..., -2.3039,  1.2637,  1.9519]],\n\n         ...,\n\n         [[ 0.4012, -0.0278, -0.1031,  ...,  0.2614,  0.9767,  0.5994],\n          [ 0.2222,  0.3167, -0.2024,  ...,  0.9616,  0.3658,  1.0162],\n          [ 0.3276,  0.0629,  0.1905,  ...,  1.0855,  0.8707,  0.0940],\n          ...,\n          [ 0.2403, -0.0951,  0.1646,  ...,  0.3345,  0.2687,  0.2159],\n          [ 0.2873,  0.0887, -0.0544,  ...,  1.0306,  0.3196,  0.5268],\n          [-0.0552, -0.0461,  0.0765,  ...,  1.0465,  0.2690,  0.4687]],\n\n         [[ 0.9759,  1.3121, -0.6612,  ..., -0.3228,  1.1476, -1.2349],\n          [ 1.0862,  0.3406, -0.6767,  ..., -1.0748,  1.4611,  0.6789],\n          [ 0.6566,  0.1325, -0.5036,  ..., -1.9292,  1.4180,  0.0719],\n          ...,\n          [ 1.1746, -0.0249, -1.0666,  ..., -0.9283,  1.2044, -0.7485],\n          [ 1.2952,  0.0145, -0.4903,  ..., -1.0618,  0.9241,  0.0928],\n          [ 0.9810,  0.0274, -0.2624,  ..., -0.8447,  0.3484, -0.2251]],\n\n         [[ 0.6922,  0.4421,  0.2786,  ..., -0.2213,  0.2488,  1.8778],\n          [-0.1203, -0.2795, -0.0287,  ..., -0.2255,  0.5681,  1.2821],\n          [ 0.3923,  0.6569,  0.0967,  ..., -0.0928,  0.2676,  2.2244],\n          ...,\n          [ 0.4983, -0.2781,  0.9789,  ...,  0.5424,  1.0169,  1.1159],\n          [-0.8550,  0.5215, -0.2168,  ..., -0.1893,  0.9473,  0.7673],\n          [-0.9623,  0.1968,  1.1720,  ..., -0.4878,  0.9685, -0.6823]]]],\n       grad_fn=<PermuteBackward0>), tensor([[[[ 3.5844e-02,  4.5047e-02, -3.2349e-02,  ...,  1.1302e-01,\n            3.4111e-03, -7.3823e-02],\n          [ 2.4216e-02, -2.3168e-01,  7.9895e-02,  ..., -3.9604e-02,\n            1.3466e-01, -8.8950e-02],\n          [ 1.3182e-01,  4.2661e-02,  7.7161e-03,  ...,  1.1645e-01,\n            1.4362e-01, -3.0297e-02],\n          ...,\n          [ 5.1271e-02, -1.0683e-02,  1.3832e-01,  ...,  4.6392e-02,\n           -7.1929e-02,  3.3192e-01],\n          [ 4.0427e-02,  3.1326e-02,  7.5804e-03,  ...,  6.6739e-02,\n           -9.5121e-02,  2.2703e-02],\n          [-2.5431e-01,  9.7892e-02, -3.1401e-01,  ..., -5.9719e-02,\n            8.7119e-02, -1.5292e-01]],\n\n         [[ 4.6511e-01,  2.9299e-01, -2.6004e-01,  ..., -4.8896e-01,\n           -3.9832e-01,  5.1992e-02],\n          [ 3.6216e-01, -2.1008e-01,  2.3111e-01,  ...,  1.2695e-02,\n           -9.8509e-03, -1.9051e-01],\n          [ 5.0594e-01, -2.8700e-01, -3.7256e-02,  ...,  1.3379e-01,\n            1.4818e-01, -7.0381e-02],\n          ...,\n          [ 4.5519e-01,  2.2482e-01,  2.7037e-02,  ..., -7.6202e-02,\n            1.3018e-01,  1.1114e-01],\n          [ 4.3946e-01,  5.6357e-02, -2.8075e-01,  ...,  3.8331e-02,\n            2.8041e-01, -1.0264e-01],\n          [ 5.5593e-01, -7.1407e-02,  8.1584e-03,  ...,  7.4966e-02,\n            5.5887e-01, -1.0753e-01]],\n\n         [[-3.5264e-02,  5.7019e-02, -7.3887e-02,  ..., -1.2185e-02,\n           -8.9059e-02, -1.0759e-01],\n          [-1.4517e-01, -1.1093e-01, -3.1237e-01,  ...,  7.9632e-03,\n            1.0515e-01, -6.8205e-02],\n          [-2.9723e-01, -1.0871e-01, -3.7647e-01,  ..., -4.4998e-01,\n           -3.9353e-01, -5.8729e-02],\n          ...,\n          [ 3.6986e-01,  3.6383e-01,  8.8384e-02,  ..., -2.8474e-01,\n           -2.1211e-01, -4.2789e-01],\n          [ 5.1485e-01,  1.4955e-02,  1.9848e-01,  ...,  1.8763e-03,\n           -4.4840e-02, -1.9523e-01],\n          [-3.1557e-01, -7.7205e-02,  1.2237e-01,  ..., -9.9082e-03,\n           -9.1467e-02, -1.1786e-01]],\n\n         ...,\n\n         [[-1.6929e-01, -1.6863e-01, -1.3075e-01,  ..., -4.5507e-02,\n            1.6489e-02, -4.9244e-03],\n          [-1.8289e-01, -7.3011e-02,  8.9083e-02,  ...,  2.8579e-01,\n            1.6520e-01,  3.9901e-01],\n          [ 1.8149e-02,  1.4864e-01,  1.3995e-01,  ..., -2.0186e-01,\n           -3.1164e-01,  1.8832e-01],\n          ...,\n          [ 1.8829e-01,  3.7086e-01,  2.2190e-02,  ..., -4.3816e-01,\n           -4.5873e-02, -2.3247e-01],\n          [-6.9325e-02,  2.2089e-01, -5.2158e-02,  ..., -5.8061e-05,\n           -4.4377e-02, -2.3630e-02],\n          [-1.4491e-01, -7.6687e-01, -1.0080e-02,  ...,  1.4490e-01,\n           -1.4273e-01,  1.1995e-02]],\n\n         [[ 1.1663e-01, -9.5174e-02, -8.0097e-02,  ...,  1.1799e-01,\n            1.4442e-01,  8.0563e-02],\n          [-4.0979e-01,  1.7985e-01,  6.2052e-02,  ..., -4.6011e-01,\n           -1.5909e-01,  1.6538e-01],\n          [ 1.0707e-01, -1.4439e-01, -3.8615e-02,  ..., -3.1468e-01,\n           -1.1422e-01,  1.1694e-01],\n          ...,\n          [-8.9047e-02, -5.7536e-02, -1.4755e-01,  ..., -4.0699e-01,\n           -1.5711e-01, -2.4647e-01],\n          [-5.0915e-02,  8.4827e-02,  5.0269e-02,  ..., -2.7516e-02,\n           -2.4682e-01, -1.2400e-01],\n          [-4.0786e-02, -6.3005e-02, -5.9178e-02,  ...,  1.9072e-01,\n            2.5695e-01,  1.3483e-01]],\n\n         [[-1.4032e-01, -2.1724e-01,  2.1163e-01,  ...,  1.1325e-02,\n           -1.6940e-01, -5.6700e-02],\n          [ 1.6501e-01,  1.4751e-01,  1.2316e-01,  ...,  5.2810e-01,\n            3.7520e-01,  5.6596e-02],\n          [-1.6167e-01, -9.5173e-02, -3.0007e-01,  ..., -1.3899e-01,\n            7.6265e-02,  1.5000e-01],\n          ...,\n          [ 1.9036e-02, -4.1325e-01, -5.3456e-02,  ...,  1.0850e-01,\n            3.1322e-01,  7.4104e-02],\n          [ 4.7434e-02,  8.3881e-02, -5.8630e-02,  ...,  5.6656e-02,\n           -1.4553e-01,  1.3967e-01],\n          [ 1.1568e-01, -1.1512e-01, -3.7184e-02,  ...,  9.3072e-02,\n            9.4980e-02,  5.2496e-03]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-2.3234e-01,  1.7469e+00, -1.3506e+00,  ...,  1.3035e+00,\n           -1.1436e+00,  1.3027e+00],\n          [ 3.7144e-01,  1.5962e+00, -9.8959e-01,  ..., -3.7702e-01,\n           -1.6238e+00,  4.9728e-01],\n          [ 1.5475e+00,  1.7371e+00, -1.1542e+00,  ...,  2.6363e-02,\n           -2.4185e+00,  6.0650e-02],\n          ...,\n          [ 1.1640e+00,  2.7594e-01, -3.8811e-01,  ...,  9.9817e-01,\n           -2.4461e-01, -2.2513e+00],\n          [ 9.1530e-02,  1.3589e+00,  5.4383e-02,  ...,  9.0259e-01,\n           -2.1145e+00, -1.0515e+00],\n          [-2.3758e-01,  4.2933e-01,  2.5327e-01,  ...,  6.8149e-01,\n           -7.0189e-01, -1.3681e-01]],\n\n         [[-1.4716e+00, -7.0062e-01, -8.4053e-01,  ..., -3.4795e-01,\n            9.0868e-01, -5.7943e-01],\n          [-6.7887e-01, -8.5541e-01, -1.9801e+00,  ..., -1.3131e+00,\n           -2.7207e-01,  1.9432e-01],\n          [-8.6449e-01,  1.6246e-02, -1.5927e+00,  ..., -1.5577e-01,\n            4.3638e-01,  3.4525e-01],\n          ...,\n          [-8.9806e-01,  3.8957e-01, -1.8324e+00,  ..., -3.9667e-01,\n           -9.1773e-01, -5.6276e-01],\n          [-5.7540e-01,  9.9297e-01, -1.6385e+00,  ..., -2.2806e-01,\n            3.7440e-01, -1.2218e+00],\n          [-5.3996e-01,  1.2337e+00, -1.4777e+00,  ..., -1.9484e-01,\n           -7.1104e-01, -6.1031e-01]],\n\n         [[ 3.3298e-01,  1.1988e-01, -2.9469e-02,  ..., -1.2560e+00,\n            1.5321e-01, -2.1866e-01],\n          [ 3.3311e-01,  6.0988e-01, -3.2191e-01,  ..., -1.2439e+00,\n           -7.9251e-02,  7.9440e-02],\n          [-1.3959e-01,  2.9871e-01, -1.1090e-01,  ..., -8.7817e-01,\n           -2.1968e-01,  5.7344e-01],\n          ...,\n          [-1.1917e-01, -1.2049e-01,  8.8956e-02,  ..., -1.0531e+00,\n            2.7097e-01,  2.8109e-01],\n          [-1.6320e-01, -2.1190e-01, -2.8066e-01,  ..., -1.1110e+00,\n           -1.1413e-01,  3.4103e-01],\n          [-1.9088e-01, -2.2637e-01, -1.9520e-01,  ..., -1.3609e+00,\n            7.7478e-03,  5.4753e-02]],\n\n         ...,\n\n         [[ 4.1961e-01, -5.4149e-01, -6.5129e-01,  ..., -1.3049e-01,\n            6.4293e-01, -1.0648e+00],\n          [-1.1139e+00,  1.7472e+00,  1.9236e+00,  ..., -5.2888e-01,\n           -8.8113e-01, -1.1274e+00],\n          [-3.5030e-02,  1.6498e+00,  1.5704e+00,  ...,  1.8705e+00,\n            4.4842e-01,  1.7473e-01],\n          ...,\n          [ 2.8044e-02,  1.5038e+00,  1.7172e+00,  ..., -1.5435e-01,\n           -7.6511e-01, -8.1489e-01],\n          [-6.5316e-01,  1.2453e+00,  1.9217e+00,  ...,  6.9396e-01,\n           -1.3474e+00, -1.1424e+00],\n          [-4.9458e-01,  1.4317e+00,  1.6529e+00,  ...,  5.9429e-01,\n           -1.7269e+00, -3.5413e-01]],\n\n         [[-1.2016e+00, -2.7812e+00,  1.2903e-01,  ...,  1.6795e+00,\n            1.5993e+00, -1.5680e+00],\n          [-2.4824e-01,  9.6243e-01, -6.0818e-01,  ..., -6.4028e-01,\n            7.3015e-01,  1.6932e-03],\n          [ 3.7342e-01,  7.0263e-01, -5.0011e-01,  ..., -6.0884e-01,\n            4.8429e-01, -9.1718e-02],\n          ...,\n          [-2.1023e-01, -1.1352e-01, -8.6533e-01,  ..., -4.3357e-01,\n            1.0432e+00,  2.3951e-01],\n          [-3.5406e-01,  3.6508e-01, -7.0875e-01,  ..., -1.5285e-01,\n            9.8004e-01,  3.0699e-01],\n          [-3.1061e-01,  2.6206e-01, -7.0317e-01,  ..., -3.8614e-01,\n            7.4612e-01, -1.0789e-01]],\n\n         [[ 1.2471e+00,  1.8337e+00,  1.4891e+00,  ..., -2.7984e-01,\n            8.3699e-02, -4.6373e-01],\n          [-7.5649e-03,  2.5955e+00,  5.7040e-01,  ...,  1.0415e+00,\n           -1.6044e-01, -3.6244e-01],\n          [ 7.7530e-02,  2.8104e+00,  1.5624e+00,  ...,  1.5091e+00,\n           -1.8090e-02, -1.2300e+00],\n          ...,\n          [-4.7830e-01,  2.4190e+00,  2.3556e+00,  ...,  1.7733e+00,\n           -1.6757e+00, -2.5219e+00],\n          [ 9.0540e-02,  3.3119e+00, -3.6678e-01,  ...,  2.4435e+00,\n           -1.6148e+00, -2.1822e+00],\n          [ 5.6891e-01,  1.7215e+00,  7.9348e-01,  ..., -6.3630e-01,\n           -4.2486e-01,  1.1764e-02]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 1.8121e-01, -1.3411e-01, -2.1478e-01,  ...,  7.0410e-02,\n            2.1432e-01, -4.1736e-01],\n          [-3.4722e-01, -2.4165e-01, -3.5845e-01,  ..., -4.0395e-03,\n            6.8928e-01,  6.3408e-01],\n          [ 1.8921e-01,  1.1412e-01, -3.7454e-01,  ..., -6.1886e-01,\n            1.5584e-01, -3.3977e-01],\n          ...,\n          [-9.8094e-01, -3.1039e-01, -4.3409e-02,  ...,  8.2431e-01,\n            1.2980e-02,  3.8809e-03],\n          [ 3.3090e-01, -8.1123e-02,  1.0761e-01,  ..., -2.8871e-01,\n            4.1475e-01,  4.9912e-01],\n          [ 6.5354e-01,  1.7933e-01,  9.7152e-02,  ..., -9.8650e-02,\n           -1.9800e-01, -7.1575e-02]],\n\n         [[-1.2948e-01, -1.3113e-01,  3.0471e-01,  ..., -9.5208e-02,\n           -5.2637e-01,  2.0391e-02],\n          [-5.2768e-01, -2.4699e-01, -1.2828e-01,  ..., -1.3858e-01,\n            1.6376e-01,  3.1491e-01],\n          [ 3.4299e-02,  2.9798e-01, -1.8136e-01,  ...,  3.7112e-01,\n           -1.1525e-02, -2.1673e-01],\n          ...,\n          [-8.4662e-03, -1.8613e-01,  2.7562e-01,  ...,  4.4664e-01,\n           -1.5165e-01, -5.9345e-01],\n          [ 2.7736e-01, -5.3698e-01,  1.0314e+00,  ...,  1.0592e-01,\n           -1.0284e-01, -2.0281e-01],\n          [ 3.6434e-01, -1.9135e-02,  1.0105e-01,  ...,  1.8952e-01,\n            2.6101e-01, -4.4438e-02]],\n\n         [[ 4.5340e-02, -4.0817e-01,  5.3539e-02,  ..., -4.7963e-01,\n           -2.8298e-01,  2.7899e-02],\n          [ 8.4529e-01,  9.4444e-02,  2.4181e-02,  ..., -7.5536e-01,\n           -4.6340e-02,  1.8064e-01],\n          [ 8.0320e-01,  1.4924e-01,  5.8457e-01,  ..., -8.3811e-01,\n            1.0063e-01,  2.5599e-01],\n          ...,\n          [ 9.6557e-01, -9.7738e-02,  2.9158e-02,  ..., -3.4948e-01,\n            1.6999e-01, -1.4430e-01],\n          [ 8.1042e-01, -2.8220e-02, -1.2203e-01,  ..., -3.2469e-01,\n           -2.2869e-01,  4.6458e-01],\n          [ 4.8326e-01,  1.9731e-01,  2.5365e-01,  ..., -9.5574e-02,\n           -1.1013e-01, -3.0431e-01]],\n\n         ...,\n\n         [[ 1.4653e-01,  6.2398e-01, -1.6506e-01,  ...,  1.2628e-01,\n           -9.4077e-01, -1.0024e-01],\n          [ 8.5481e-02, -3.7416e-01,  6.1154e-02,  ...,  2.1396e-01,\n           -6.8562e-01, -1.3296e-01],\n          [-2.7189e-01,  7.6011e-02,  5.0749e-01,  ...,  6.4782e-02,\n           -6.3529e-01, -3.4742e-01],\n          ...,\n          [-1.5075e-01,  1.6193e-01,  4.4225e-01,  ...,  5.5478e-01,\n            9.6686e-02,  1.3932e-02],\n          [ 2.9650e-02, -3.2289e-01, -3.7855e-01,  ...,  2.1001e-01,\n           -5.2798e-01,  7.2306e-01],\n          [ 5.7424e-02, -8.9264e-01,  3.6512e-01,  ...,  2.4724e-01,\n           -7.7394e-01, -2.8834e-01]],\n\n         [[ 1.9841e-01, -1.6214e-01,  8.8751e-02,  ...,  3.8060e-01,\n           -3.5175e+00, -4.8737e-02],\n          [ 4.8521e-02, -4.2689e-01,  2.9561e-03,  ...,  4.1736e-01,\n            3.3645e-02, -1.3576e-01],\n          [-2.3386e-01,  4.3438e-02,  1.9538e-01,  ...,  2.6902e-02,\n            7.1384e-02,  8.4704e-02],\n          ...,\n          [-1.4844e-03,  1.7191e-01, -5.1814e-01,  ...,  2.2445e-01,\n           -1.5839e-01,  1.5118e-01],\n          [ 1.7462e-02, -2.2360e-03,  4.6600e-01,  ...,  6.4922e-02,\n            3.4853e-02,  1.8072e-01],\n          [ 4.1400e-01,  1.7019e-01,  2.7337e-02,  ...,  1.4136e-01,\n           -1.5423e-01,  7.8442e-02]],\n\n         [[-5.0851e-02, -5.9927e-02, -5.6215e-02,  ..., -2.0252e-01,\n            1.2368e-01, -3.3855e-02],\n          [-1.1510e-02, -7.6934e-02,  2.3691e-01,  ...,  6.5874e-02,\n            1.5217e-02,  1.8671e-01],\n          [ 1.5296e-01, -1.3156e-01,  1.3923e-01,  ...,  1.8831e-01,\n           -8.2086e-02,  1.2744e-01],\n          ...,\n          [ 3.9660e-02,  2.4684e-01,  1.9528e-01,  ..., -9.5808e-02,\n            1.7549e-01, -6.6851e-03],\n          [ 8.3237e-02,  1.1592e-01, -5.2513e-02,  ..., -3.2531e-02,\n            2.5978e-01,  1.4565e-01],\n          [ 1.2383e-01, -1.1883e-02,  5.0095e-01,  ..., -1.0735e-02,\n            1.1066e-01,  1.8190e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.1322, -1.1527,  0.3087,  ..., -0.6205, -0.1060, -0.0181],\n          [ 0.5456, -2.5518, -0.2942,  ..., -1.2907,  0.0803,  0.1253],\n          [ 0.9459, -2.5900,  0.3366,  ...,  0.2387,  0.0244, -0.0984],\n          ...,\n          [-1.4713, -1.8862, -0.5822,  ..., -0.4205, -0.2317, -0.3811],\n          [-0.4795, -1.7547,  0.5800,  ...,  1.0587,  0.7753, -1.0023],\n          [-0.2153, -2.2462, -0.5551,  ...,  1.7418,  0.0601, -0.8750]],\n\n         [[-0.4981,  0.4839, -0.4288,  ...,  1.2952, -0.4981, -0.4568],\n          [-1.4536, -0.2465, -0.9163,  ...,  0.4530,  0.6458,  0.4874],\n          [-1.6652, -0.9680, -1.0875,  ..., -0.0277,  1.3271, -0.3510],\n          ...,\n          [-2.1762, -0.6636, -1.8135,  ..., -0.9017,  1.3285,  0.1540],\n          [-1.3590, -1.9787, -1.5488,  ..., -1.1410,  1.3344, -0.2104],\n          [-1.4276, -0.6944, -0.5667,  ...,  1.1990,  0.8454, -0.3241]],\n\n         [[ 1.3747,  3.0648,  3.7658,  ...,  0.6805,  1.6251, -0.7113],\n          [-3.6194,  2.6739, -2.5109,  ..., -3.2047,  2.9450, -0.3144],\n          [-3.1928,  1.5469, -3.1628,  ..., -2.9214,  3.4801,  1.2360],\n          ...,\n          [-4.6832, -1.4904, -4.8171,  ..., -3.4247,  1.8220,  0.7462],\n          [-4.9916, -1.4019, -5.5591,  ..., -3.7371,  2.9422,  0.6384],\n          [-3.3272, -1.9141, -4.6821,  ..., -3.4394,  3.4462,  0.7966]],\n\n         ...,\n\n         [[ 1.3571, -2.6940, -2.5864,  ...,  0.9747,  0.4724,  2.7245],\n          [-3.2790,  1.4895,  0.4607,  ...,  0.6635, -1.8444, -0.3443],\n          [-3.4600,  2.6956,  1.3558,  ..., -0.1266, -2.7145,  0.0972],\n          ...,\n          [-3.1993,  4.0702,  1.9383,  ..., -0.9552, -3.1067, -1.4688],\n          [-3.8521,  4.6710,  2.9112,  ..., -2.2364, -3.9045, -1.5241],\n          [-3.5332,  4.3554,  2.3162,  ..., -0.6138, -2.1636, -1.3958]],\n\n         [[ 1.7131,  0.4496,  0.9466,  ...,  0.0104, -0.9866, -0.3256],\n          [ 2.1683,  0.8876,  1.4803,  ...,  0.1768, -1.8011, -1.9908],\n          [ 2.0806,  1.0288,  1.1972,  ..., -0.0733, -1.5057, -1.4346],\n          ...,\n          [ 1.9361,  0.8342,  1.0479,  ..., -0.0835, -1.9249, -1.2110],\n          [ 2.2447,  0.3010,  1.0368,  ..., -0.2990, -1.8205, -1.2766],\n          [ 1.7111,  0.2756,  0.7408,  ...,  0.0539, -1.9953, -0.9998]],\n\n         [[-0.2538,  0.1160, -0.5586,  ...,  0.2681,  0.2844,  0.1296],\n          [-0.2222,  0.8479, -0.4422,  ..., -0.2732,  0.8777,  0.8108],\n          [-0.6727,  0.5071,  0.0572,  ...,  0.0786,  0.3229,  0.3834],\n          ...,\n          [ 0.2167, -0.1937, -1.1421,  ..., -0.4700,  0.8094, -0.1040],\n          [-0.4399,  0.3740,  0.0801,  ..., -0.2625,  0.2348, -0.2820],\n          [-0.7647, -0.3623, -0.5461,  ...,  0.6692,  0.6866,  0.8584]]]],\n       grad_fn=<PermuteBackward0>), tensor([[[[-2.6110e-02, -6.3370e-03, -1.2897e-01,  ..., -2.7515e-02,\n            3.0886e-02, -5.4642e-01],\n          [ 2.8421e-01, -8.6539e-01, -2.9025e-01,  ...,  2.3311e-01,\n           -8.4891e-01,  1.3338e+00],\n          [ 2.4186e-01, -2.5358e-01, -8.4709e-01,  ..., -4.7114e-01,\n           -4.3807e-01,  8.2508e-01],\n          ...,\n          [ 5.8147e-01, -8.3756e-01,  1.4187e-02,  ...,  6.5366e-01,\n            3.2311e-01,  1.0884e+00],\n          [ 2.4317e-02, -4.3096e-01, -1.3149e-01,  ..., -2.2943e-01,\n            4.7279e-01,  6.5807e-01],\n          [ 1.6472e-01,  1.1389e+00, -1.3656e+00,  ...,  3.6690e-01,\n            5.6864e-01, -9.9857e-01]],\n\n         [[ 3.3488e-02, -2.1709e-02,  3.1775e-02,  ..., -3.6363e-02,\n           -2.0804e-02,  7.0153e-02],\n          [-2.9799e-02,  6.2118e-01, -3.6438e-01,  ...,  4.9335e-02,\n           -1.8000e-01,  3.8404e-01],\n          [-4.7976e-01,  1.9055e-02, -1.4230e+00,  ..., -4.2935e-01,\n            4.5856e-01,  1.0601e-01],\n          ...,\n          [-1.1260e+00, -6.7430e-02, -1.2505e+00,  ...,  9.8989e-01,\n            2.0997e-01,  6.6872e-01],\n          [-3.0780e-01, -2.7036e-02,  7.3606e-01,  ..., -1.8043e-01,\n           -6.6421e-02, -4.7701e-01],\n          [-5.7835e-02, -1.4135e-02,  2.8287e-01,  ..., -1.8417e-01,\n           -1.4726e-01,  1.0323e-01]],\n\n         [[ 6.9997e-03, -7.2047e-01, -1.4875e-02,  ...,  5.4531e-02,\n            3.6829e-02, -1.3042e-02],\n          [ 7.3096e-01, -1.3004e+00,  2.5491e-02,  ..., -2.0688e-01,\n            2.1388e-01, -1.9886e-01],\n          [-5.9057e-01, -1.3042e+00,  1.9017e-01,  ..., -1.8207e-01,\n           -3.5322e-03,  3.4668e-01],\n          ...,\n          [ 4.1662e-01, -4.3040e-01,  4.1711e-01,  ..., -7.3938e-01,\n           -1.8402e-01, -3.6389e-01],\n          [-1.5217e-02, -1.5639e+00, -5.2417e-01,  ..., -2.4254e-01,\n           -2.1576e-01,  3.0141e-01],\n          [ 1.0562e-01, -1.4539e+00, -1.0584e-01,  ..., -1.0705e-01,\n            3.9389e-02, -1.4812e-01]],\n\n         ...,\n\n         [[ 2.0108e-02, -5.6756e-02,  1.3052e+00,  ...,  1.0925e-03,\n            1.9278e-01, -2.0602e-03],\n          [-2.6232e-02,  3.2866e-01,  1.9221e+00,  ...,  1.4766e-01,\n           -6.7260e-02,  2.4187e-01],\n          [-4.8278e-01, -4.2951e-01,  1.8054e+00,  ...,  3.6253e-01,\n           -3.1257e-01,  3.7770e-01],\n          ...,\n          [-1.0864e+00, -7.8481e-01,  2.2155e+00,  ..., -2.1905e-01,\n            1.4895e-01,  3.9424e-02],\n          [ 1.1841e-01, -5.9558e-01,  1.9721e+00,  ...,  4.6364e-01,\n           -2.0958e-01,  1.8704e-01],\n          [ 8.8032e-02, -3.0378e-01,  2.5235e+00,  ..., -1.3628e-01,\n            2.6798e-01,  3.4488e-01]],\n\n         [[-1.5290e-02, -6.3416e-02, -1.4310e-01,  ...,  1.6105e-01,\n            1.1368e-01,  1.8954e-01],\n          [-9.1473e-01,  2.2297e-01,  1.4207e-01,  ...,  3.7581e-02,\n           -3.2340e-01, -1.5199e-01],\n          [ 3.7227e-01, -4.9001e-01,  1.7333e-01,  ..., -1.4885e-01,\n           -6.3321e-01, -2.0094e-01],\n          ...,\n          [-4.8509e-01,  2.7552e-01,  4.1076e-01,  ...,  7.9583e-02,\n           -1.2452e-02, -6.0336e-01],\n          [ 1.9530e-01,  2.1733e-01,  3.4654e-01,  ...,  3.8038e-01,\n           -1.0907e+00, -8.6067e-02],\n          [ 6.8279e-01,  6.9183e-01,  2.1597e-01,  ...,  2.1290e-01,\n           -1.1599e-01,  4.2206e-01]],\n\n         [[ 2.3022e-02,  2.4736e-02,  1.4599e-02,  ..., -1.3392e-02,\n            2.2758e-01, -6.3206e-03],\n          [ 4.9218e-02,  5.3240e-01,  9.0467e-01,  ...,  1.1255e-01,\n           -2.0287e+00,  9.8514e-01],\n          [-4.7997e-01, -7.5514e-02, -1.9737e-01,  ..., -6.4949e-02,\n           -1.9641e+00,  1.0550e-01],\n          ...,\n          [ 5.7662e-01,  1.3777e-01,  3.1310e-02,  ...,  1.8253e-01,\n           -2.1296e+00, -1.7676e-01],\n          [ 2.4730e-01,  8.7523e-02, -3.3989e-01,  ...,  8.7950e-02,\n           -2.2735e+00, -1.8762e-01],\n          [ 3.9984e-01, -2.0190e-01,  1.6419e-02,  ..., -2.5319e-01,\n           -1.3256e+00, -2.3872e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 5.1605e-03, -1.8791e-01,  1.4746e-01,  ..., -8.8068e-01,\n            7.5894e-01, -1.1973e+00],\n          [-2.5677e+00,  1.7679e+00, -3.9106e+00,  ...,  1.2833e+00,\n           -1.2259e+00,  2.1156e+00],\n          [-1.6822e+00, -3.9114e-01, -1.4672e+00,  ..., -1.2825e-01,\n            5.9892e-01,  4.3526e-01],\n          ...,\n          [-1.5596e+00, -3.2881e-02,  6.3978e-01,  ...,  1.7795e+00,\n           -1.6521e+00,  2.0406e+00],\n          [-6.5270e-01, -5.5162e-01,  1.0236e+00,  ..., -5.6010e-01,\n           -1.9103e+00,  1.2966e+00],\n          [-1.0920e-01, -8.7920e-01,  1.5121e-02,  ...,  6.2073e-01,\n           -2.7510e-01,  2.1425e-01]],\n\n         [[ 8.0498e-01,  2.0352e-01,  1.7896e-02,  ..., -1.6228e-01,\n           -1.0867e+00, -2.0632e-01],\n          [ 6.3068e-01, -1.4465e+00,  5.0411e-01,  ...,  3.4637e-01,\n            5.0468e+00,  2.1150e+00],\n          [-1.1162e+00, -1.3258e+00,  6.3189e-01,  ...,  1.2063e+00,\n            4.4761e+00,  1.0679e+00],\n          ...,\n          [ 2.2878e-01, -2.3659e+00,  7.8082e-01,  ...,  1.5353e+00,\n            4.7206e+00,  1.8281e+00],\n          [-4.8325e-01, -2.4448e+00,  2.4398e-01,  ..., -2.1931e-01,\n            4.3510e+00,  2.2534e+00],\n          [-1.7464e+00, -2.7802e-02, -1.4060e+00,  ..., -8.7865e-02,\n            4.2460e+00,  1.9398e+00]],\n\n         [[ 3.3238e-01, -3.5263e-01, -3.3511e-01,  ...,  3.3173e-01,\n            1.4302e+00,  2.7422e-01],\n          [-3.7069e-01, -6.1829e+00, -2.2466e+00,  ..., -3.6439e+00,\n           -2.1060e+00, -7.4567e+00],\n          [-4.5128e-01, -5.9982e+00, -2.4673e+00,  ..., -4.1265e+00,\n           -3.8545e+00, -6.1227e+00],\n          ...,\n          [-2.1317e+00, -6.2376e+00, -4.9529e+00,  ..., -3.5573e+00,\n           -2.2995e+00, -4.4041e+00],\n          [-2.2614e+00, -7.2026e+00, -3.0680e+00,  ..., -2.5467e+00,\n           -3.5838e+00, -3.2058e+00],\n          [-3.0414e+00, -6.8481e+00, -1.5457e+00,  ..., -3.4928e+00,\n           -2.2893e+00, -5.9958e+00]],\n\n         ...,\n\n         [[ 2.3405e-01,  1.8003e+00,  5.3820e-01,  ...,  2.6242e-01,\n            4.4860e-01, -1.6709e+00],\n          [ 1.3520e+00, -5.1191e+00,  2.9198e+00,  ..., -8.6180e-01,\n           -1.6337e+00,  5.9583e+00],\n          [-8.9200e-02, -6.2376e+00,  4.5249e-01,  ..., -1.8860e+00,\n           -2.1434e+00,  7.1481e+00],\n          ...,\n          [ 3.8247e-01, -7.7788e+00,  2.1529e+00,  ..., -2.9409e+00,\n           -1.4936e+00,  6.4806e+00],\n          [ 5.7257e-01, -6.5320e+00,  3.4520e-01,  ..., -4.8911e+00,\n           -1.1042e+00,  6.2615e+00],\n          [ 2.3119e-02, -7.1271e+00,  1.8783e+00,  ..., -2.4430e+00,\n           -1.0648e+00,  5.3935e+00]],\n\n         [[ 7.0162e-02, -5.0270e-02,  1.6436e-01,  ..., -8.4555e-02,\n           -8.5299e-02, -1.4128e-01],\n          [ 4.7663e-01, -5.4246e-01,  6.5545e-01,  ...,  4.4172e-01,\n           -1.1501e+00, -1.4259e+00],\n          [ 1.6341e+00, -1.9560e+00, -1.2453e+00,  ..., -1.1005e+00,\n           -1.0474e-01, -3.4483e-01],\n          ...,\n          [-1.4072e-01, -1.0868e+00, -9.5866e-02,  ...,  9.9929e-01,\n            1.2154e+00,  1.0204e+00],\n          [-5.3142e-01, -5.1684e-01, -7.8924e-01,  ..., -4.3379e-01,\n           -5.0606e-01, -1.4453e-01],\n          [-1.6270e-01, -6.7943e-01,  3.7796e-02,  ..., -8.0383e-02,\n           -2.0414e-01,  3.0041e-01]],\n\n         [[ 4.0545e-01, -3.8652e-02,  1.8953e+00,  ..., -2.2527e-01,\n           -1.9901e-01, -9.9291e-01],\n          [ 3.7929e+00,  9.7979e-01, -1.5706e+00,  ...,  8.7371e-01,\n            1.3123e+00,  4.0946e+00],\n          [ 2.6437e+00,  2.8533e+00, -1.1851e+00,  ...,  1.4979e+00,\n            1.7340e+00,  2.7878e+00],\n          ...,\n          [ 3.7213e+00,  4.2312e-01, -4.0639e+00,  ...,  3.0060e+00,\n            1.1026e+00,  4.5419e+00],\n          [ 4.2811e+00,  3.5972e-01, -3.0493e+00,  ...,  3.7985e+00,\n            1.4962e+00,  5.2126e+00],\n          [ 2.6493e+00,  1.5411e+00, -3.0109e+00,  ..., -5.3203e-01,\n            6.5990e-01,  4.2414e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 3.9765e-02,  6.3191e-02,  6.3380e-04,  ...,  1.9104e-02,\n            9.9082e-02,  3.4521e-02],\n          [ 1.1378e+00, -1.2861e+00, -1.2908e-01,  ..., -3.3004e-01,\n           -1.3635e+00, -2.2904e+00],\n          [-8.1626e-02,  9.3745e-02, -2.8481e-01,  ...,  2.1468e-01,\n           -9.6816e-01,  2.9894e-01],\n          ...,\n          [ 2.1699e-01, -1.8662e-01,  3.1800e-01,  ...,  7.8087e-02,\n           -1.3018e+00,  2.1320e-01],\n          [ 7.9638e-01,  2.0152e-01,  1.0130e-01,  ...,  2.5974e-01,\n           -7.7726e-01, -7.3525e-01],\n          [-2.1013e-01, -6.6706e-01,  1.7082e-01,  ...,  4.4624e-02,\n           -2.1095e-01,  1.0726e+00]],\n\n         [[-4.9772e-02,  4.5371e-03,  8.2704e-02,  ..., -5.1366e-02,\n           -3.5350e-02, -4.1695e-02],\n          [ 9.3125e-01,  4.8477e-01,  1.2722e-02,  ...,  2.5011e-01,\n            5.0911e-01,  7.7029e-02],\n          [ 5.3607e-01,  3.6337e-01,  5.9256e-01,  ...,  1.3317e-01,\n            2.4218e-01,  5.0219e-01],\n          ...,\n          [ 9.9435e-01,  8.4733e-01, -1.4116e-02,  ..., -2.2738e-01,\n           -3.3423e-01,  7.2092e-01],\n          [ 7.0013e-01,  4.3564e-02,  9.8744e-02,  ..., -4.9008e-01,\n           -1.1142e-01,  2.7808e-01],\n          [-2.6422e-01,  3.3483e-02,  4.0394e-02,  ...,  2.1468e-01,\n            2.0354e-01, -5.8808e-02]],\n\n         [[ 2.8733e-02, -1.1324e-01, -6.5474e-02,  ..., -2.8632e-02,\n            7.8444e-02, -1.6102e-01],\n          [-4.5820e-01,  4.7828e-01,  7.0546e-02,  ...,  5.3585e-01,\n           -4.5617e-01, -2.3535e-01],\n          [-3.3742e-01, -4.2131e-02,  5.9882e-01,  ...,  2.5610e-01,\n            7.7897e-02, -4.0960e-01],\n          ...,\n          [ 7.5842e-01, -5.6218e-02, -7.4135e-01,  ...,  5.3670e-02,\n           -4.3988e-01,  1.1196e+00],\n          [-8.5638e-01,  1.0162e+00, -1.6276e+00,  ..., -5.2393e-01,\n           -5.1775e-01,  2.8000e-01],\n          [ 3.0931e-01,  9.2681e-02, -5.2069e-01,  ..., -2.1601e-01,\n           -2.4954e-01, -6.8193e-02]],\n\n         ...,\n\n         [[-2.0445e-02,  1.2575e-01, -8.2247e-03,  ..., -3.0457e-02,\n            6.6124e-02, -3.3832e-02],\n          [-7.7384e-01,  4.6625e-01, -8.6402e-01,  ...,  1.1561e+00,\n            1.9820e-01, -3.0625e-01],\n          [-2.7758e-04,  6.3935e-01, -1.8950e-01,  ...,  2.0117e-01,\n           -1.7873e-02,  5.5499e-01],\n          ...,\n          [ 7.8662e-01, -5.6376e-02,  4.7865e-01,  ..., -4.2434e-01,\n           -1.5718e-01, -4.8276e-01],\n          [ 6.4126e-01, -9.5627e-02, -9.7524e-03,  ...,  1.4783e-02,\n            3.4626e-01,  1.4248e-01],\n          [ 1.3236e-01,  2.3395e-01,  8.1250e-02,  ...,  4.1129e-01,\n            2.2832e-01,  5.4297e-02]],\n\n         [[-1.7626e-01, -1.0919e-01, -8.4360e-02,  ..., -2.3040e-01,\n           -1.7456e-02, -4.5445e-02],\n          [-7.3267e-01,  3.0908e-01, -6.8270e-01,  ...,  1.1911e+00,\n            6.0792e-01, -5.9669e-01],\n          [ 3.2711e-01, -8.1703e-01, -6.7690e-01,  ..., -1.4106e-01,\n            5.1631e-01,  1.7033e+00],\n          ...,\n          [ 6.9877e-01,  2.1668e-01,  2.2550e+00,  ...,  7.3070e-01,\n            1.5383e-01, -1.6586e-01],\n          [-1.2518e-01,  2.8484e-03,  1.7571e-01,  ...,  1.3301e-01,\n            1.5198e-01, -2.0102e-02],\n          [ 3.2786e-01,  4.0679e-01,  6.3502e-01,  ..., -9.9532e-01,\n            2.8010e-01,  1.7276e-01]],\n\n         [[ 1.2476e-01, -6.5556e-02, -2.6808e-02,  ..., -8.9693e-03,\n           -9.2486e-02, -8.6446e-02],\n          [-3.6288e-01, -4.0901e-01,  4.7382e-02,  ...,  7.5869e-01,\n            2.6507e-01, -2.3738e-01],\n          [-3.1819e-01,  4.7386e-01,  2.4661e-01,  ...,  1.0666e-02,\n            2.0598e-01, -6.8917e-01],\n          ...,\n          [-5.9656e-02,  5.2958e-01, -5.8517e-01,  ...,  2.4241e-01,\n            7.2702e-02,  4.3875e-01],\n          [-2.8286e-01, -2.9105e-01, -5.9394e-01,  ..., -1.3986e-01,\n            3.1039e-01, -5.7179e-01],\n          [ 4.7208e-01, -1.1132e-01,  2.8570e-02,  ..., -8.4544e-02,\n           -4.1679e-01,  1.1348e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-8.9410e-01, -1.4102e-01,  3.3448e-01,  ..., -9.8900e-01,\n            2.4201e-02, -2.9690e+00],\n          [ 2.0739e+00, -6.6276e-01, -9.6401e-01,  ..., -2.2700e+00,\n           -2.5282e+00,  5.5307e+00],\n          [ 1.4538e+00,  9.1335e-01, -1.2821e+00,  ..., -1.7829e+00,\n           -2.5922e+00,  7.0503e+00],\n          ...,\n          [-7.4861e-02, -1.2873e+00, -4.2342e+00,  ..., -1.1139e+00,\n           -4.1929e-01,  7.9390e+00],\n          [ 6.1465e-01,  1.4598e+00, -3.6137e+00,  ...,  1.9781e-01,\n           -5.2970e-01,  7.9857e+00],\n          [ 4.4373e-01, -2.1877e-01, -2.2024e+00,  ..., -2.1846e+00,\n           -1.8394e+00,  8.6314e+00]],\n\n         [[ 3.3228e-01, -5.2100e-02,  4.4828e-01,  ..., -1.3505e-01,\n           -6.7878e-02, -2.2125e+00],\n          [-1.9308e+00,  1.9479e-01,  3.7004e+00,  ..., -7.5413e-01,\n           -1.4453e+00,  5.9218e+00],\n          [-2.3695e+00,  6.8371e-01,  3.6881e+00,  ...,  4.3966e-01,\n           -1.1369e+00,  6.4070e+00],\n          ...,\n          [-1.4517e+00,  3.6522e-01,  2.4737e+00,  ..., -7.0429e-01,\n           -9.3994e-01,  6.8221e+00],\n          [-2.4442e+00,  5.6833e-01,  2.1406e+00,  ..., -1.6726e-02,\n           -2.8341e+00,  6.6074e+00],\n          [-1.7411e+00,  1.0740e-01,  2.9581e+00,  ..., -5.2872e-01,\n           -4.2821e-01,  6.4365e+00]],\n\n         [[ 1.3868e-01, -6.5963e-01, -2.3258e-01,  ...,  1.4861e-01,\n            2.7447e-01, -1.6060e-01],\n          [ 8.7125e-02,  1.5625e+00,  8.7948e-01,  ..., -5.6049e-02,\n            6.4114e-01, -2.2401e-02],\n          [-1.3730e+00,  1.8783e+00,  1.0146e+00,  ..., -7.2353e-01,\n           -1.0071e+00, -1.1916e-01],\n          ...,\n          [-1.4432e+00,  2.3373e+00, -7.6812e-02,  ...,  1.3016e-01,\n           -3.4882e-01,  1.0060e+00],\n          [ 3.4654e-01,  2.0433e+00,  1.0946e+00,  ..., -1.9423e-01,\n            5.6170e-01,  8.5613e-01],\n          [ 3.7557e-01,  2.7165e+00,  1.5422e+00,  ..., -6.2141e-01,\n            2.8909e-01, -1.2470e+00]],\n\n         ...,\n\n         [[-3.8548e-01,  3.3657e-02, -8.6132e-04,  ...,  1.2389e+00,\n            4.4031e-02,  1.7787e+00],\n          [-3.3900e-01, -1.1665e+00, -1.6126e+00,  ..., -2.2094e+00,\n           -1.2285e+00, -8.3998e-01],\n          [ 1.1457e+00, -1.9595e+00, -2.7776e+00,  ..., -2.5459e+00,\n           -2.1862e+00, -6.8518e-01],\n          ...,\n          [ 2.7297e+00, -5.4906e-01,  6.4908e-01,  ..., -2.9931e+00,\n           -1.2364e+00, -2.9284e+00],\n          [ 9.0714e-01, -2.5425e-01,  1.0949e+00,  ..., -4.2778e+00,\n           -7.9689e-01, -2.4453e+00],\n          [ 5.2888e-01, -4.7623e-01, -1.0388e+00,  ..., -4.2955e+00,\n           -1.3179e+00, -6.7411e-01]],\n\n         [[-3.5278e-01, -1.6115e-01,  2.2002e-01,  ...,  2.5153e-01,\n           -2.5440e-02,  2.5464e-02],\n          [-5.8535e-01, -1.6797e+00, -9.7091e-02,  ...,  1.3156e+00,\n           -4.3526e-01, -3.6301e-01],\n          [-1.4276e+00, -4.4909e-01,  4.2122e-01,  ...,  8.0923e-01,\n            2.0564e+00,  5.5882e-01],\n          ...,\n          [ 2.3271e+00,  3.7035e-01, -1.2498e-01,  ...,  1.6023e+00,\n            7.8902e-01,  8.7364e-01],\n          [ 1.0688e+00,  6.8914e-01,  1.0407e+00,  ...,  1.1552e+00,\n           -4.6404e-01,  5.0676e-01],\n          [-5.4183e-01,  2.2367e-01,  1.1283e+00,  ...,  4.9600e-01,\n            4.4042e-01,  1.2166e+00]],\n\n         [[ 3.4287e+00,  2.1075e+00, -2.1753e+00,  ..., -2.8384e+00,\n           -3.9170e+00, -1.1987e+00],\n          [-2.3681e+00,  6.4387e-01,  2.7032e+00,  ...,  9.6174e-01,\n            5.6489e+00, -3.8173e+00],\n          [-1.7256e+00, -6.4346e-01,  3.3742e+00,  ...,  1.0354e-01,\n            1.0917e+01, -2.0007e+00],\n          ...,\n          [-2.4372e+00, -3.5694e+00,  5.2531e+00,  ..., -2.7536e+00,\n            1.4675e+01,  2.3681e+00],\n          [-5.4329e+00, -3.3473e+00,  6.1980e+00,  ..., -1.9572e+00,\n            1.3900e+01,  2.5586e+00],\n          [-5.6755e+00, -3.2005e+00,  9.5993e+00,  ..., -1.9897e-01,\n            1.4622e+01, -1.6569e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[-9.6099e-04, -5.7273e-02,  1.4961e-02,  ...,  5.1007e-02,\n            2.4101e-02,  6.1853e-02],\n          [ 8.1719e-01,  3.1390e-01,  4.9729e-01,  ..., -4.4034e-01,\n           -5.6994e-01,  1.1864e+00],\n          [ 9.6673e-03, -1.2195e-01,  9.2736e-02,  ..., -8.4646e-01,\n            1.8833e-01, -2.2715e-02],\n          ...,\n          [-8.3899e-02, -1.7438e-01,  8.2991e-01,  ...,  4.0479e-01,\n           -5.2889e-01, -1.2070e+00],\n          [ 3.9354e-01,  4.8804e-02,  1.7574e-01,  ...,  1.7612e-01,\n            3.2382e-01, -6.9690e-01],\n          [-4.1270e-01,  1.0351e-01,  1.8573e-02,  ...,  6.5982e-02,\n           -2.0056e-01, -4.9835e-02]],\n\n         [[-5.8026e-02, -2.3602e-02, -1.3654e-01,  ..., -3.6943e-02,\n            4.6139e-02, -3.2082e-04],\n          [ 5.3729e-01,  2.3710e-01,  3.6851e-01,  ...,  3.0927e-01,\n           -7.5684e-01,  6.9841e-01],\n          [ 8.7620e-02, -3.0468e-01, -4.1744e-01,  ...,  4.6823e-01,\n           -5.7566e-01,  6.2960e-01],\n          ...,\n          [ 4.8862e-01,  6.7331e-01, -1.3201e-01,  ..., -4.5718e-01,\n            4.0848e-01,  3.6935e-01],\n          [ 1.3514e-01,  3.2320e-02, -1.7488e-01,  ...,  2.5361e-01,\n            6.0363e-01,  3.6989e-01],\n          [-3.1217e-01,  6.9660e-02, -1.0854e-01,  ..., -3.3014e-01,\n           -1.8350e-01,  1.7417e-01]],\n\n         [[ 5.9868e-02,  9.4087e-02,  8.9803e-02,  ...,  1.8044e-02,\n           -8.2018e-02, -7.6688e-03],\n          [ 4.6114e-03, -1.3464e-01,  5.5771e-01,  ..., -1.0991e+00,\n           -1.0160e-01, -4.8283e-01],\n          [-5.1055e-01, -3.0271e-01, -7.6251e-01,  ..., -5.6934e-02,\n           -4.8848e-01,  6.0688e-02],\n          ...,\n          [-5.6406e-01, -3.3250e-01,  5.2524e-01,  ...,  3.8864e-01,\n            6.4106e-01,  2.6505e-02],\n          [-2.4166e-01,  6.7879e-01, -5.6899e-01,  ...,  5.1276e-01,\n            8.9496e-01, -3.2001e-01],\n          [ 1.9636e-01, -1.2071e-01, -1.2509e-01,  ..., -2.6019e-01,\n           -2.9594e-01,  3.1048e-02]],\n\n         ...,\n\n         [[-5.9281e-03,  8.4552e-02, -7.0813e-02,  ...,  4.7959e-02,\n            4.0231e-02, -1.3932e-01],\n          [-6.4524e-02, -1.8763e-01, -5.0959e-01,  ...,  1.2312e-01,\n            9.9802e-01, -5.4559e-01],\n          [ 2.7483e-01,  5.9988e-01, -8.3259e-01,  ...,  2.9060e-01,\n           -1.6327e-01,  5.9452e-01],\n          ...,\n          [ 1.1946e+00,  3.1072e-01, -2.8943e-01,  ...,  4.8221e-01,\n            1.0371e+00, -1.0225e+00],\n          [ 5.3250e-01, -1.2834e+00, -4.2687e-01,  ...,  1.3547e+00,\n           -1.9294e-01,  4.6109e-01],\n          [-2.1219e-01,  5.5494e-01, -4.9708e-01,  ...,  1.8992e-01,\n           -1.3038e-01, -9.2226e-01]],\n\n         [[-1.4771e-01, -5.4743e-02,  1.0354e-01,  ..., -6.4467e-02,\n            5.0235e-02, -4.7105e-03],\n          [ 2.0542e-01,  7.5674e-01, -3.8195e-01,  ...,  7.9123e-01,\n            3.3666e-01,  3.1182e-01],\n          [ 1.7716e-02, -2.9456e-01, -4.1132e-01,  ..., -3.7351e-02,\n           -5.0875e-01,  7.6014e-01],\n          ...,\n          [ 4.6112e-01,  1.3695e+00,  4.5065e-01,  ..., -6.2355e-01,\n            2.1478e-01,  1.1362e+00],\n          [-4.8439e-02,  1.9275e-02, -2.2616e-01,  ...,  6.6442e-02,\n           -1.4004e-01,  1.5981e-02],\n          [ 3.6793e-01, -4.4020e-01,  3.2716e-01,  ...,  5.6387e-01,\n            6.9215e-01,  6.9417e-02]],\n\n         [[-1.8205e-02, -3.0886e-03, -1.9086e-02,  ..., -2.5844e-02,\n            8.7407e-03, -1.7466e-02],\n          [-7.2501e-01, -4.0966e-01, -5.0878e-02,  ...,  7.9444e-01,\n           -4.2704e-01, -3.8911e-01],\n          [-2.3777e-01,  1.8286e-01, -1.1924e-01,  ...,  3.9828e-01,\n           -9.7823e-02, -7.2584e-01],\n          ...,\n          [-4.2147e-01, -4.4072e-01,  1.3276e-01,  ..., -3.9426e-01,\n            5.9784e-01, -5.9402e-01],\n          [-1.1911e+00, -2.2353e-01, -5.2611e-01,  ..., -6.8117e-01,\n            4.3145e-01, -6.0661e-01],\n          [ 5.7201e-01, -2.1513e-01, -2.0821e-02,  ..., -2.6662e-01,\n            4.3591e-01,  9.3392e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.7386e-02, -2.9366e-01,  2.2930e-01,  ...,  1.6992e+00,\n           -2.1956e-01, -6.9672e-02],\n          [ 1.3258e+00,  4.3520e-03, -4.5178e-01,  ..., -3.3861e+00,\n            6.0935e-01, -9.7994e-02],\n          [-3.8396e-03,  6.8534e-01, -4.5098e-01,  ..., -3.5777e+00,\n            4.3510e-01, -1.0692e+00],\n          ...,\n          [ 1.0944e+00, -1.3281e-01, -8.4928e-01,  ..., -4.4945e+00,\n           -8.8708e-01, -7.0986e-01],\n          [-4.0466e-01,  1.8280e-01,  7.3280e-02,  ..., -3.9964e+00,\n            5.3101e-01, -8.9631e-01],\n          [-2.8022e-01,  2.4591e-01, -9.5407e-01,  ..., -3.1422e+00,\n            5.9489e-01, -6.9649e-01]],\n\n         [[ 1.4856e-01,  9.7933e-01, -1.4228e+00,  ..., -1.2427e-01,\n            2.7183e-01,  9.2512e-01],\n          [-4.5280e+00, -5.5021e+00,  7.7566e-01,  ...,  3.7733e-02,\n            2.0070e+00, -6.6960e-01],\n          [-1.8428e+00, -5.4617e+00, -1.5096e+00,  ..., -1.3806e-01,\n           -1.6786e+00, -1.6976e+00],\n          ...,\n          [-1.0155e+00, -4.1935e+00,  9.1142e-01,  ..., -6.7730e-01,\n            8.5889e-01, -2.9881e+00],\n          [ 3.6602e-01, -2.7849e+00,  1.7301e+00,  ...,  8.3982e-01,\n            1.8913e+00, -1.8723e+00],\n          [ 1.8487e-01, -2.9940e+00,  3.7968e-01,  ..., -6.0796e-01,\n            1.2830e+00, -1.7956e+00]],\n\n         [[-6.7567e-01,  2.5791e-01, -4.4622e-02,  ...,  1.8188e-01,\n            3.5410e-02, -2.7977e-01],\n          [ 7.9076e-01, -6.6335e-01, -1.7585e+00,  ..., -1.6750e+00,\n           -1.0765e+00, -1.3595e+00],\n          [ 2.1679e+00, -6.9918e-02,  4.3477e-01,  ...,  1.2724e-01,\n           -4.9424e-01, -1.1511e+00],\n          ...,\n          [ 1.8131e+00, -2.6902e-01,  1.9496e-01,  ..., -7.7712e-02,\n           -1.8967e+00,  9.0248e-02],\n          [ 1.1712e+00, -1.0126e+00, -8.9854e-01,  ..., -8.4999e-01,\n           -1.0316e+00, -2.0615e+00],\n          [ 6.7570e-01,  3.8597e-01, -3.9110e-01,  ..., -8.8804e-02,\n           -3.7925e-01,  9.4492e-01]],\n\n         ...,\n\n         [[-2.6750e-02,  1.1317e-01,  1.4411e-01,  ..., -9.5337e-02,\n            2.8758e-02,  1.7906e-01],\n          [ 5.2997e-01, -2.4245e-01, -8.6445e-03,  ...,  1.7977e+00,\n           -1.2685e+00,  6.6170e-01],\n          [ 1.3688e+00, -5.8446e-01, -1.0249e+00,  ...,  6.1781e-01,\n           -1.2555e+00,  1.8549e-01],\n          ...,\n          [-4.0208e-01, -3.9943e-01,  9.0350e-01,  ..., -8.4163e-02,\n            2.9849e-01,  1.3064e+00],\n          [ 8.7521e-01, -5.4618e-01,  6.0006e-01,  ..., -4.2599e-01,\n            9.5319e-01,  4.6232e-02],\n          [ 6.7025e-01, -2.4472e-02,  6.4640e-01,  ...,  9.7068e-01,\n            5.1276e-01,  1.2734e-01]],\n\n         [[-3.0175e+00,  3.9929e-01, -3.6378e-02,  ..., -4.7122e-01,\n           -3.4804e-01,  1.2437e+00],\n          [ 5.1598e+00, -6.4113e-01, -1.2113e+00,  ..., -5.4299e-01,\n           -6.3423e-01, -2.7112e+00],\n          [ 3.9647e+00, -4.5006e-01, -8.1767e-01,  ...,  1.3302e+00,\n            1.0222e+00, -3.6523e-01],\n          ...,\n          [ 6.9698e+00,  1.0402e-01, -1.2673e+00,  ...,  1.4771e+00,\n           -3.9454e-01, -1.3275e+00],\n          [ 5.9740e+00, -3.1729e-01, -3.0471e-01,  ..., -1.6971e+00,\n            1.9964e+00, -5.9249e-01],\n          [ 4.3904e+00,  3.9197e-01, -6.1715e-01,  ..., -1.7761e+00,\n            3.8099e-01,  9.8361e-02]],\n\n         [[-1.4068e-02, -2.3846e-01,  2.5290e-02,  ..., -1.6074e-01,\n            3.3649e-01,  8.6691e-02],\n          [ 2.8668e-02, -2.1868e+00,  1.7570e-01,  ...,  3.2765e-01,\n            3.8849e-01, -1.7206e+00],\n          [-2.3774e-02, -1.9333e+00, -1.1854e-01,  ..., -5.0054e-01,\n            1.4996e+00, -2.0566e-01],\n          ...,\n          [-1.6754e-01, -7.2157e-01,  6.8358e-01,  ...,  2.4385e-01,\n            1.1955e+00, -2.1362e+00],\n          [-1.7204e-01, -1.5373e+00,  4.9301e-01,  ...,  1.1556e-01,\n            1.8178e+00, -1.0164e+00],\n          [ 2.1786e-01, -1.8928e+00,  4.4174e-01,  ...,  4.2819e-01,\n            1.5182e-01, -2.0864e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-0.0283, -0.0237, -0.0065,  ..., -0.0032, -0.0248,  0.3515],\n          [ 0.8264,  0.2939, -0.5176,  ..., -0.2927, -0.2171,  0.0181],\n          [ 1.9226, -0.7101,  0.3985,  ...,  0.1594,  0.7347, -0.2097],\n          ...,\n          [ 0.3205, -0.6643,  0.0532,  ..., -0.3513, -0.3939, -1.5316],\n          [ 0.0561, -0.2875, -0.6101,  ...,  1.2166,  0.5898, -1.2971],\n          [ 0.1017,  0.4254, -0.1121,  ...,  0.1045,  0.3800, -1.0232]],\n\n         [[ 0.0052, -0.0295,  0.0151,  ..., -0.0267,  0.0140,  0.0122],\n          [-0.5628, -0.9254,  0.9794,  ..., -0.2008,  1.3605, -0.3241],\n          [ 0.7993,  0.5138, -0.2952,  ..., -0.7700,  0.4493, -0.8436],\n          ...,\n          [-0.0907,  0.4751,  1.4920,  ..., -0.6118,  0.6339, -0.4834],\n          [ 1.1835, -0.9603,  1.0771,  ..., -0.7290,  0.1659, -1.8319],\n          [-0.7705,  0.0071, -1.1086,  ..., -0.2116,  1.5475, -1.0844]],\n\n         [[-0.0587,  0.0065, -0.0385,  ..., -0.0367,  0.0108, -0.0737],\n          [-0.3782,  0.4603, -0.0197,  ..., -0.0948, -0.1734, -0.0478],\n          [-1.0508, -0.9034, -0.1986,  ...,  0.7021,  0.1026,  0.6465],\n          ...,\n          [ 0.6918, -0.7151,  0.4399,  ..., -0.5258,  0.4609,  0.3265],\n          [-0.5982, -0.3842, -0.2050,  ..., -0.3919, -0.2597, -0.3368],\n          [-0.2127,  0.2818,  1.1315,  ..., -0.4063,  0.3917,  0.4088]],\n\n         ...,\n\n         [[-0.3268, -0.1926, -0.0725,  ..., -0.4884,  0.2164,  0.0924],\n          [ 2.4077, -2.1106,  0.0814,  ...,  2.1166,  0.7840, -0.3542],\n          [ 0.7914, -2.0034, -1.2725,  ...,  0.1668,  0.2048, -0.0149],\n          ...,\n          [ 0.1624,  0.0656,  0.3339,  ...,  1.6880,  0.5858, -0.4577],\n          [ 0.3699, -2.1781, -0.6363,  ...,  1.6692, -0.0237,  0.6235],\n          [ 1.1835, -1.2606, -0.3178,  ...,  0.8860, -0.2557, -1.0126]],\n\n         [[-0.0743, -0.1376, -0.0477,  ..., -0.1892, -0.1411,  0.1259],\n          [-0.8208, -0.8386,  0.6731,  ...,  0.6332,  0.0199, -0.7615],\n          [ 0.2827,  0.3740, -0.2432,  ...,  0.1827, -0.3376,  0.5142],\n          ...,\n          [ 0.9158,  0.1738,  0.1932,  ..., -0.3132, -0.0828,  0.6322],\n          [-1.2725,  0.6167, -0.2177,  ..., -0.5662, -0.9483,  0.7020],\n          [-0.4237, -0.4396, -0.7444,  ..., -0.1120, -0.1108,  0.0457]],\n\n         [[-0.0376, -0.0407,  0.1040,  ...,  0.0808, -0.0425,  0.0137],\n          [ 0.1663, -0.5093,  0.4754,  ..., -0.8001, -0.2647, -0.0260],\n          [ 0.8517, -0.0424,  0.2084,  ..., -0.4614, -0.3543, -0.4421],\n          ...,\n          [ 0.8837, -0.2089, -1.3849,  ...,  0.0321,  0.3742,  0.3700],\n          [ 1.5021,  0.3024, -1.6816,  ...,  0.2755, -0.4314,  1.2684],\n          [ 0.8986, -0.4031, -0.7551,  ...,  0.2049,  0.5642,  0.3766]]]],\n       grad_fn=<PermuteBackward0>)), (tensor([[[[-3.4242e-01,  8.8585e-01, -1.5804e-01,  ...,  1.1261e+00,\n           -1.9518e-01,  1.4177e-01],\n          [-1.9220e+00, -3.5766e+00,  1.0735e+00,  ..., -2.9989e+00,\n            2.4457e-01,  1.6964e+00],\n          [ 2.0634e-01, -4.5545e+00, -3.9479e-01,  ..., -2.3682e+00,\n            7.5262e-01,  1.9643e+00],\n          ...,\n          [ 4.1850e-02, -3.6175e+00, -3.7537e-01,  ..., -3.7409e+00,\n           -2.5598e+00,  1.3602e+00],\n          [ 9.7942e-01, -4.3081e+00, -8.1837e-01,  ..., -3.9368e+00,\n           -3.5577e-01,  6.4094e-01],\n          [-1.1241e+00, -4.2882e+00,  9.7364e-01,  ..., -3.9289e+00,\n            3.2482e-01,  1.0470e+00]],\n\n         [[ 4.3837e-02,  8.5526e-01, -6.5018e-01,  ..., -4.8066e-02,\n            2.9846e-01,  1.3144e-02],\n          [ 1.8581e+00, -8.6762e-01,  1.1911e-01,  ...,  1.4102e+00,\n           -1.5516e+00, -8.9818e-01],\n          [ 3.9744e-01, -7.4262e-01, -8.7026e-01,  ...,  2.1461e+00,\n            6.7020e-01, -5.7750e-01],\n          ...,\n          [-1.8549e+00,  4.0110e-01,  1.0519e+00,  ..., -6.1303e-01,\n            1.0524e+00, -1.9586e+00],\n          [-1.6497e+00,  1.7422e+00,  2.8445e+00,  ..., -4.2254e-01,\n            1.4167e+00,  2.2798e-02],\n          [ 3.9260e-01,  5.7385e-01,  6.0346e-01,  ...,  1.8517e+00,\n            1.6710e-01, -8.4124e-03]],\n\n         [[-3.0691e-01,  1.4184e-01, -9.7711e-01,  ..., -3.5239e-01,\n           -6.5329e-02, -1.5691e-01],\n          [ 5.4449e-01,  2.6089e-01,  3.3700e+00,  ...,  5.8992e-01,\n            3.0752e-01,  1.6272e-01],\n          [ 1.8183e-01, -4.2966e-01,  3.6656e+00,  ...,  6.5348e-01,\n            1.6247e-01,  1.1807e+00],\n          ...,\n          [ 6.0342e-01, -2.8372e-02,  4.0457e+00,  ...,  1.4485e-01,\n           -3.0530e-01, -1.8585e-02],\n          [ 8.4563e-01, -6.5222e-02,  3.8245e+00,  ...,  4.2785e-02,\n            8.7348e-01,  8.6994e-01],\n          [-4.1459e-01,  9.7909e-01,  2.9803e+00,  ..., -3.9050e-01,\n           -1.2682e-01,  4.7121e-02]],\n\n         ...,\n\n         [[ 3.7623e-01,  8.8415e-02, -6.9547e-02,  ..., -4.7736e-02,\n            2.2840e-01,  1.9032e-02],\n          [ 7.1144e-01,  1.8763e-01, -3.9937e-01,  ..., -4.9091e-01,\n           -1.2776e+00,  6.4044e-01],\n          [-3.3112e-01,  1.5726e+00, -1.1475e-01,  ...,  1.2293e+00,\n           -3.2792e-01,  1.3483e+00],\n          ...,\n          [-1.2218e+00,  1.0106e+00,  1.5841e+00,  ...,  2.4095e-01,\n            1.8157e+00,  2.5419e-01],\n          [-7.0075e-01, -2.0352e+00,  3.5377e-01,  ..., -2.1764e-01,\n            1.2933e+00,  3.9608e-01],\n          [-1.2331e+00, -2.5181e-01,  9.9036e-01,  ..., -7.5637e-02,\n            1.3286e+00,  6.3743e-01]],\n\n         [[ 1.9031e-01,  5.9438e-02,  3.3524e-01,  ...,  4.2277e-01,\n            1.9401e-02,  2.2399e-01],\n          [ 5.9327e-01,  2.8811e-01, -1.4083e-01,  ..., -1.5039e+00,\n           -2.3323e-01,  3.1527e-01],\n          [ 1.1468e+00, -2.1674e-01,  1.2189e+00,  ..., -4.9551e-01,\n            2.9952e-01,  4.2660e-01],\n          ...,\n          [ 1.2327e+00,  1.9132e-01,  9.7667e-01,  ..., -3.9745e-01,\n           -8.6595e-01,  1.6085e-01],\n          [ 1.5555e+00,  1.2640e-01,  1.5087e+00,  ..., -2.6383e-01,\n           -1.4203e+00, -3.3963e-01],\n          [ 2.5104e+00, -4.2117e-01,  9.7204e-01,  ...,  7.9410e-02,\n           -1.9639e+00,  1.2759e+00]],\n\n         [[-3.0269e+00,  5.5620e-01,  5.7562e-01,  ..., -9.3499e-01,\n            3.1438e-01,  1.8537e-01],\n          [ 6.4035e+00, -2.6481e-01, -1.7831e+00,  ...,  9.5200e-01,\n           -1.3967e+00, -1.9982e-02],\n          [ 6.5658e+00, -5.8532e-01, -3.0053e+00,  ...,  1.1486e+00,\n           -8.4129e-01, -1.1981e+00],\n          ...,\n          [ 8.7470e+00,  4.9102e-01, -8.1829e-01,  ...,  9.2144e-01,\n           -1.9827e-01, -2.1748e+00],\n          [ 8.8249e+00,  7.7651e-01, -9.9607e-01,  ...,  1.0463e-01,\n           -8.5053e-01, -1.0812e+00],\n          [ 9.4365e+00, -1.1869e+00, -5.3457e-01,  ...,  2.5683e+00,\n            4.1110e-01, -7.9529e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 4.2588e-02, -5.0356e-02,  8.1064e-03,  ..., -7.2504e-02,\n            9.6370e-03, -9.2134e-02],\n          [-4.3344e-01,  1.3342e-01, -4.7552e-02,  ...,  4.4079e-01,\n            2.6153e-01,  1.0634e+00],\n          [ 3.0987e-01, -1.2253e-01, -8.2554e-01,  ..., -5.1116e-01,\n           -7.1061e-01,  9.2578e-01],\n          ...,\n          [-8.3976e-01,  2.3753e-01,  2.7464e-01,  ...,  2.1087e-01,\n            2.5149e-01,  4.4114e-01],\n          [-1.1380e+00,  2.7989e-01, -2.8601e-01,  ..., -3.8907e-02,\n            6.6291e-01, -1.5787e-01],\n          [ 2.5615e-01, -1.8164e-01,  3.2558e-01,  ..., -7.4514e-02,\n            1.2012e-01, -5.7117e-01]],\n\n         [[ 7.9494e-02,  1.9629e-02, -1.4942e-02,  ..., -3.9482e-02,\n            2.1056e-02, -1.7007e-02],\n          [ 4.6344e-01, -1.4725e-01,  8.2258e-01,  ...,  3.4143e-01,\n            6.6488e-02, -1.0046e+00],\n          [ 4.0347e-01, -8.7195e-01, -1.1793e+00,  ...,  1.0580e+00,\n            5.7153e-01,  5.3592e-01],\n          ...,\n          [-6.6896e-01,  1.4602e-01,  1.4269e+00,  ..., -1.1985e-01,\n            1.1612e+00,  2.0802e+00],\n          [-2.0435e-01,  2.5427e-01,  8.5200e-01,  ..., -8.8234e-01,\n            9.5405e-01,  4.8340e-01],\n          [ 8.2470e-01,  1.2348e-01, -1.8964e-02,  ..., -2.7635e-01,\n            3.8721e-01,  7.9089e-01]],\n\n         [[ 6.5061e-02,  1.7394e-02, -1.3197e-02,  ...,  1.9595e-02,\n           -6.2144e-02, -6.3763e-02],\n          [-1.1359e-02,  6.8293e-01, -8.8521e-01,  ..., -8.8195e-01,\n           -9.2533e-01,  1.0995e+00],\n          [ 7.2526e-01, -6.4550e-01, -1.0321e-01,  ..., -6.4715e-01,\n           -5.5848e-01,  1.3314e+00],\n          ...,\n          [-6.7675e-01, -1.5009e-01, -6.6685e-01,  ..., -4.3112e-01,\n           -8.0608e-01, -2.0868e-01],\n          [-6.1433e-01, -2.4865e-01, -3.9539e-01,  ..., -1.8268e+00,\n            3.9166e-01, -1.5418e+00],\n          [-3.6172e-01, -6.2750e-01, -3.1816e-01,  ..., -9.2305e-02,\n            2.7719e-01,  3.6234e-02]],\n\n         ...,\n\n         [[-1.2369e-03,  2.0590e-02,  1.8059e-02,  ..., -6.7566e-02,\n           -2.1130e-02,  1.0344e-02],\n          [-2.6505e-01,  6.8229e-02, -5.8064e-01,  ...,  2.0919e+00,\n           -2.0487e-01, -6.2631e-02],\n          [-1.1090e+00, -4.0114e-01,  6.4974e-01,  ...,  1.8533e+00,\n           -5.9498e-01, -1.5189e+00],\n          ...,\n          [-1.7999e-01, -1.3203e+00, -4.0722e-01,  ...,  5.0378e-01,\n           -6.4837e-01,  2.0433e-01],\n          [ 1.6615e-01, -6.4841e-02,  4.4674e-01,  ..., -1.3760e+00,\n           -1.5886e+00,  1.6740e+00],\n          [-2.3218e-01, -1.0700e+00, -2.0870e-01,  ...,  4.2789e-01,\n            1.3457e-01,  4.9070e-01]],\n\n         [[ 4.5884e-02, -1.3652e-02,  3.3538e-02,  ...,  4.2297e-02,\n           -1.0650e-02,  1.3725e-02],\n          [ 6.7968e-01, -6.1345e-01, -5.1771e-01,  ...,  3.9566e-01,\n           -6.3267e-01, -7.4087e-01],\n          [ 3.2293e-01, -5.0785e-01, -2.0838e+00,  ...,  1.2406e+00,\n            3.0909e-01,  7.6786e-01],\n          ...,\n          [ 6.6215e-01,  1.4883e+00, -1.3764e+00,  ..., -8.5867e-01,\n           -9.7664e-01,  7.5940e-02],\n          [-3.7327e-01,  1.0781e+00, -1.1749e+00,  ...,  1.5871e-02,\n           -8.2584e-01, -8.5889e-01],\n          [-1.0721e-01, -2.9212e-01, -1.0636e+00,  ...,  4.9721e-01,\n           -3.1659e-02, -7.9181e-02]],\n\n         [[ 7.6791e-02, -2.0113e-01, -8.1943e-02,  ..., -2.3764e-02,\n            2.0464e-01, -5.6837e-02],\n          [ 9.9648e-02, -2.1344e+00,  4.2548e-02,  ...,  4.3812e-01,\n           -7.9336e-01,  4.1660e-01],\n          [-1.0473e-01, -8.4764e-01, -1.0118e-01,  ...,  7.0098e-01,\n           -6.8365e-02, -1.1925e-01],\n          ...,\n          [ 8.6354e-02,  2.0148e+00, -7.8215e-01,  ...,  1.2433e+00,\n           -1.2465e+00,  8.4485e-02],\n          [ 2.1874e-01,  1.7080e+00, -7.7510e-01,  ...,  2.0696e-01,\n            1.1352e-02,  1.2247e-01],\n          [-9.0595e-01, -7.8929e-01,  2.8048e-02,  ...,  1.5975e-01,\n           -3.9888e-01,  8.6554e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.0446, -0.2861, -0.1417,  ...,  0.6163,  0.7392, -0.3206],\n          [-3.9079, -2.3097,  2.2869,  ..., -1.0490, -3.9810,  0.3166],\n          [-4.8613, -0.9516,  2.6062,  ..., -0.0303, -3.9882, -0.5383],\n          ...,\n          [-3.5567, -2.6193,  0.7828,  ...,  0.6872, -4.4898, -0.6281],\n          [-4.2590, -1.7552,  2.8268,  ..., -0.6523, -4.0929, -0.2955],\n          [-4.9762, -1.9708,  0.0080,  ..., -0.3365, -3.7900, -0.1139]],\n\n         [[-0.1387, -0.0569,  0.1582,  ..., -0.0465, -0.8847, -0.2043],\n          [-0.5542, -0.0729, -0.3130,  ..., -0.0560, -0.7031,  1.6099],\n          [-1.3839,  1.4181, -0.2936,  ...,  1.3373, -1.0466,  1.9511],\n          ...,\n          [-1.8806,  0.3803, -1.2217,  ...,  1.7803,  0.9103,  0.4690],\n          [-1.2040,  1.6865, -0.4972,  ...,  0.5542, -0.4544,  1.0700],\n          [-2.2268,  0.3460, -1.5116,  ...,  0.5357, -0.8997,  0.5252]],\n\n         [[ 0.1924,  0.3075,  1.1360,  ..., -0.4682,  0.4283, -0.5042],\n          [ 1.1163, -0.8514, -1.3363,  ..., -0.5049, -2.3173,  1.4079],\n          [-0.4352, -0.6518, -1.4657,  ...,  0.3762, -3.2430,  2.4583],\n          ...,\n          [-1.2546, -1.4138, -1.6076,  ..., -2.2605, -1.6244, -0.5993],\n          [-0.4396, -2.4026, -0.8960,  ..., -1.1734, -1.3114,  0.8956],\n          [ 0.6041, -1.4925, -0.8934,  ..., -1.4043, -2.3182,  1.5456]],\n\n         ...,\n\n         [[-0.1552,  0.0680, -0.2229,  ..., -0.0112,  0.1523,  0.0379],\n          [-1.4715, -0.2699, -1.0010,  ...,  0.9816, -0.0131, -0.5940],\n          [-2.8031, -0.0749, -0.5765,  ...,  1.4030,  0.5713, -0.3813],\n          ...,\n          [-0.7421,  0.1682,  1.1091,  ...,  0.2662, -1.0974, -1.7564],\n          [ 0.5485,  0.4741,  1.4970,  ..., -0.3822, -0.6439, -1.4745],\n          [-1.9331,  1.2431, -0.7142,  ...,  0.8943, -0.3290, -0.2887]],\n\n         [[-0.3520, -2.1820,  0.1305,  ..., -0.0781, -0.0452,  0.9126],\n          [-0.1676,  0.7424,  0.8457,  ..., -0.0430, -0.6897,  0.9972],\n          [-1.0619,  3.2376,  2.5831,  ...,  0.4896,  0.5569,  1.1650],\n          ...,\n          [ 0.1921,  4.7669, -0.9619,  ...,  0.1920,  0.0281, -1.6348],\n          [-0.3346,  4.0043,  0.8320,  ...,  1.9739,  0.4835,  0.2861],\n          [-0.4076,  1.6655, -1.2985,  ...,  1.3795, -0.0910,  1.3841]],\n\n         [[ 0.3705,  0.0804, -0.1422,  ...,  0.6539,  0.1286,  0.2599],\n          [ 0.2785, -0.1845, -0.7767,  ..., -0.6425,  0.7165, -1.3394],\n          [-0.0426, -1.2866, -0.2084,  ...,  0.4318,  1.4718,  0.1445],\n          ...,\n          [-2.9565, -2.3736, -1.0456,  ...,  0.5869, -0.2452, -0.1996],\n          [-2.0673, -1.9636,  0.6297,  ..., -1.2112, -0.6369,  2.2856],\n          [-1.5174, -0.1974,  1.0155,  ...,  0.1546,  0.5188,  1.0438]]]],\n       grad_fn=<PermuteBackward0>), tensor([[[[-3.2128e-02,  4.2769e-02, -6.2959e-02,  ..., -2.4990e-02,\n           -5.5760e-04,  1.9665e-02],\n          [ 5.3965e-01,  1.5681e-02, -8.6195e-01,  ..., -6.3801e-01,\n            3.3482e-02,  2.0060e-01],\n          [-2.2824e-02,  1.7671e-01, -1.9057e-01,  ..., -6.8474e-01,\n           -7.3559e-01,  5.6330e-01],\n          ...,\n          [-5.3655e-01, -6.8140e-01, -2.7338e-01,  ..., -8.9929e-01,\n            6.7783e-01, -7.7594e-02],\n          [-6.6499e-02, -2.1919e-01,  7.2967e-01,  ...,  3.1051e-01,\n           -9.1984e-01,  1.6034e+00],\n          [-4.6005e-02,  1.7540e-01, -1.4991e-01,  ..., -3.8299e-01,\n           -1.2224e-01,  3.0644e-01]],\n\n         [[ 8.2082e-03, -2.1715e-02,  3.5759e-02,  ...,  2.5118e-02,\n           -4.6394e-02,  1.3449e-02],\n          [-5.6013e-01, -4.7914e-01, -7.3465e-01,  ...,  2.4955e-01,\n           -2.2302e-01,  1.7230e-02],\n          [-2.6670e-01, -5.7561e-02, -1.0933e+00,  ...,  6.9102e-01,\n            8.8651e-01,  2.3363e-01],\n          ...,\n          [ 1.4549e+00,  6.2701e-01,  3.4483e-01,  ..., -2.6119e-01,\n           -1.8188e-01,  2.0104e-01],\n          [ 9.1125e-01, -5.0901e-01,  1.7518e-01,  ...,  4.0394e-02,\n           -8.2176e-03, -6.1320e-01],\n          [-3.7897e-01, -1.3483e-01,  9.1875e-02,  ...,  3.8443e-01,\n            4.2697e-01, -3.3593e-01]],\n\n         [[ 5.1188e-02, -3.5194e-02,  2.7533e-02,  ...,  1.4181e-02,\n           -6.4940e-03,  2.2787e-02],\n          [ 5.1446e-01, -1.3208e+00, -1.0446e+00,  ...,  1.7527e-02,\n            1.7641e+00, -3.5737e-01],\n          [-2.7716e-01,  6.2415e-02, -1.8526e+00,  ..., -4.1313e-01,\n           -5.6179e-01,  1.0078e+00],\n          ...,\n          [ 4.1809e-01, -5.0762e-02, -3.4584e-01,  ..., -1.2960e+00,\n           -5.4343e-01, -1.4812e-01],\n          [ 1.5966e-01, -1.5908e-01, -2.6502e-01,  ..., -2.6891e-01,\n            1.3304e+00, -6.3225e-01],\n          [ 4.6884e-01, -2.5218e-01, -6.3545e-01,  ..., -2.6028e+00,\n            3.5556e-02, -2.5807e-01]],\n\n         ...,\n\n         [[-1.8817e-01,  7.5630e-02,  5.1481e-02,  ...,  6.3044e-02,\n            4.5983e-02, -1.2272e-01],\n          [-4.8166e-01, -8.0081e-01,  4.7553e-01,  ...,  9.2072e-01,\n            1.4889e+00, -4.9100e-01],\n          [ 3.1190e-01, -1.7164e+00, -6.4195e-01,  ..., -3.0160e-01,\n            9.8333e-01, -1.3910e+00],\n          ...,\n          [ 2.6294e-01,  1.7654e-01, -2.2927e-01,  ..., -5.6709e-01,\n           -4.2602e-01,  1.8268e-01],\n          [-1.2287e+00, -8.8129e-01, -4.9618e-01,  ...,  5.7656e-01,\n           -9.3973e-02,  9.1813e-01],\n          [-5.2435e-01, -5.0482e-01, -6.5543e-01,  ..., -9.4711e-02,\n            2.7462e-01, -4.3348e-01]],\n\n         [[-5.8365e-01, -2.0280e-02,  4.3795e-02,  ..., -1.2728e-02,\n            1.4847e-02, -1.1488e-02],\n          [ 2.1189e-01,  6.3309e-01, -8.5212e-01,  ...,  1.7115e-02,\n           -1.6814e-01,  3.3735e-01],\n          [-5.0398e-01,  1.2201e-01, -9.9508e-01,  ...,  1.0425e+00,\n            5.1320e-01,  8.6971e-01],\n          ...,\n          [-1.4073e+00,  4.5373e-01, -1.8495e-01,  ...,  1.0106e-01,\n            1.1485e+00, -5.4967e-02],\n          [-7.8669e-01, -4.6794e-01,  8.1498e-02,  ..., -6.6191e-01,\n            9.3903e-01, -4.7145e-01],\n          [-2.6530e+00, -1.3969e-01,  2.4383e-01,  ..., -2.2311e-01,\n            4.6452e-01,  3.6028e-01]],\n\n         [[ 1.8879e-02,  8.3848e-02, -5.0716e-02,  ...,  5.5664e-02,\n            2.9355e-02, -4.1401e-02],\n          [-3.1205e-01,  3.7567e-01,  3.4224e-01,  ...,  7.1520e-01,\n            7.5321e-01, -1.1299e-01],\n          [-1.0119e+00,  3.3448e-01, -1.2705e+00,  ..., -8.8392e-01,\n           -2.3355e+00, -2.2953e-01],\n          ...,\n          [ 1.9421e-01,  1.2625e+00,  6.1021e-01,  ...,  1.0141e+00,\n           -1.3892e-01, -3.8717e-01],\n          [-1.6888e+00,  1.0561e+00,  6.2911e-01,  ..., -7.9247e-01,\n           -1.2793e+00,  2.5452e-02],\n          [-6.8985e-01,  3.8036e-01,  1.1172e+00,  ..., -3.2169e-01,\n           -9.4463e-01,  8.1670e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-3.0739e-02, -2.3328e+00,  1.6444e-01,  ..., -2.4874e-01,\n           -2.1955e-01,  6.7818e-02],\n          [ 6.6501e-01,  3.8897e+00,  2.5626e-01,  ..., -1.2447e+00,\n           -5.1476e-01,  1.7492e-01],\n          [ 2.3555e-01,  4.3144e+00,  1.5203e+00,  ..., -1.0305e+00,\n           -2.7401e-01, -2.9700e-01],\n          ...,\n          [-7.4795e-01,  6.0315e+00,  1.4481e+00,  ..., -1.7219e+00,\n            1.5043e-01,  3.6442e-02],\n          [-1.1906e+00,  6.0815e+00,  7.5815e-01,  ...,  7.6899e-03,\n            1.6461e+00, -4.0052e-01],\n          [-7.7746e-01,  4.0435e+00,  8.6778e-01,  ..., -1.0730e+00,\n            3.5681e-01, -7.8313e-01]],\n\n         [[-8.1230e-01,  2.0313e-01,  4.6825e-01,  ..., -5.1517e-01,\n            1.0709e+00,  1.1254e+00],\n          [ 1.9943e-01,  7.3408e-02,  1.8181e+00,  ..., -3.0854e-01,\n            1.3158e+00,  6.8892e-02],\n          [ 3.2874e-01, -6.4358e-01,  2.3493e+00,  ..., -1.5555e-01,\n            2.4417e+00,  1.8911e-01],\n          ...,\n          [ 6.9652e-01,  1.3289e+00, -4.7835e-01,  ..., -1.1337e+00,\n            6.5288e-01, -2.0380e+00],\n          [ 2.1073e-01,  1.0003e+00,  1.2394e+00,  ..., -6.3918e-01,\n            8.0475e-01, -1.5733e+00],\n          [ 3.1132e-01,  2.8403e-01,  2.9093e-01,  ..., -1.5865e+00,\n            3.1738e+00, -7.4550e-01]],\n\n         [[-8.3052e-01,  4.9202e-01,  1.5700e-02,  ...,  5.0540e-01,\n           -2.3221e-01,  1.1760e+00],\n          [ 1.8285e+00, -1.1218e+00, -6.0110e-01,  ...,  1.7362e-01,\n            1.3459e+00,  1.1774e-01],\n          [ 1.6430e+00, -2.1772e+00,  1.7248e+00,  ...,  3.0036e-01,\n            7.7876e-01,  9.9057e-01],\n          ...,\n          [ 1.0010e+00, -1.7313e+00,  1.9045e+00,  ...,  8.0702e-01,\n            5.2974e-01, -6.8052e-01],\n          [ 1.5992e+00, -2.7915e+00,  1.0877e+00,  ...,  7.4602e-01,\n            3.0332e-02, -1.3237e+00],\n          [ 1.6438e+00, -9.9109e-01,  9.2324e-01,  ...,  1.1409e+00,\n            5.9684e-01, -3.3019e-03]],\n\n         ...,\n\n         [[-3.0107e-01, -1.1655e-01,  1.3441e-01,  ...,  1.8965e-01,\n            1.7320e+00, -2.8680e+00],\n          [ 1.9154e+00,  1.2091e+00,  2.8645e-01,  ...,  1.3748e-01,\n           -3.8644e+00,  3.9812e+00],\n          [ 9.2973e-01, -1.0160e-01, -1.3099e-02,  ..., -3.6517e-01,\n           -4.1451e+00,  4.7426e+00],\n          ...,\n          [ 5.7876e-01, -5.6903e-01, -9.7981e-01,  ..., -1.5678e+00,\n           -5.4191e+00,  5.7578e+00],\n          [-1.9895e-01, -5.5637e-01, -4.0058e-01,  ..., -1.3523e+00,\n           -5.3991e+00,  5.7263e+00],\n          [ 1.0074e-01,  9.1534e-01,  5.5960e-01,  ..., -1.0116e+00,\n           -5.7379e+00,  5.5124e+00]],\n\n         [[ 1.8309e-01,  3.5898e-01,  2.1865e-01,  ..., -2.1976e-01,\n            3.2432e-02, -1.3621e-01],\n          [-1.1902e+00,  2.5967e-01,  1.3770e+00,  ...,  1.6082e+00,\n            5.3296e-01,  1.0141e-01],\n          [-1.6201e+00,  3.1865e-01,  5.4789e-01,  ...,  7.9333e-01,\n            4.1223e-01, -9.2892e-01],\n          ...,\n          [-1.7144e+00,  2.9198e-01, -6.5764e-01,  ...,  1.4415e+00,\n           -4.7545e-02,  6.2226e-01],\n          [-1.0669e+00,  9.0313e-01, -9.0604e-01,  ...,  1.4476e+00,\n           -3.0205e-01, -8.2349e-01],\n          [-6.1682e-01,  4.0207e-01, -2.7279e-01,  ...,  1.9482e+00,\n           -5.3192e-01, -1.6915e-01]],\n\n         [[ 3.8544e-01,  1.1505e-01,  6.3900e-01,  ...,  5.3104e-01,\n            5.7931e-01, -3.3185e-01],\n          [ 4.0666e-01, -9.3643e-01, -1.0314e+00,  ..., -6.5106e-01,\n           -3.1251e+00, -3.6746e-01],\n          [ 9.7926e-01, -9.1059e-01,  2.0969e-01,  ..., -1.8782e+00,\n           -3.4683e+00,  2.0600e-01],\n          ...,\n          [-1.4226e-01, -9.7476e-01, -5.4240e-01,  ..., -2.8039e+00,\n           -4.1771e+00,  1.9208e+00],\n          [-7.5886e-01, -6.7514e-01, -4.4394e-02,  ..., -2.4649e+00,\n           -4.5963e+00,  6.7639e-01],\n          [-6.9450e-01,  4.6576e-01, -7.3801e-01,  ..., -2.1795e+00,\n           -4.2150e+00,  2.8132e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 5.3734e-02, -1.4238e-02, -3.5810e-02,  ...,  1.2174e-01,\n           -5.9948e-02, -4.3049e-02],\n          [-4.0711e-01,  2.3952e-01, -1.4630e-01,  ..., -4.0966e-01,\n            8.4789e-01, -2.2644e-01],\n          [-1.4474e+00, -8.4849e-01, -9.8837e-02,  ..., -2.0224e-01,\n            6.6301e-01,  7.1867e-01],\n          ...,\n          [-6.3025e-01, -9.1939e-01,  1.5612e+00,  ...,  6.4965e-01,\n            2.6919e+00,  8.4095e-01],\n          [-5.2483e-01, -1.3637e+00,  1.8403e+00,  ...,  3.8219e-01,\n            1.4497e+00,  1.0680e-03],\n          [-2.9676e-02,  1.7135e-01, -7.6390e-01,  ..., -3.9354e-01,\n            4.4974e-01, -9.9768e-01]],\n\n         [[ 1.7320e-02,  2.3816e-02,  4.7974e-02,  ..., -4.7309e-03,\n           -6.8243e-03,  3.2884e-03],\n          [ 5.4060e-01,  1.3387e+00,  1.0772e+00,  ..., -4.1183e-01,\n           -7.2695e-02,  7.3047e-01],\n          [ 1.6604e+00, -1.0405e+00, -4.6418e-02,  ..., -1.5549e-01,\n            4.8930e-01,  2.6706e-01],\n          ...,\n          [-2.6610e-02,  1.4448e+00, -9.6232e-02,  ...,  1.4043e+00,\n           -2.1171e-01,  6.2546e-01],\n          [ 1.7877e+00, -7.9522e-01,  3.4070e-01,  ..., -1.0215e+00,\n            5.2032e-01, -7.5460e-01],\n          [-6.6356e-01,  7.8232e-01,  8.1056e-01,  ..., -6.7723e-01,\n           -5.3982e-01, -7.7322e-01]],\n\n         [[ 5.1727e-02, -3.2729e-02,  6.2676e-02,  ...,  3.5751e-02,\n           -7.1613e-02, -5.9328e-02],\n          [-3.5343e-01,  7.5885e-01, -4.1293e-02,  ...,  2.4424e-01,\n           -6.9912e-01, -5.4976e-01],\n          [ 7.8512e-02, -4.0856e-01,  5.3512e-01,  ..., -8.2215e-01,\n            1.6111e-03, -5.0301e-01],\n          ...,\n          [-7.4352e-01,  2.1682e-01,  5.4941e-01,  ..., -7.3409e-01,\n            5.1859e-01,  4.1631e-02],\n          [-3.8653e-01,  1.1920e+00, -2.0321e-01,  ..., -1.3420e-01,\n           -2.3149e-01, -1.5669e-01],\n          [-6.5035e-01,  1.6409e-01, -2.7168e-01,  ..., -5.6858e-02,\n            3.0424e-01,  6.7127e-02]],\n\n         ...,\n\n         [[-9.5711e-02, -3.3712e-02,  3.5806e-02,  ..., -9.8101e-02,\n            3.3037e-02,  2.1276e-02],\n          [-1.0548e+00,  1.0086e+00,  3.5336e-01,  ...,  1.4173e-01,\n            1.1533e+00, -5.7750e-01],\n          [ 3.0501e-01,  3.8879e-01,  1.4593e+00,  ..., -1.5761e+00,\n            6.6029e-01, -2.4784e+00],\n          ...,\n          [ 2.1433e-01,  3.0902e-01, -1.5677e-01,  ..., -1.4376e+00,\n            3.1234e-01, -1.5930e-01],\n          [ 9.2112e-02,  1.3849e+00, -3.5478e-01,  ..., -2.0249e+00,\n            1.7484e+00,  1.5088e+00],\n          [ 1.0588e+00,  5.0691e-02,  1.6493e-02,  ..., -3.3869e-01,\n            6.8473e-01,  6.6575e-02]],\n\n         [[ 1.5089e-01, -6.4248e-02,  1.3481e-01,  ...,  7.3110e-02,\n            4.8974e-03, -1.2889e-01],\n          [ 6.8720e-01,  5.7468e-02, -1.7870e-01,  ..., -1.1156e+00,\n           -1.2297e+00,  1.5925e-02],\n          [ 4.6848e-01,  6.8089e-01,  4.5960e-01,  ..., -3.4666e-01,\n           -8.2155e-01,  7.9261e-01],\n          ...,\n          [-6.8295e-01, -4.1632e-01, -3.1648e-01,  ..., -1.0120e+00,\n           -1.2630e+00,  4.1550e-01],\n          [ 3.2675e-02, -5.2766e-01, -1.6868e+00,  ..., -9.0995e-01,\n           -2.2853e-01,  1.4612e+00],\n          [ 2.0993e-01, -2.2173e-01,  1.0833e+00,  ..., -6.0768e-01,\n            6.2882e-01,  8.7863e-02]],\n\n         [[ 2.1724e-01, -6.2232e-02, -5.5712e-02,  ...,  2.1461e-02,\n            4.3089e-02,  3.7415e-02],\n          [ 1.3125e+00, -4.4910e-01, -7.5738e-01,  ...,  3.2747e-01,\n           -9.8980e-02, -8.0641e-02],\n          [-1.6063e-01, -7.7957e-01, -1.6312e-01,  ..., -4.8402e-01,\n            8.7137e-01, -2.5966e-01],\n          ...,\n          [-3.6798e-01,  5.0565e-01,  2.8998e-01,  ...,  2.5920e-01,\n           -1.9344e+00,  7.5728e-01],\n          [ 4.9460e-02, -4.9568e-01,  8.4527e-01,  ..., -3.3127e-01,\n            6.4243e-01, -3.5335e-01],\n          [ 1.1826e-01, -1.5026e-01,  9.7509e-01,  ...,  4.7500e-01,\n           -8.4105e-01,  6.5077e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.3000e-02, -2.4427e-01, -4.4500e-01,  ...,  3.0083e-01,\n            3.2684e-01,  3.6586e-01],\n          [-3.1921e-01,  1.1035e+00, -8.1620e-01,  ..., -1.0129e+00,\n           -1.0356e-01, -3.4720e-01],\n          [ 1.2050e-01,  8.5493e-01, -4.7644e-01,  ...,  2.5663e-01,\n           -7.2198e-01,  7.0494e-01],\n          ...,\n          [-3.0341e-01,  2.8503e-03,  4.0952e-01,  ...,  2.3109e+00,\n           -8.2102e-01, -3.8004e-01],\n          [-3.2060e-03,  2.9617e-01, -1.1835e-01,  ...,  3.1173e+00,\n            4.8563e-01,  1.0006e+00],\n          [ 4.6373e-01, -9.1020e-02, -9.6269e-01,  ...,  6.1472e-01,\n           -6.0768e-01,  9.6790e-01]],\n\n         [[-2.7947e-01,  1.5264e-01,  1.2265e-01,  ...,  6.3867e-02,\n           -1.1406e+00, -1.3803e-01],\n          [ 7.5798e-01,  7.3406e-01,  2.4232e+00,  ..., -1.7083e-01,\n           -1.2876e+00,  6.4982e-01],\n          [ 5.9163e-01, -2.5393e-01,  9.1644e-01,  ...,  1.4073e+00,\n           -9.9605e-01,  1.3304e+00],\n          ...,\n          [ 2.9274e-01, -3.5706e-01,  1.8072e+00,  ...,  5.2217e-01,\n           -1.9019e+00, -1.5490e+00],\n          [-3.1271e-02,  1.4249e-01,  1.4840e+00,  ...,  4.6309e-01,\n           -1.1398e+00, -3.6930e-01],\n          [-1.5090e-01,  1.7000e+00,  1.0501e+00,  ...,  4.5167e-01,\n            8.9898e-01,  2.7553e-01]],\n\n         [[-1.2364e+00, -1.0861e-01,  5.7612e-01,  ..., -6.5710e-01,\n            4.6449e-01, -2.9151e-01],\n          [ 5.4201e-01,  4.5983e-01, -1.3218e-01,  ...,  6.8797e-01,\n            3.7853e-01,  7.0102e-01],\n          [ 1.0557e+00,  3.7951e-01,  9.9992e-02,  ...,  1.0149e+00,\n           -8.0010e-02,  3.1117e-01],\n          ...,\n          [ 2.7617e+00,  9.2056e-01,  2.5572e+00,  ..., -2.7046e-01,\n           -2.6543e-01,  4.2675e-01],\n          [ 3.2526e+00,  2.6459e+00,  1.0609e+00,  ...,  4.3607e-01,\n           -1.4836e-01,  5.3355e-01],\n          [ 1.2066e+00,  2.9331e+00,  7.7193e-03,  ...,  6.1325e-01,\n           -1.2444e+00,  4.3294e-01]],\n\n         ...,\n\n         [[ 7.8954e-01, -9.0881e-01, -3.9374e-01,  ..., -1.0515e+00,\n           -4.3844e-01,  4.8402e-01],\n          [ 1.0609e+00, -1.1448e+00, -7.7389e-01,  ..., -4.1185e-01,\n           -8.2883e-01, -6.0351e-01],\n          [ 5.0185e-01, -6.5958e-01, -5.7255e-02,  ..., -1.2351e+00,\n           -6.1601e-01, -5.3572e-01],\n          ...,\n          [ 2.8482e-01,  9.0139e-01, -4.6546e-01,  ..., -1.0758e+00,\n            5.9336e-01, -1.4398e+00],\n          [-1.4410e+00,  1.8157e+00, -1.4097e-01,  ..., -1.1282e+00,\n            1.1474e+00, -1.1473e+00],\n          [ 9.0526e-01,  2.4593e-01, -1.1596e+00,  ...,  3.7836e-01,\n           -1.2631e+00, -4.5477e-01]],\n\n         [[-9.2652e-01,  2.5459e+00,  3.0600e-01,  ...,  3.4490e-01,\n            1.9552e+00, -5.4894e-01],\n          [ 4.5858e-01, -2.1932e+00,  1.7457e-01,  ...,  1.7436e+00,\n           -2.5849e+00,  2.2585e+00],\n          [ 1.7932e-02, -2.7316e+00,  2.1564e-01,  ...,  6.8611e-01,\n           -4.1920e+00,  1.6138e+00],\n          ...,\n          [ 2.3517e-01, -6.8795e+00,  2.4382e+00,  ...,  1.0712e+00,\n           -3.7377e+00,  2.1150e+00],\n          [-5.6485e-01, -5.2606e+00,  1.9043e+00,  ...,  6.5478e-01,\n           -4.0746e+00,  7.2067e-01],\n          [-4.5100e-02, -3.6478e+00,  1.7280e-01,  ..., -7.5855e-01,\n           -4.0225e+00,  1.6237e+00]],\n\n         [[-2.0252e+00, -3.5049e-01, -1.1153e+00,  ..., -3.9788e-01,\n            6.0882e-02,  2.5314e-01],\n          [ 2.0696e+00, -4.9512e-01,  1.0584e+00,  ...,  7.4010e-01,\n            4.9070e-01,  5.7455e-01],\n          [ 2.5638e+00,  1.1148e+00, -5.5302e-01,  ...,  1.2067e-01,\n            3.6513e-01, -1.7264e-01],\n          ...,\n          [ 4.7496e+00, -1.1327e+00,  3.4154e+00,  ...,  1.0882e+00,\n            5.4831e-01, -2.3920e-01],\n          [ 3.7342e+00, -7.3702e-01,  2.6068e+00,  ...,  3.8731e-01,\n           -4.0681e-01, -8.3097e-01],\n          [ 2.0753e+00,  1.0187e+00,  2.0027e+00,  ...,  5.9609e-01,\n           -1.2865e-01, -3.3630e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-5.9407e-02, -8.5679e-02,  1.7006e-02,  ...,  1.0696e-01,\n           -2.7256e-02,  1.2712e-02],\n          [-1.1028e-01, -2.6695e-01, -2.7972e-01,  ...,  7.3321e-02,\n            8.1304e-02,  9.9563e-01],\n          [ 2.2059e-01,  5.5391e-01, -1.4877e+00,  ..., -2.8705e-01,\n            3.1862e-01,  8.9564e-01],\n          ...,\n          [-2.2597e+00,  4.0054e-01,  3.5313e-01,  ..., -3.1097e-01,\n           -6.2333e-01,  6.2799e-02],\n          [-4.0290e-01,  4.4471e-01, -5.3869e-01,  ...,  3.8806e-01,\n            7.7051e-01, -8.9603e-02],\n          [-6.9788e-02,  9.6001e-01, -1.9557e-01,  ...,  1.2244e+00,\n           -4.5771e-01, -4.4116e-01]],\n\n         [[ 1.9984e-02,  9.9455e-03, -1.8535e-02,  ...,  2.8180e-02,\n            3.0411e-02,  5.3315e-02],\n          [ 5.9644e-01,  5.1996e-01, -1.2417e+00,  ..., -7.3600e-02,\n            1.1116e+00,  4.7234e-01],\n          [ 9.7821e-01, -1.1090e+00, -1.6003e-01,  ...,  1.1247e+00,\n           -1.9147e-01,  2.4299e-01],\n          ...,\n          [-2.4673e+00,  2.1871e+00,  1.5703e+00,  ..., -4.3630e-01,\n           -1.2542e-01, -6.9802e-01],\n          [ 2.0128e-01,  7.3901e-01, -9.9507e-01,  ..., -1.5172e+00,\n           -4.1022e-01, -5.7266e-01],\n          [ 2.5451e-02,  8.2747e-01, -5.4466e-01,  ..., -5.8290e-01,\n           -9.6744e-01, -4.3227e-01]],\n\n         [[ 3.0771e-02,  3.3925e-02, -9.5088e-02,  ...,  2.0078e-02,\n           -1.8055e-03,  3.6986e-03],\n          [-7.0360e-01,  1.2550e-01,  2.7324e-01,  ...,  2.4933e-01,\n           -1.0440e+00,  2.5170e+00],\n          [-3.4458e-01, -8.2069e-01, -4.0843e-01,  ..., -7.7839e-01,\n           -7.3081e-01, -2.8720e-01],\n          ...,\n          [-6.4247e-01,  2.9498e-01, -1.6238e+00,  ...,  1.0017e+00,\n           -4.7254e-01,  3.8370e-01],\n          [ 1.0750e-01,  5.6388e-01, -1.1467e+00,  ...,  4.9151e-01,\n            4.4171e-01,  4.7236e-01],\n          [-5.2674e-01,  6.2729e-01, -7.3631e-01,  ..., -9.5472e-02,\n           -3.0963e-01, -9.4148e-02]],\n\n         ...,\n\n         [[ 3.2988e-02,  1.8975e-02, -2.9906e-03,  ..., -2.4181e-03,\n           -7.7691e-04,  3.6506e-02],\n          [ 1.0896e+00, -5.7907e-01,  2.7873e-01,  ...,  5.9871e-01,\n            2.0423e+00, -1.8796e-01],\n          [ 1.1956e+00, -2.4500e-01,  9.7125e-01,  ...,  7.4841e-01,\n           -1.6449e-01, -7.1359e-01],\n          ...,\n          [-1.2320e+00,  2.2416e+00,  1.4954e+00,  ...,  3.9171e-01,\n           -3.1156e-01, -1.0704e+00],\n          [-9.0054e-01,  2.1070e-01, -2.4055e-01,  ..., -2.8735e-01,\n           -2.5012e-01, -2.8543e-01],\n          [ 1.7678e-01,  9.9594e-01, -1.2952e-01,  ...,  3.1505e-01,\n            1.0217e+00, -2.8011e-01]],\n\n         [[-6.6889e-02, -4.6806e-02,  1.3993e-02,  ...,  1.3800e-02,\n           -6.0449e-02, -1.0146e-01],\n          [-1.2984e-01, -3.9512e-01,  9.2746e-02,  ...,  2.9088e-01,\n            1.8776e-01, -2.5011e-02],\n          [ 1.4572e+00, -1.4012e-01,  1.1444e-01,  ...,  2.8305e-01,\n           -3.2234e-01, -1.2569e-01],\n          ...,\n          [ 7.1413e-01, -1.7208e+00,  6.2937e-02,  ..., -6.0423e-01,\n            3.3153e-01, -1.3289e+00],\n          [ 8.2657e-02, -8.4586e-02, -1.6153e+00,  ..., -2.1428e-01,\n           -1.4150e-01,  1.0627e+00],\n          [ 6.7371e-01, -6.1994e-01, -2.5474e-01,  ...,  3.9961e-01,\n            4.5265e-01,  4.9732e-01]],\n\n         [[-1.5357e-02,  3.5532e-02, -6.0959e-02,  ..., -2.2750e-02,\n            4.1216e-03,  3.3249e-03],\n          [-4.9697e-01, -9.3557e-01, -6.3136e-02,  ...,  6.6151e-01,\n            4.0965e-01, -7.5031e-02],\n          [-4.4716e-02, -6.6199e-01, -9.2861e-01,  ...,  5.9766e-01,\n            2.3181e-01, -2.1284e-01],\n          ...,\n          [ 9.3537e-01,  2.7058e-01,  1.1165e+00,  ..., -6.2206e-01,\n            2.9264e-01,  1.3320e+00],\n          [ 7.5008e-01,  1.0221e+00, -3.0354e-02,  ...,  1.3531e-01,\n            1.1982e+00,  1.2875e-02],\n          [-1.1730e+00, -6.0364e-01,  1.8613e-01,  ...,  4.8842e-01,\n           -8.2276e-02,  3.5773e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.5168,  0.5003, -0.8527,  ..., -1.0179, -1.3143,  0.2035],\n          [ 0.5839,  0.4706, -0.0539,  ...,  0.7804, -0.5336, -0.4840],\n          [ 0.6194, -0.1866,  0.5777,  ...,  1.4978, -0.3987, -1.0123],\n          ...,\n          [ 1.3470,  0.3720, -0.5412,  ...,  1.6907, -0.3261, -0.6066],\n          [ 1.6338, -0.9301,  0.1403,  ...,  1.6979,  0.9465, -1.1397],\n          [ 1.0263, -0.0312,  0.4805,  ...,  1.9947, -0.4926, -1.0369]],\n\n         [[ 0.8600, -2.0708,  0.1513,  ...,  0.2453, -2.4785, -0.4229],\n          [ 1.3937, -0.5899,  1.3122,  ...,  1.7829, -0.9209,  0.0461],\n          [ 1.2642,  1.6078,  0.4370,  ...,  0.8510,  0.5742, -0.4311],\n          ...,\n          [-0.2522,  3.1486, -0.0085,  ...,  0.1856,  3.6584, -0.8100],\n          [ 0.7939,  1.4203,  0.2039,  ...,  0.5636,  2.3544, -1.3126],\n          [ 0.5796,  1.1935, -0.4128,  ..., -0.0242,  2.9575, -1.5629]],\n\n         [[ 1.0033,  0.3818, -0.1770,  ..., -0.8112, -1.4041, -0.3646],\n          [-0.8060, -0.2143, -1.7062,  ...,  1.3577, -0.0913,  0.3456],\n          [-0.1113, -0.4196, -1.3489,  ...,  1.2174,  0.0079,  0.0536],\n          ...,\n          [-3.3497, -0.2660,  0.2152,  ...,  1.4347,  0.1310,  1.4777],\n          [-1.0710, -0.9403, -2.2382,  ...,  1.8840, -0.8573,  0.6312],\n          [ 0.1759, -0.5456, -0.7188,  ...,  1.3544, -0.2407, -0.2945]],\n\n         ...,\n\n         [[ 0.2209, -0.5819,  0.4830,  ..., -0.6500,  1.0846,  0.2841],\n          [-0.4176, -0.2444, -0.1033,  ..., -1.9155, -1.5817,  0.6707],\n          [-1.1385,  1.7267, -2.5488,  ..., -2.3843, -1.3253,  0.6908],\n          ...,\n          [-1.5273,  1.4584, -2.7749,  ..., -1.0319, -2.3548,  1.2913],\n          [-0.4061,  2.5040, -2.4008,  ..., -1.3577, -1.8418,  1.6940],\n          [-0.3213,  0.4250, -1.2700,  ..., -3.8195, -0.4979,  1.6445]],\n\n         [[ 0.2557,  0.5515,  0.5423,  ...,  0.7245,  0.0758,  0.8386],\n          [ 0.0373,  1.1293, -0.8812,  ...,  1.3053,  0.1991,  1.0668],\n          [ 0.1955,  1.5928, -0.9004,  ...,  0.8965, -0.3034, -0.3748],\n          ...,\n          [-0.0899,  2.2438, -0.5928,  ...,  0.3604, -1.3797, -0.0256],\n          [ 1.0178,  2.0922, -0.1509,  ...,  1.3384, -1.0962, -0.1963],\n          [ 1.6399,  1.9349,  1.2059,  ..., -0.5345, -1.0859,  0.4052]],\n\n         [[-0.7103,  0.3011, -1.5822,  ..., -0.4242,  0.2360, -1.3157],\n          [ 0.0054,  1.0721,  1.2615,  ...,  0.6028, -0.2910,  0.4983],\n          [-0.3964,  0.6106, -0.1719,  ...,  1.1167, -0.9742,  1.4335],\n          ...,\n          [ 1.7506,  0.9744,  1.3645,  ...,  1.5455,  0.3070,  1.9734],\n          [-0.9912,  0.5391,  1.5399,  ...,  0.9224,  0.0180,  3.2051],\n          [-0.3301,  0.1262,  2.0273,  ...,  2.3883,  0.8853, -0.5951]]]],\n       grad_fn=<PermuteBackward0>), tensor([[[[-6.0670e-03,  4.1580e-02, -6.0121e-02,  ...,  5.8650e-02,\n           -5.0545e-02, -7.4066e-02],\n          [-1.3468e+00,  1.2899e-01,  1.0814e+00,  ..., -3.7751e-01,\n           -3.3316e-01, -2.1959e-01],\n          [-5.5962e-01,  5.0996e-01,  1.2739e+00,  ..., -3.0219e-01,\n            1.1735e-01,  8.0562e-01],\n          ...,\n          [ 4.0354e-01, -1.3779e+00, -1.7089e-01,  ..., -7.0931e-01,\n           -1.5366e+00,  4.9889e-01],\n          [-1.0464e-01,  6.3719e-01,  1.1747e+00,  ...,  3.1930e-01,\n           -1.4733e+00,  2.9720e-01],\n          [ 4.8980e-01, -3.8612e-02,  1.0899e+00,  ...,  3.5262e-01,\n           -1.5532e+00, -7.8569e-01]],\n\n         [[ 5.0298e-02, -3.1197e-03,  2.3202e-02,  ..., -2.5890e-02,\n           -1.5499e-02, -2.3228e-02],\n          [-1.0113e+00,  5.7627e-01,  4.9574e-01,  ..., -3.2675e-01,\n            1.8656e-01,  8.2123e-01],\n          [ 1.4849e-01,  7.7403e-01, -1.0155e+00,  ...,  3.1667e-01,\n           -1.8597e-01,  4.8591e-01],\n          ...,\n          [-1.2798e-01, -5.1137e-01,  1.0950e+00,  ...,  3.6580e+00,\n            2.7943e-02, -6.0400e-01],\n          [ 5.0271e-01, -1.6136e+00, -1.8023e-01,  ..., -5.1401e-02,\n            9.7688e-01, -1.7705e-01],\n          [-5.7576e-01,  2.3451e-01, -5.6929e-02,  ...,  1.7267e-01,\n            5.6935e-02,  1.5519e+00]],\n\n         [[-2.1214e-02,  3.3352e-02, -8.7513e-02,  ..., -8.9315e-03,\n            3.0822e-02,  3.8786e-02],\n          [-5.2402e-01, -2.6212e-01, -2.3345e-01,  ...,  3.4806e-01,\n            1.7069e-01, -2.4730e-04],\n          [-4.9385e-01,  4.8865e-01, -4.3231e-01,  ...,  7.6064e-01,\n           -2.9905e-02,  1.8609e-01],\n          ...,\n          [-1.5463e-01,  3.1104e+00, -7.4308e-01,  ..., -2.0623e-01,\n           -7.7929e-01,  9.4195e-01],\n          [-7.9531e-01,  1.3734e+00, -4.3311e-01,  ..., -4.4867e-01,\n            1.8048e-01,  6.7478e-02],\n          [-7.1460e-01,  5.9888e-01,  1.0618e+00,  ...,  5.3553e-01,\n           -7.6815e-01, -2.0368e-02]],\n\n         ...,\n\n         [[-1.0483e-01,  3.7457e-02, -1.1568e-03,  ..., -4.4699e-02,\n           -8.8917e-03,  1.7837e-02],\n          [ 8.6269e-01, -1.4697e-01,  3.6745e-01,  ...,  3.1546e-01,\n            3.5175e-02, -3.0443e-01],\n          [ 5.1551e-01,  2.5198e-01,  1.5730e-01,  ...,  1.4892e+00,\n           -5.0922e-01,  2.0167e+00],\n          ...,\n          [-8.4730e-01, -4.3078e-01,  5.2054e-01,  ..., -9.0683e-02,\n            2.3514e-01, -9.9465e-02],\n          [-6.5804e-01, -7.2872e-01, -3.5987e-02,  ...,  1.0228e+00,\n           -7.1774e-01,  9.4541e-01],\n          [-8.0607e-01, -7.0931e-01,  7.0981e-01,  ...,  9.3562e-02,\n           -8.5871e-01,  1.3432e-01]],\n\n         [[ 9.2671e-02,  1.3452e-02,  5.3226e-02,  ...,  3.1511e-03,\n            4.3145e-02,  1.1899e-02],\n          [-1.5642e-01,  1.9026e-01,  7.6595e-01,  ..., -1.3407e-01,\n            2.6676e-01, -5.0297e-01],\n          [ 6.1654e-01,  8.3766e-01,  1.0002e+00,  ...,  1.2987e-01,\n            1.4224e+00, -4.2693e-01],\n          ...,\n          [-3.0885e-02,  1.5424e+00,  6.3994e-01,  ..., -7.0803e-01,\n            2.7368e+00,  1.4347e+00],\n          [ 1.9046e-01,  2.8000e+00, -1.0230e+00,  ..., -9.5442e-02,\n            6.7177e-01,  5.6662e-02],\n          [-2.2475e-01,  9.7459e-01,  2.7916e+00,  ..., -2.6345e-01,\n            6.6847e-01, -1.8378e+00]],\n\n         [[-1.0774e-01,  2.8406e-02, -5.5795e-02,  ..., -8.4050e-02,\n            6.1122e-02, -6.3834e-03],\n          [ 2.9483e-01, -4.6036e-01, -5.0067e-01,  ..., -4.2501e-01,\n            1.4048e+00,  3.5767e-02],\n          [-7.1402e-01, -6.3282e-01, -6.3516e-01,  ..., -1.0530e+00,\n            4.5487e-01, -1.2223e+00],\n          ...,\n          [-3.1073e-01, -1.3114e-01,  6.1908e-01,  ..., -1.1282e+00,\n            9.6892e-01,  1.1984e-01],\n          [-9.2515e-01,  1.1405e-01,  1.4297e-01,  ...,  2.4874e-01,\n           -2.8436e-01,  3.1334e-01],\n          [-4.7070e-01, -2.1283e-01,  1.8143e-01,  ..., -6.6503e-01,\n           -9.3208e-01,  8.6368e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-1.7151, -0.3351, -0.2937,  ...,  0.1779,  0.3182, -0.4845],\n          [-0.0573, -0.2968, -0.2792,  ...,  1.8097, -0.9933, -0.0485],\n          [ 0.4551,  0.2350, -0.5202,  ...,  1.4073, -1.1556, -0.5031],\n          ...,\n          [ 0.4398,  0.2872, -1.3292,  ...,  1.0791, -0.5067, -0.6926],\n          [ 1.4281,  0.7992, -0.5960,  ...,  0.2981, -0.7968, -0.0723],\n          [ 1.4787,  0.0107, -0.4716,  ...,  0.5184, -2.1060, -0.5924]],\n\n         [[ 0.1182, -0.0641,  2.3043,  ...,  0.2435,  0.0934, -0.1985],\n          [ 0.3078, -0.7078, -0.0229,  ..., -0.1684,  0.3255,  0.4997],\n          [-0.0072, -1.4351, -0.3262,  ..., -0.0116, -0.4237, -1.0236],\n          ...,\n          [ 0.0789,  1.0277, -0.1959,  ..., -0.3314, -0.0123,  0.1554],\n          [-0.1221, -0.4109, -0.2510,  ..., -0.1642,  0.4183, -1.1042],\n          [ 0.3249, -0.0160, -1.2672,  ...,  0.3571,  0.7415, -0.0222]],\n\n         [[-0.1897,  1.0560,  0.4685,  ..., -0.5601,  0.3216, -0.1095],\n          [-1.2898,  0.1961,  0.3851,  ...,  0.0611, -0.4468, -0.4500],\n          [-1.2418, -0.5390, -0.3550,  ...,  1.1175,  0.2285, -0.6764],\n          ...,\n          [-1.7289, -1.8670, -0.2395,  ...,  0.8597,  0.1823,  0.1264],\n          [-1.4579, -1.1564,  0.1421,  ...,  1.1056, -0.7289, -0.9327],\n          [-0.5909,  0.2044, -0.4299,  ...,  1.1715,  0.5954, -0.7546]],\n\n         ...,\n\n         [[ 0.5702,  0.9629, -0.8822,  ..., -0.7408,  0.6916,  0.8577],\n          [ 1.1006,  1.7073, -1.6259,  ..., -0.9801, -0.5523,  0.2173],\n          [ 0.6847,  1.8472, -0.7955,  ..., -0.5540, -0.5932,  0.3027],\n          ...,\n          [-1.6889,  0.1444,  0.2351,  ..., -0.8126, -1.4681, -0.2635],\n          [ 0.2845,  1.1499, -0.4750,  ..., -0.8172, -0.8146,  0.3588],\n          [ 0.0874, -0.2214, -0.0856,  ..., -0.7394, -1.2066,  0.1715]],\n\n         [[-0.4207,  0.3802,  0.3173,  ...,  0.7072,  0.0623, -0.0753],\n          [-0.9885,  1.0626, -0.9565,  ..., -0.0961, -0.5346, -1.2537],\n          [-0.8144,  1.0409, -0.3393,  ...,  0.7575, -0.7873, -0.3033],\n          ...,\n          [ 0.7162,  0.5353,  0.5786,  ...,  1.2553, -0.3931,  0.5719],\n          [-0.4955,  0.3584, -0.4676,  ...,  0.7423, -0.1553,  0.4724],\n          [-1.1989,  0.5740, -1.4242,  ..., -0.1654, -0.2418, -1.2209]],\n\n         [[-0.7356, -0.0250,  0.4452,  ..., -0.0942,  0.0330, -0.0571],\n          [ 0.1039, -0.4520,  1.6473,  ...,  0.0384, -0.3122,  0.2989],\n          [ 0.0984, -1.1736,  1.5161,  ...,  0.2563, -0.7524, -0.1577],\n          ...,\n          [ 0.3700,  0.0524,  0.3323,  ..., -0.1997, -1.8872,  0.6791],\n          [ 0.1144, -0.8560,  1.3444,  ..., -0.9688, -0.0111,  0.6124],\n          [ 0.3719, -1.1888,  2.9866,  ...,  1.5564,  1.0569,  1.0004]]]],\n       grad_fn=<PermuteBackward0>), tensor([[[[ 0.0627, -0.1041, -0.1861,  ..., -0.2973,  0.2617, -0.1300],\n          [ 0.9190, -0.4094,  0.9732,  ...,  0.7065, -1.3206,  1.6103],\n          [-0.3314,  0.7099,  0.8130,  ...,  1.2446, -1.0029,  1.6824],\n          ...,\n          [ 0.3073, -0.1798,  2.0175,  ...,  3.8588, -1.2389,  0.9518],\n          [-1.0282,  0.0810,  1.8490,  ...,  2.1276, -0.6254,  0.2580],\n          [-2.1301,  0.1848,  0.6389,  ...,  0.8497, -2.1894,  2.4372]],\n\n         [[ 0.0701, -0.0366,  0.0433,  ..., -0.0205, -0.1226,  0.1881],\n          [-0.4828,  0.0397,  0.1133,  ...,  0.6646, -0.4122, -0.4976],\n          [-0.0560,  0.5185, -0.3796,  ..., -0.0358, -1.7324, -0.5987],\n          ...,\n          [ 0.3621, -1.0770,  0.8416,  ..., -1.0863, -1.4621,  1.3165],\n          [-0.4170, -0.1856, -0.2208,  ...,  0.6679,  0.2648, -0.7330],\n          [ 0.9327,  0.1231, -0.2568,  ...,  0.0206, -0.5632, -0.0348]],\n\n         [[ 0.0102,  0.0407, -0.0427,  ...,  0.0176,  0.0324,  0.0545],\n          [-0.8474, -0.1339,  0.6198,  ..., -1.1320, -0.1028,  0.0237],\n          [-0.3179,  0.2617, -0.2293,  ..., -0.3102, -0.2109,  0.9155],\n          ...,\n          [-1.1459,  0.6247, -0.4677,  ...,  0.4716,  0.2258,  1.9537],\n          [ 0.3159, -0.4951,  0.3948,  ...,  0.0583,  0.3305,  2.0492],\n          [ 0.5957, -0.2422, -0.1601,  ...,  0.0871,  0.6242,  0.0631]],\n\n         ...,\n\n         [[-0.0194, -0.0276,  0.0886,  ...,  0.0796, -0.0209,  0.0248],\n          [-0.7218,  0.9741,  0.7868,  ..., -0.1377, -0.3252, -1.0529],\n          [ 0.0102,  0.0130,  0.1943,  ...,  1.0051,  0.9481, -0.4571],\n          ...,\n          [-1.2697,  1.1965,  1.8222,  ...,  1.2815,  1.1525, -0.2608],\n          [-0.9059, -0.1876, -0.2131,  ...,  0.1001,  0.5176, -0.7554],\n          [-0.2481,  0.0416, -0.7926,  ...,  0.2645, -0.6107, -0.3649]],\n\n         [[-0.1515, -0.0920,  0.0492,  ..., -0.0616,  0.0336, -0.0914],\n          [ 0.1947,  0.3574,  0.4865,  ..., -0.0827, -0.0695,  0.1024],\n          [ 0.0617, -0.4696,  0.1419,  ..., -0.5913, -0.3143,  0.7776],\n          ...,\n          [-0.4784,  1.0185, -0.0705,  ...,  0.2748, -0.4973,  1.3698],\n          [-0.8326,  0.6881,  0.1242,  ..., -0.5708,  0.6708,  0.8386],\n          [-1.0543, -0.0815,  0.9794,  ...,  0.3561,  0.6065,  0.8012]],\n\n         [[ 0.1127, -0.1414,  0.0995,  ..., -0.1078,  0.0248, -0.1947],\n          [ 0.3453, -0.7535,  0.9195,  ...,  0.1146, -0.0401,  0.5830],\n          [-0.6160, -0.7786,  1.2499,  ..., -1.0763,  0.0126, -0.6472],\n          ...,\n          [-1.0815,  0.2212,  0.6810,  ..., -1.4694, -0.5813,  0.5124],\n          [-0.5673, -0.7975, -0.1831,  ...,  0.2839,  0.3034,  0.0535],\n          [-0.9700,  0.6699, -0.1582,  ...,  0.8679, -0.3234,  1.0039]]]],\n       grad_fn=<PermuteBackward0>))), hidden_states=None, attentions=None, cross_attentions=None)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:22:24.122699122Z",
     "start_time": "2023-12-06T09:22:23.971137146Z"
    }
   },
   "id": "70fadb02d258c59b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "torch_device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id, device_map='auto').to(torch_device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:24:53.159479936Z",
     "start_time": "2023-12-06T09:24:51.848739889Z"
    }
   },
   "id": "61c2a9f8e739d76f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:24:53.665758285Z",
     "start_time": "2023-12-06T09:24:53.663149809Z"
    }
   },
   "id": "ecab418e48bc50e6"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)rocessor_config.json: 100%|██| 47.7k/47.7k [00:00<00:00, 441kB/s]\n",
      "/home/aizdebski/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/transformers/models/imagegpt/feature_extraction_imagegpt.py:28: FutureWarning: The class ImageGPTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ImageGPTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Downloading config.json: 100%|█████████████████| 511/511 [00:00<00:00, 3.58MB/s]\n",
      "Downloading pytorch_model.bin: 100%|███████| 1.86G/1.86G [00:44<00:00, 41.8MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "ImageGPTForCausalImageModeling(\n  (transformer): ImageGPTModel(\n    (wte): Embedding(513, 1024)\n    (wpe): Embedding(1024, 1024)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-35): 36 x ImageGPTBlock(\n        (ln_1): ImageGPTLayerNorm()\n        (attn): ImageGPTAttention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): ImageGPTLayerNorm()\n        (mlp): ImageGPTMLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): QuickGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): ImageGPTLayerNorm()\n  )\n  (lm_head): Linear(in_features=1024, out_features=512, bias=False)\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ImageGPTFeatureExtractor, ImageGPTForCausalImageModeling\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "feature_extractor = ImageGPTFeatureExtractor.from_pretrained('openai/imagegpt-medium')\n",
    "model = ImageGPTForCausalImageModeling.from_pretrained('openai/imagegpt-medium')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:27:33.164724909Z",
     "start_time": "2023-12-06T09:26:42.346690415Z"
    }
   },
   "id": "635eeba51cf26978"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1153052/2127122845.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  context = torch.tensor(context).to(device)\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (1024). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "context = torch.full((batch_size, 1), model.config.vocab_size - 1) #initialize with SOS token (with ID 512)\n",
    "context = torch.tensor(context).to(device)\n",
    "output = model.generate(input_ids=context, max_length=model.config.n_positions + 1, temperature=1.0, do_sample=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:30:14.527982102Z",
     "start_time": "2023-12-06T09:28:30.876556084Z"
    }
   },
   "id": "4f2bbc9bb95a24d3"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1920x1440 with 8 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize samples with Image-GPT color palette.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "clusters = feature_extractor.clusters\n",
    "n_px = feature_extractor.size\n",
    "\n",
    "samples = output[:,1:].cpu().detach().numpy()\n",
    "samples_img = [np.reshape(np.rint(127.5 * (clusters[s] + 1.0)), [32, 32, 3]).astype(np.uint8) for s in samples] # convert color cluster tokens back to pixels\n",
    "f, axes = plt.subplots(1, batch_size, dpi=300)\n",
    "\n",
    "for img, ax in zip(samples_img, axes):\n",
    "    ax.axis('off')\n",
    "    ax.imshow(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:30:31.439256264Z",
     "start_time": "2023-12-06T09:30:31.100783323Z"
    }
   },
   "id": "660c14d99fdb226c"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 3.61k/3.61k [00:00<00:00, 21.3MB/s]\n",
      "Downloading metadata: 100%|████████████████| 1.66k/1.66k [00:00<00:00, 11.0MB/s]\n",
      "Downloading readme: 100%|██████████████████| 5.00k/5.00k [00:00<00:00, 14.5MB/s]\n",
      "Downloading data: 100%|██████████████████████| 170M/170M [00:08<00:00, 19.0MB/s]\n",
      "Generating train split:   0%|                  | 0/50000 [00:00<?, ? examples/s]/home/aizdebski/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/datasets/features/image.py:332: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "Generating train split: 100%|████| 50000/50000 [00:09<00:00, 5215.51 examples/s]\n",
      "Generating test split: 100%|█████| 10000/10000 [00:02<00:00, 4034.92 examples/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Loading a dataset cached in a LocalFileSystem is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dataset\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# load cifar10 (only small portion for demonstration purposes) \u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m train_ds, test_ds \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcifar10\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain[:5000]\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest[:2000]\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# split up training into training + validation\u001B[39;00m\n\u001B[1;32m      6\u001B[0m splits \u001B[38;5;241m=\u001B[39m train_ds\u001B[38;5;241m.\u001B[39mtrain_test_split(test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n",
      "File \u001B[0;32m~/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/datasets/load.py:2149\u001B[0m, in \u001B[0;36mload_dataset\u001B[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001B[0m\n\u001B[1;32m   2145\u001B[0m \u001B[38;5;66;03m# Build dataset for splits\u001B[39;00m\n\u001B[1;32m   2146\u001B[0m keep_in_memory \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   2147\u001B[0m     keep_in_memory \u001B[38;5;28;01mif\u001B[39;00m keep_in_memory \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m is_small_dataset(builder_instance\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mdataset_size)\n\u001B[1;32m   2148\u001B[0m )\n\u001B[0;32m-> 2149\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[43mbuilder_instance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverification_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverification_mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43min_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_memory\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2150\u001B[0m \u001B[38;5;66;03m# Rename and cast features to match task schema\u001B[39;00m\n\u001B[1;32m   2151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2152\u001B[0m     \u001B[38;5;66;03m# To avoid issuing the same warning twice\u001B[39;00m\n",
      "File \u001B[0;32m~/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/datasets/builder.py:1173\u001B[0m, in \u001B[0;36mDatasetBuilder.as_dataset\u001B[0;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001B[0m\n\u001B[1;32m   1171\u001B[0m is_local \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m is_remote_filesystem(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fs)\n\u001B[1;32m   1172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_local:\n\u001B[0;32m-> 1173\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading a dataset cached in a \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fs)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_dir):\n\u001B[1;32m   1175\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[1;32m   1176\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: could not find data in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Please make sure to call \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1177\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbuilder.download_and_prepare(), or use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1178\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatasets.load_dataset() before trying to access the Dataset object.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1179\u001B[0m     )\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: Loading a dataset cached in a LocalFileSystem is not supported."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load cifar10 (only small portion for demonstration purposes) \n",
    "train_ds, test_ds = load_dataset('cifar10', split=['train[:5000]', 'test[:2000]'])\n",
    "# split up training into training + validation\n",
    "splits = train_ds.train_test_split(test_size=0.1)\n",
    "train_ds = splits['train']\n",
    "val_ds = splits['test']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:36:21.209021211Z",
     "start_time": "2023-12-06T09:35:57.127858841Z"
    }
   },
   "id": "8acc55531195c8d8"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import torchvision"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:37:50.261335544Z",
     "start_time": "2023-12-06T09:37:50.220336837Z"
    }
   },
   "id": "6a0c48de2f8838ea"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to datasets/cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 170498071/170498071 [00:06<00:00, 26570299.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/cifar10/cifar-10-python.tar.gz to datasets/cifar10/\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(root='datasets/cifar10/', download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:39:03.223170150Z",
     "start_time": "2023-12-06T09:38:54.735220186Z"
    }
   },
   "id": "7e4061c7029e9fc1"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(<PIL.Image.Image image mode=RGB size=32x32>, 6)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:39:07.771603604Z",
     "start_time": "2023-12-06T09:39:07.769875423Z"
    }
   },
   "id": "6fa8dadd8399d822"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cifar10\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:56:34.299891676Z",
     "start_time": "2023-12-06T09:56:32.924208645Z"
    }
   },
   "id": "1039e3ea96ccbf3d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "image = dataset['train'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:56:36.216633667Z",
     "start_time": "2023-12-06T09:56:36.177038435Z"
    }
   },
   "id": "fec4e8c3015945c8"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "permute",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(\u001B[43mimage\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimg\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpermute\u001B[49m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[0;32m~/micromamba/envs/hybrid-transformer/lib/python3.11/site-packages/PIL/Image.py:529\u001B[0m, in \u001B[0;36mImage.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    527\u001B[0m     deprecate(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage categories\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m10\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_animated\u001B[39m\u001B[38;5;124m\"\u001B[39m, plural\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    528\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_category\n\u001B[0;32m--> 529\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(name)\n",
      "\u001B[0;31mAttributeError\u001B[0m: permute"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(image['img'].permute(1, 2, 0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:46:19.134833916Z",
     "start_time": "2023-12-06T09:46:19.033310981Z"
    }
   },
   "id": "2fe8af152045d33e"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>",
      "image/png": "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"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image['img']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:46:26.373783432Z",
     "start_time": "2023-12-06T09:46:26.324754168Z"
    }
   },
   "id": "a39e1af09cc8daf2"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (1024). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1920x1440 with 4 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, ImageGPTForCausalImageModeling\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"openai/imagegpt-small\")\n",
    "model = ImageGPTForCausalImageModeling.from_pretrained(\"openai/imagegpt-small\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# unconditional generation of 8 images\n",
    "batch_size = 4\n",
    "context = torch.full((batch_size, 1), model.config.vocab_size - 1)  # initialize with SOS token\n",
    "context = context.to(device)\n",
    "output = model.generate(\n",
    "    input_ids=context, max_length=model.config.n_positions + 1, temperature=1.0, do_sample=True, top_k=40\n",
    ")\n",
    "\n",
    "clusters = image_processor.clusters\n",
    "height = image_processor.size[\"height\"]\n",
    "width = image_processor.size[\"width\"]\n",
    "\n",
    "samples = output[:, 1:].cpu().detach().numpy()\n",
    "samples_img = [\n",
    "    np.reshape(np.rint(127.5 * (clusters[s] + 1.0)), [height, width, 3]).astype(np.uint8) for s in samples\n",
    "]  # convert color cluster tokens back to pixels\n",
    "f, axes = plt.subplots(1, batch_size, dpi=300)\n",
    "\n",
    "for img, ax in zip(samples_img, axes):\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T11:00:41.891949085Z",
     "start_time": "2023-12-06T10:59:35.615357300Z"
    }
   },
   "id": "7e3b7a4c907dd50"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "(32, 32, 3)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_img[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T11:01:47.605535284Z",
     "start_time": "2023-12-06T11:01:47.587653070Z"
    }
   },
   "id": "940563d7d85ae0c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, ImageGPTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"openai/imagegpt-small\")\n",
    "model = ImageGPTForImageClassification.from_pretrained(\"openai/imagegpt-small\")\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "393659cf30a7828b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "ImageGPTImageProcessor {\n  \"clusters\": [\n    [\n      0.8866443634033203,\n      0.6618829369544983,\n      0.3891746401786804\n    ],\n    [\n      -0.6042559146881104,\n      -0.02295008860528469,\n      0.5423797369003296\n    ],\n    [\n      0.12942790985107422,\n      0.03570118546485901,\n      -0.3643915355205536\n    ],\n    [\n      -0.3553103804588318,\n      -0.15857496857643127,\n      -0.664303183555603\n    ],\n    [\n      0.7844981551170349,\n      -0.2559399902820587,\n      -0.7189618945121765\n    ],\n    [\n      0.1935412883758545,\n      0.23239648342132568,\n      0.08234082162380219\n    ],\n    [\n      -0.9012048840522766,\n      -0.7926875352859497,\n      -0.9216221570968628\n    ],\n    [\n      -0.013770446181297302,\n      -0.8677454590797424,\n      -0.8910260796546936\n    ],\n    [\n      -0.8732763528823853,\n      -0.5560516715049744,\n      -0.686274528503418\n    ],\n    [\n      -0.3679597079753876,\n      -0.4616401493549347,\n      -0.8443512916564941\n    ],\n    [\n      -0.17434515058994293,\n      -0.35372495651245117,\n      -0.5616933107376099\n    ],\n    [\n      0.7205567955970764,\n      0.6045222282409668,\n      0.527334988117218\n    ],\n    [\n      -0.05053819343447685,\n      0.1381247639656067,\n      -0.1910051703453064\n    ],\n    [\n      0.53249192237854,\n      0.21986378729343414,\n      -0.1370566189289093\n    ],\n    [\n      -0.5499509572982788,\n      0.6311273574829102,\n      0.8301469683647156\n    ],\n    [\n      -0.0623948909342289,\n      -0.10504596680402756,\n      -0.2894057631492615\n    ],\n    [\n      0.8541644215583801,\n      0.4792228937149048,\n      0.07953768968582153\n    ],\n    [\n      -0.4161697328090668,\n      -0.5115739703178406,\n      -0.43697986006736755\n    ],\n    [\n      0.9533290266990662,\n      0.9274855852127075,\n      0.5679895877838135\n    ],\n    [\n      -0.7291542291641235,\n      -0.628097653388977,\n      -0.7699974775314331\n    ],\n    [\n      0.5313871502876282,\n      0.26622718572616577,\n      0.2107263058423996\n    ],\n    [\n      0.02250233106315136,\n      -0.1575583517551422,\n      -0.09264706820249557\n    ],\n    [\n      -0.16142235696315765,\n      0.0030967944767326117,\n      0.680765688419342\n    ],\n    [\n      -0.0008921666303649545,\n      -0.047903429716825485,\n      -0.11226630955934525\n    ],\n    [\n      -0.10056599974632263,\n      -0.6199851632118225,\n      -0.5905289649963379\n    ],\n    [\n      0.36189737915992737,\n      -0.5128692984580994,\n      -0.5751007199287415\n    ],\n    [\n      -0.5218700766563416,\n      -0.35565218329429626,\n      -0.6801741719245911\n    ],\n    [\n      -0.004487038590013981,\n      0.0499449297785759,\n      -0.34433433413505554\n    ],\n    [\n      0.3216712176799774,\n      0.2629038691520691,\n      0.09036855399608612\n    ],\n    [\n      0.27530282735824585,\n      0.40375596284866333,\n      -0.4079127311706543\n    ],\n    [\n      -0.4074484705924988,\n      -0.26290711760520935,\n      -0.33841392397880554\n    ],\n    [\n      0.7986500859260559,\n      0.7467415928840637,\n      0.647467315196991\n    ],\n    [\n      -0.16817767918109894,\n      0.4910394251346588,\n      0.15420623123645782\n    ],\n    [\n      -0.21436354517936707,\n      0.023510200902819633,\n      0.43241268396377563\n    ],\n    [\n      -0.40356260538101196,\n      -0.5356048941612244,\n      -0.5896926522254944\n    ],\n    [\n      0.3242187798023224,\n      0.08525704592466354,\n      -0.19164560735225677\n    ],\n    [\n      -0.32216736674308777,\n      -0.4917454123497009,\n      -0.6309071779251099\n    ],\n    [\n      -0.38158607482910156,\n      -0.5385871529579163,\n      -0.7054222822189331\n    ],\n    [\n      -0.24477025866508484,\n      0.07710830122232437,\n      -0.21819734573364258\n    ],\n    [\n      -0.4544757604598999,\n      -0.28715264797210693,\n      0.19457608461380005\n    ],\n    [\n      0.3922958970069885,\n      -0.04505942016839981,\n      -0.46043047308921814\n    ],\n    [\n      -0.6633502840995789,\n      -0.4843274652957916,\n      -0.24858099222183228\n    ],\n    [\n      0.3302103877067566,\n      0.5696513056755066,\n      0.10619977116584778\n    ],\n    [\n      -0.1213420107960701,\n      -0.1513548493385315,\n      -0.7746183276176453\n    ],\n    [\n      0.02183908224105835,\n      -0.29862523078918457,\n      -0.5074599981307983\n    ],\n    [\n      -0.8835203051567078,\n      -0.7302054762840271,\n      0.30284789204597473\n    ],\n    [\n      -0.410575807094574,\n      -0.10831455886363983,\n      0.28231197595596313\n    ],\n    [\n      -0.0038531296886503696,\n      -0.3962152898311615,\n      -0.7741573452949524\n    ],\n    [\n      0.34942829608917236,\n      0.350960910320282,\n      0.3488500118255615\n    ],\n    [\n      -0.39364781975746155,\n      0.03495653346180916,\n      -0.3540157973766327\n    ],\n    [\n      -0.07268346846103668,\n      0.029805386438965797,\n      0.30300232768058777\n    ],\n    [\n      -0.855398416519165,\n      -0.5722979307174683,\n      -0.19805879890918732\n    ],\n    [\n      -0.26683011651039124,\n      -0.27701082825660706,\n      -0.2609962224960327\n    ],\n    [\n      -0.3457053005695343,\n      0.2817457616329193,\n      -0.5590637922286987\n    ],\n    [\n      -0.6952950954437256,\n      -0.5743372440338135,\n      -0.6705573201179504\n    ],\n    [\n      0.523847758769989,\n      0.32931753993034363,\n      -0.029757514595985413\n    ],\n    [\n      0.4000224769115448,\n      0.252950519323349,\n      -0.07705940306186676\n    ],\n    [\n      -0.21261973679065704,\n      -0.1472283899784088,\n      0.2760908603668213\n    ],\n    [\n      -0.5430170893669128,\n      -0.3718504011631012,\n      0.012515963986515999\n    ],\n    [\n      -0.92361980676651,\n      -0.9171434640884399,\n      -0.9339240193367004\n    ],\n    [\n      -0.17573337256908417,\n      -0.1685536950826645,\n      -0.33348602056503296\n    ],\n    [\n      -0.30869874358177185,\n      -0.3544236123561859,\n      -0.1135273203253746\n    ],\n    [\n      -0.5163084268569946,\n      0.05249231308698654,\n      -0.7978107333183289\n    ],\n    [\n      -0.1575734168291092,\n      -0.26073628664016724,\n      -0.29685407876968384\n    ],\n    [\n      -0.07752817869186401,\n      -0.10982697457075119,\n      0.06651923060417175\n    ],\n    [\n      -0.5863983631134033,\n      -0.16673429310321808,\n      -0.3866238296031952\n    ],\n    [\n      -0.28994566202163696,\n      -0.20120011270046234,\n      0.05026695132255554\n    ],\n    [\n      -0.793811023235321,\n      -0.2712944746017456,\n      0.7479417324066162\n    ],\n    [\n      -0.4872121810913086,\n      0.26298385858535767,\n      0.6379027366638184\n    ],\n    [\n      0.10957116633653641,\n      -0.028541117906570435,\n      0.10372563451528549\n    ],\n    [\n      -0.4547993242740631,\n      -0.4405229091644287,\n      -0.47519412636756897\n    ],\n    [\n      -0.9882778525352478,\n      -0.9892479777336121,\n      -0.9887582063674927\n    ],\n    [\n      0.8967511057853699,\n      0.8172797560691833,\n      -0.00848731491714716\n    ],\n    [\n      0.8169391751289368,\n      0.20236308872699738,\n      0.22856123745441437\n    ],\n    [\n      0.9754669666290283,\n      0.9802407026290894,\n      0.9766666293144226\n    ],\n    [\n      -0.9453840255737305,\n      -0.9282575845718384,\n      -0.8594306707382202\n    ],\n    [\n      -0.9195259809494019,\n      -0.8593184947967529,\n      -0.7556572556495667\n    ],\n    [\n      -0.8385721445083618,\n      -0.190311461687088,\n      -0.11632368713617325\n    ],\n    [\n      -0.43058156967163086,\n      -0.22221753001213074,\n      -0.5097092986106873\n    ],\n    [\n      -0.22450797259807587,\n      -0.06987760215997696,\n      0.10926814377307892\n    ],\n    [\n      -0.9219630360603333,\n      -0.8413735628128052,\n      -0.6118304133415222\n    ],\n    [\n      0.9968767166137695,\n      0.9970247745513916,\n      0.9967049956321716\n    ],\n    [\n      0.205012708902359,\n      -0.4318155348300934,\n      -0.8442745208740234\n    ],\n    [\n      -0.09030798822641373,\n      -0.34330934286117554,\n      -0.47994205355644226\n    ],\n    [\n      0.9550600647926331,\n      0.9519978761672974,\n      0.9411756992340088\n    ],\n    [\n      0.13809911906719208,\n      -0.21429237723350525,\n      -0.5639499425888062\n    ],\n    [\n      -0.2655453383922577,\n      -0.36435338854789734,\n      -0.5013294816017151\n    ],\n    [\n      0.16679424047470093,\n      0.167513906955719,\n      0.15711624920368195\n    ],\n    [\n      -0.36666491627693176,\n      -0.685397744178772,\n      -0.8884972333908081\n    ],\n    [\n      -0.5366653800010681,\n      -0.5366100668907166,\n      -0.5332698225975037\n    ],\n    [\n      -0.00972462072968483,\n      0.12029983103275299,\n      0.48295629024505615\n    ],\n    [\n      0.2542765140533447,\n      0.2748924493789673,\n      -0.032631732523441315\n    ],\n    [\n      -0.5462303757667542,\n      -0.525596559047699,\n      -0.8729211688041687\n    ],\n    [\n      0.5557466149330139,\n      0.058265406638383865,\n      0.15023870766162872\n    ],\n    [\n      0.0680597722530365,\n      0.026245953515172005,\n      -0.5551841259002686\n    ],\n    [\n      0.6587851643562317,\n      0.5081396698951721,\n      -0.4627259373664856\n    ],\n    [\n      -0.9546892046928406,\n      -0.9589608311653137,\n      -0.9571543335914612\n    ],\n    [\n      -0.4646446108818054,\n      -0.4912768006324768,\n      -0.5407620668411255\n    ],\n    [\n      -0.4812314510345459,\n      -0.6482282280921936,\n      -0.5272032022476196\n    ],\n    [\n      0.12023928016424179,\n      -0.5664827227592468,\n      -0.6074532270431519\n    ],\n    [\n      0.6493494510650635,\n      0.9341198205947876,\n      0.9682050943374634\n    ],\n    [\n      -0.49569153785705566,\n      -0.33036357164382935,\n      -0.42618829011917114\n    ],\n    [\n      -0.73708575963974,\n      -0.6543773412704468,\n      -0.5806164741516113\n    ],\n    [\n      0.009461924433708191,\n      0.2977884113788605,\n      -0.76119464635849\n    ],\n    [\n      0.6656442284584045,\n      0.6677116751670837,\n      0.66777503490448\n    ],\n    [\n      0.15271037817001343,\n      0.1402694284915924,\n      -0.045931797474622726\n    ],\n    [\n      -0.21469759941101074,\n      -0.21596451103687286,\n      -0.24124926328659058\n    ],\n    [\n      0.033514540642499924,\n      0.1876029521226883,\n      -0.2994413673877716\n    ],\n    [\n      0.6557291746139526,\n      0.2525959312915802,\n      -0.03010040521621704\n    ],\n    [\n      0.3780847489833832,\n      0.22955067455768585,\n      0.29666024446487427\n    ],\n    [\n      0.09473847597837448,\n      -0.2077258676290512,\n      -0.4256230294704437\n    ],\n    [\n      -0.1965586394071579,\n      -0.6026338934898376,\n      -0.877092719078064\n    ],\n    [\n      -0.22824859619140625,\n      -0.060569919645786285,\n      -0.3626217246055603\n    ],\n    [\n      0.4986802935600281,\n      0.5413235425949097,\n      0.6382442116737366\n    ],\n    [\n      -0.2982630133628845,\n      -0.44031649827957153,\n      -0.3191494941711426\n    ],\n    [\n      0.39659959077835083,\n      0.40043067932128906,\n      0.3959878385066986\n    ],\n    [\n      -0.08158642798662186,\n      -0.019053487107157707,\n      -0.6247203350067139\n    ],\n    [\n      0.33112651109695435,\n      0.42531758546829224,\n      0.6050598621368408\n    ],\n    [\n      -0.8151780366897583,\n      -0.8605278730392456,\n      -0.9021719694137573\n    ],\n    [\n      0.5756203532218933,\n      -0.279142826795578,\n      -0.10808606445789337\n    ],\n    [\n      -0.35837414860725403,\n      -0.12738753855228424,\n      -0.4099779427051544\n    ],\n    [\n      0.20993082225322723,\n      -0.3724344074726105,\n      -0.46085381507873535\n    ],\n    [\n      0.5815994739532471,\n      0.6169049143791199,\n      0.6712881922721863\n    ],\n    [\n      -0.037142347544431686,\n      0.2509496212005615,\n      0.5934980511665344\n    ],\n    [\n      -0.5224048495292664,\n      0.15720880031585693,\n      -0.13347752392292023\n    ],\n    [\n      0.8516570329666138,\n      -0.28838855028152466,\n      -0.2811373770236969\n    ],\n    [\n      0.3303981423377991,\n      0.7609142661094666,\n      0.9427692294120789\n    ],\n    [\n      -0.526467502117157,\n      -0.19269751012325287,\n      -0.6645249724388123\n    ],\n    [\n      0.6592423915863037,\n      0.7726253271102905,\n      0.5242446660995483\n    ],\n    [\n      0.8826857805252075,\n      0.9557124376296997,\n      0.9768160581588745\n    ],\n    [\n      0.080816350877285,\n      0.05601746588945389,\n      0.0004282121662981808\n    ],\n    [\n      0.12476764619350433,\n      0.1192106381058693,\n      0.057267725467681885\n    ],\n    [\n      -0.3069612383842468,\n      -0.6384562849998474,\n      -0.646470844745636\n    ],\n    [\n      -0.8210628032684326,\n      0.1764705777168274,\n      0.88174968957901\n    ],\n    [\n      -0.029447853565216064,\n      -0.21727943420410156,\n      -0.4299236834049225\n    ],\n    [\n      -0.4459696114063263,\n      -0.30544278025627136,\n      -0.11068958044052124\n    ],\n    [\n      0.3415957987308502,\n      0.049382299184799194,\n      0.0515187606215477\n    ],\n    [\n      0.391489177942276,\n      0.526522696018219,\n      0.7385607957839966\n    ],\n    [\n      0.8275082111358643,\n      -0.7554028630256653,\n      -0.8247315287590027\n    ],\n    [\n      0.4855187237262726,\n      0.43647506833076477,\n      0.3769521713256836\n    ],\n    [\n      0.10949407517910004,\n      0.16393597424030304,\n      0.23906537890434265\n    ],\n    [\n      0.13651733100414276,\n      0.05571146309375763,\n      -0.7967619299888611\n    ],\n    [\n      -0.26615267992019653,\n      0.31644773483276367,\n      -0.1660955846309662\n    ],\n    [\n      -0.69644695520401,\n      -0.7076600790023804,\n      -0.7211990356445312\n    ],\n    [\n      0.13769978284835815,\n      0.18018724024295807,\n      -0.1801241785287857\n    ],\n    [\n      0.26187387108802795,\n      0.3039964437484741,\n      0.3465462625026703\n    ],\n    [\n      -0.8368983864784241,\n      0.18385538458824158,\n      0.5279856324195862\n    ],\n    [\n      -0.671728253364563,\n      -0.3264021873474121,\n      -0.53046053647995\n    ],\n    [\n      0.018821779638528824,\n      0.09530801326036453,\n      0.2028338462114334\n    ],\n    [\n      0.6071164608001709,\n      0.5858768820762634,\n      -0.1584533154964447\n    ],\n    [\n      0.5584195852279663,\n      0.03623456507921219,\n      -0.12032688409090042\n    ],\n    [\n      0.25074291229248047,\n      0.14844824373722076,\n      0.009652674198150635\n    ],\n    [\n      -0.8694665431976318,\n      -0.8634858727455139,\n      -0.839803159236908\n    ],\n    [\n      0.3917236626148224,\n      -0.047499798238277435,\n      -0.13375069200992584\n    ],\n    [\n      -0.7228668332099915,\n      -0.6486008763313293,\n      -0.46101221442222595\n    ],\n    [\n      0.18100985884666443,\n      0.38608551025390625,\n      0.628271758556366\n    ],\n    [\n      0.6831871867179871,\n      0.6719169616699219,\n      0.8747395873069763\n    ],\n    [\n      -0.7035294771194458,\n      0.9296077489852905,\n      -0.8525488972663879\n    ],\n    [\n      0.019319158047437668,\n      0.047794047743082047,\n      -0.09124830365180969\n    ],\n    [\n      0.21009762585163116,\n      0.21474285423755646,\n      0.2082643210887909\n    ],\n    [\n      0.20219512283802032,\n      0.11510763317346573,\n      0.08604258298873901\n    ],\n    [\n      -0.001771716051734984,\n      -0.1555626392364502,\n      -0.5461942553520203\n    ],\n    [\n      0.16574536263942719,\n      0.3201632499694824,\n      0.4023251235485077\n    ],\n    [\n      0.15098775923252106,\n      -0.019698454067111015,\n      -0.24036967754364014\n    ],\n    [\n      0.12424777448177338,\n      -0.3093182444572449,\n      -0.2761974036693573\n    ],\n    [\n      0.2556920349597931,\n      0.3668353259563446,\n      -0.15743565559387207\n    ],\n    [\n      -0.6734697222709656,\n      -0.6715599894523621,\n      -0.6557834148406982\n    ],\n    [\n      -0.9074482917785645,\n      -0.08410628139972687,\n      0.40000778436660767\n    ],\n    [\n      0.42929357290267944,\n      0.357200562953949,\n      0.2927454710006714\n    ],\n    [\n      -0.7549343705177307,\n      -0.7041350603103638,\n      -0.6599728465080261\n    ],\n    [\n      -0.31240081787109375,\n      -0.6062411665916443,\n      -0.7798004746437073\n    ],\n    [\n      -0.5995224714279175,\n      -0.5704464912414551,\n      -0.4742653965950012\n    ],\n    [\n      0.1815611869096756,\n      0.04752116650342941,\n      -0.005148107185959816\n    ],\n    [\n      0.2631436586380005,\n      0.48577186465263367,\n      0.6743332743644714\n    ],\n    [\n      0.449628621339798,\n      0.1334758698940277,\n      -0.22476890683174133\n    ],\n    [\n      -0.7262263298034668,\n      -0.8952340483665466,\n      -0.9364691972732544\n    ],\n    [\n      -0.8275038003921509,\n      -0.7674733400344849,\n      -0.6750351190567017\n    ],\n    [\n      -0.04179047793149948,\n      0.04246848449110985,\n      0.12192150205373764\n    ],\n    [\n      -0.6439576148986816,\n      -0.6421950459480286,\n      -0.5686083436012268\n    ],\n    [\n      0.365694522857666,\n      0.38971570134162903,\n      0.004083805251866579\n    ],\n    [\n      -0.11265650391578674,\n      -0.0031872179824858904,\n      0.041394345462322235\n    ],\n    [\n      -0.5328749418258667,\n      0.08787879347801208,\n      0.31642478704452515\n    ],\n    [\n      -0.512047529220581,\n      -0.08577389270067215,\n      0.09757570177316666\n    ],\n    [\n      -0.017580891028046608,\n      -0.20241889357566833,\n      -0.23954741656780243\n    ],\n    [\n      -0.22029943764209747,\n      0.2279697209596634,\n      0.6740188002586365\n    ],\n    [\n      0.5258346199989319,\n      0.3810059428215027,\n      0.27980920672416687\n    ],\n    [\n      0.26255419850349426,\n      0.17080917954444885,\n      -0.1069149374961853\n    ],\n    [\n      0.2701607644557953,\n      0.17936640977859497,\n      0.1253487765789032\n    ],\n    [\n      -0.1069243773818016,\n      0.14620104432106018,\n      0.21676896512508392\n    ],\n    [\n      0.40918177366256714,\n      0.4756438136100769,\n      -0.7484526038169861\n    ],\n    [\n      0.9131329655647278,\n      0.9117553234100342,\n      0.923079788684845\n    ],\n    [\n      0.2663901448249817,\n      -0.5995475053787231,\n      -0.3200604021549225\n    ],\n    [\n      -0.7784014940261841,\n      0.011764703318476677,\n      -0.508151650428772\n    ],\n    [\n      -0.8813919425010681,\n      -0.7712160348892212,\n      -0.07977991551160812\n    ],\n    [\n      0.12264435738325119,\n      -0.1356671154499054,\n      -0.21538789570331573\n    ],\n    [\n      -0.7406893968582153,\n      -0.82442706823349,\n      -0.8552130460739136\n    ],\n    [\n      0.4349195957183838,\n      0.38102126121520996,\n      -0.17550426721572876\n    ],\n    [\n      0.0998995453119278,\n      0.27294236421585083,\n      -0.07623804360628128\n    ],\n    [\n      -0.4556404650211334,\n      -0.6041439771652222,\n      -0.6755514740943909\n    ],\n    [\n      -0.8852124810218811,\n      -0.886846661567688,\n      -0.8974391222000122\n    ],\n    [\n      0.1085643544793129,\n      0.27788299322128296,\n      0.5110284090042114\n    ],\n    [\n      0.05066860839724541,\n      0.07404907047748566,\n      0.0850706696510315\n    ],\n    [\n      -0.0582071952521801,\n      -0.42424219846725464,\n      -0.6010069847106934\n    ],\n    [\n      0.7953606247901917,\n      0.5398732423782349,\n      0.2787138521671295\n    ],\n    [\n      0.07006106525659561,\n      -0.02700883150100708,\n      -0.046815067529678345\n    ],\n    [\n      -0.39510682225227356,\n      -0.41920360922813416,\n      -0.5861340761184692\n    ],\n    [\n      0.9032777547836304,\n      0.7805269360542297,\n      0.5566930174827576\n    ],\n    [\n      -0.2839460074901581,\n      -0.377784788608551,\n      -0.640014111995697\n    ],\n    [\n      0.6189615726470947,\n      0.7806115746498108,\n      0.9112246036529541\n    ],\n    [\n      -0.12736748158931732,\n      0.1799142211675644,\n      -0.3498200476169586\n    ],\n    [\n      -0.6782186031341553,\n      -0.4415965676307678,\n      -0.6616004705429077\n    ],\n    [\n      0.7154431939125061,\n      0.7134858965873718,\n      0.7111637592315674\n    ],\n    [\n      -0.40411651134490967,\n      -0.4058428704738617,\n      -0.7031396627426147\n    ],\n    [\n      0.6037266254425049,\n      0.2546057105064392,\n      -0.5865435600280762\n    ],\n    [\n      -0.030707459896802902,\n      -0.02565935254096985,\n      -0.029052134603261948\n    ],\n    [\n      0.5436667799949646,\n      0.4850476384162903,\n      0.29990139603614807\n    ],\n    [\n      -0.46743983030319214,\n      -0.47828489542007446,\n      -0.640227735042572\n    ],\n    [\n      -0.26479047536849976,\n      -0.2231954038143158,\n      -0.17111815512180328\n    ],\n    [\n      0.08362161368131638,\n      -0.34537962079048157,\n      -0.6366902589797974\n    ],\n    [\n      -0.6172446608543396,\n      -0.6172076463699341,\n      -0.6432552933692932\n    ],\n    [\n      -0.9108860492706299,\n      -0.29293063282966614,\n      0.2471790313720703\n    ],\n    [\n      0.8040373921394348,\n      0.9045073390007019,\n      0.9537075161933899\n    ],\n    [\n      -0.6513022184371948,\n      -0.24690783023834229,\n      0.09721279889345169\n    ],\n    [\n      -0.44596460461616516,\n      -0.6165546178817749,\n      -0.7865057587623596\n    ],\n    [\n      -0.11631107330322266,\n      -0.2858690619468689,\n      -0.14733800292015076\n    ],\n    [\n      0.8959205150604248,\n      0.776850163936615,\n      -0.4020872712135315\n    ],\n    [\n      0.3601052761077881,\n      0.3988553285598755,\n      0.49251291155815125\n    ],\n    [\n      -0.26731595396995544,\n      -0.26987895369529724,\n      -0.5473183393478394\n    ],\n    [\n      -0.47619685530662537,\n      -0.13198773562908173,\n      -0.1730058193206787\n    ],\n    [\n      -0.18654994666576385,\n      -0.08646202087402344,\n      -0.014718189835548401\n    ],\n    [\n      -0.4939781129360199,\n      -0.48898038268089294,\n      -0.7509691119194031\n    ],\n    [\n      0.4362282454967499,\n      0.2905654311180115,\n      0.08038295060396194\n    ],\n    [\n      0.5500906109809875,\n      0.6066980957984924,\n      0.18538472056388855\n    ],\n    [\n      -0.703561007976532,\n      -0.475872665643692,\n      -0.8547963500022888\n    ],\n    [\n      -0.32337120175361633,\n      -0.41644686460494995,\n      -0.44723910093307495\n    ],\n    [\n      -0.1228637844324112,\n      0.009513471275568008,\n      -0.3269110321998596\n    ],\n    [\n      -0.05532831326127052,\n      -0.2880820631980896,\n      -0.632136344909668\n    ],\n    [\n      0.01306537538766861,\n      0.1541440635919571,\n      0.31442636251449585\n    ],\n    [\n      -0.8547711372375488,\n      -0.7236877679824829,\n      -0.7856305837631226\n    ],\n    [\n      -0.33122292160987854,\n      -0.08996910601854324,\n      -0.013522649183869362\n    ],\n    [\n      0.19104398787021637,\n      0.49409112334251404,\n      0.29054054617881775\n    ],\n    [\n      -0.8246536254882812,\n      -0.8210623264312744,\n      -0.8379841446876526\n    ],\n    [\n      0.43059009313583374,\n      0.4535168409347534,\n      0.4542773365974426\n    ],\n    [\n      0.12398073077201843,\n      0.046275846660137177,\n      -0.0954698845744133\n    ],\n    [\n      0.33695098757743835,\n      0.545078456401825,\n      -0.09679412096738815\n    ],\n    [\n      0.2479376196861267,\n      -0.1584005504846573,\n      -0.45131367444992065\n    ],\n    [\n      0.5698011517524719,\n      -0.17435789108276367,\n      -0.3622756600379944\n    ],\n    [\n      -0.28326958417892456,\n      -0.552253007888794,\n      -0.511475145816803\n    ],\n    [\n      0.3965805172920227,\n      0.3034624457359314,\n      0.19590552151203156\n    ],\n    [\n      -0.12847775220870972,\n      -0.18598346412181854,\n      -0.2504082918167114\n    ],\n    [\n      0.7366775870323181,\n      0.7880193591117859,\n      0.8475437164306641\n    ],\n    [\n      -0.2861339747905731,\n      0.17025791108608246,\n      0.35271167755126953\n    ],\n    [\n      0.8075168132781982,\n      0.42018771171569824,\n      0.44603678584098816\n    ],\n    [\n      0.2363329976797104,\n      0.08777014166116714,\n      -0.28347423672676086\n    ],\n    [\n      -0.19575831294059753,\n      -0.3653962314128876,\n      -0.851190447807312\n    ],\n    [\n      -0.7790830135345459,\n      -0.7817010283470154,\n      -0.7980022430419922\n    ],\n    [\n      -0.4479544162750244,\n      -0.2243645042181015,\n      0.02055962011218071\n    ],\n    [\n      -0.4256124794483185,\n      0.07734345644712448,\n      0.8159140348434448\n    ],\n    [\n      -0.6993678212165833,\n      -0.4087635278701782,\n      -0.10601040720939636\n    ],\n    [\n      -0.1086140125989914,\n      0.5889700055122375,\n      0.9140363335609436\n    ],\n    [\n      -0.16228757798671722,\n      0.18070262670516968,\n      0.5169607996940613\n    ],\n    [\n      0.749700665473938,\n      0.6360651850700378,\n      0.4028933644294739\n    ],\n    [\n      -0.038698162883520126,\n      0.15878617763519287,\n      -0.019297881051898003\n    ],\n    [\n      0.26143696904182434,\n      0.5723651051521301,\n      0.7870779037475586\n    ],\n    [\n      0.6218112111091614,\n      0.505821704864502,\n      0.5277906656265259\n    ],\n    [\n      0.6569492220878601,\n      0.35561317205429077,\n      -0.1962130069732666\n    ],\n    [\n      0.8325598239898682,\n      0.10312407463788986,\n      -0.8632609844207764\n    ],\n    [\n      0.33171647787094116,\n      -0.21685273945331573,\n      -0.2871755063533783\n    ],\n    [\n      0.7343755960464478,\n      0.6765835881233215,\n      0.6062597036361694\n    ],\n    [\n      -0.38332948088645935,\n      -0.29144349694252014,\n      -0.6084114909172058\n    ],\n    [\n      0.8274057507514954,\n      0.8408244252204895,\n      0.8678486347198486\n    ],\n    [\n      0.24925090372562408,\n      0.07891064137220383,\n      -0.5096247792243958\n    ],\n    [\n      0.8545863032341003,\n      0.5584403872489929,\n      -0.13889265060424805\n    ],\n    [\n      -0.8311881422996521,\n      -0.7162603735923767,\n      -0.5443006157875061\n    ],\n    [\n      -0.08647031337022781,\n      -0.14451654255390167,\n      -0.18571554124355316\n    ],\n    [\n      0.6945480108261108,\n      0.38208863139152527,\n      0.11536668241024017\n    ],\n    [\n      -0.09427246451377869,\n      0.1726670265197754,\n      -0.5678977370262146\n    ],\n    [\n      0.0062930467538535595,\n      -0.08789492398500443,\n      -0.4074787497520447\n    ],\n    [\n      -0.549629271030426,\n      -0.5167146325111389,\n      -0.3297889828681946\n    ],\n    [\n      0.2673673629760742,\n      -0.19041119515895844,\n      -0.06358104199171066\n    ],\n    [\n      -0.7795626521110535,\n      -0.24047257006168365,\n      -0.7764204144477844\n    ],\n    [\n      0.3919673264026642,\n      0.19492611289024353,\n      0.13595764338970184\n    ],\n    [\n      -0.4196263551712036,\n      -0.8605479001998901,\n      -0.901617705821991\n    ],\n    [\n      -0.2352941483259201,\n      -0.8655933737754822,\n      -0.8846911191940308\n    ],\n    [\n      -0.4142451584339142,\n      -0.7462329268455505,\n      -0.7431978583335876\n    ],\n    [\n      0.23768068850040436,\n      0.4202742874622345,\n      0.796495795249939\n    ],\n    [\n      0.2594039738178253,\n      -0.039857808500528336,\n      -0.23500750958919525\n    ],\n    [\n      4.410944711707998e-06,\n      0.3582831621170044,\n      -0.42580118775367737\n    ],\n    [\n      -0.20306804776191711,\n      -0.4723082184791565,\n      -0.6012682318687439\n    ],\n    [\n      0.3004637062549591,\n      0.25049784779548645,\n      0.19274620711803436\n    ],\n    [\n      -0.23253419995307922,\n      -0.2656415104866028,\n      -0.3554094731807709\n    ],\n    [\n      0.18377049267292023,\n      0.22542840242385864,\n      0.3122413158416748\n    ],\n    [\n      0.8251723051071167,\n      0.3228589594364166,\n      -0.11610488593578339\n    ],\n    [\n      -0.12032292783260345,\n      -0.5216472744941711,\n      -0.7512328624725342\n    ],\n    [\n      0.3880918622016907,\n      0.13227270543575287,\n      -0.0909455418586731\n    ],\n    [\n      0.26736530661582947,\n      0.0636509582400322,\n      -0.07616468518972397\n    ],\n    [\n      -0.22423118352890015,\n      0.07944183051586151,\n      -0.45292964577674866\n    ],\n    [\n      -0.5266450047492981,\n      -0.30987870693206787,\n      -0.8572283387184143\n    ],\n    [\n      -0.1661577969789505,\n      0.06344860047101974,\n      -0.8015714883804321\n    ],\n    [\n      -0.18381772935390472,\n      -0.4403200149536133,\n      -0.46376028656959534\n    ],\n    [\n      0.6711505055427551,\n      0.7436378002166748,\n      0.7911440134048462\n    ],\n    [\n      0.03696923330426216,\n      0.1562359780073166,\n      -0.445999413728714\n    ],\n    [\n      0.5192427635192871,\n      0.6023258566856384,\n      0.7681598663330078\n    ],\n    [\n      0.4870956540107727,\n      0.19961246848106384,\n      0.011532967910170555\n    ],\n    [\n      0.5697644948959351,\n      -0.6889438033103943,\n      -0.6128193140029907\n    ],\n    [\n      -0.8247247934341431,\n      -0.6001573204994202,\n      -0.9008808732032776\n    ],\n    [\n      0.059214502573013306,\n      -0.7634263038635254,\n      -0.7111309170722961\n    ],\n    [\n      0.1423216313123703,\n      0.31812146306037903,\n      -0.26413336396217346\n    ],\n    [\n      -0.1638103425502777,\n      -0.07887032628059387,\n      -0.2320381999015808\n    ],\n    [\n      0.28969767689704895,\n      0.3724275231361389,\n      0.15289252996444702\n    ],\n    [\n      0.0041793230921030045,\n      -0.48368778824806213,\n      -0.4242289960384369\n    ],\n    [\n      0.5584286451339722,\n      0.5311771631240845,\n      0.41985878348350525\n    ],\n    [\n      -0.4475919008255005,\n      -0.20042356848716736,\n      0.5337203145027161\n    ],\n    [\n      0.5304732918739319,\n      0.3061673641204834,\n      0.43950074911117554\n    ],\n    [\n      0.6813693642616272,\n      0.7716038823127747,\n      0.2512742280960083\n    ],\n    [\n      -0.5219373106956482,\n      -0.4279458820819855,\n      -0.1875661313533783\n    ],\n    [\n      -0.41927874088287354,\n      -0.036482471972703934,\n      -0.5496504902839661\n    ],\n    [\n      0.5182844996452332,\n      -0.484189510345459,\n      -0.8203639388084412\n    ],\n    [\n      -0.508963406085968,\n      -0.5042758584022522,\n      -0.4699215888977051\n    ],\n    [\n      0.9184025526046753,\n      0.8484019041061401,\n      0.33833426237106323\n    ],\n    [\n      0.9437444806098938,\n      0.8895163536071777,\n      0.7109180092811584\n    ],\n    [\n      0.7086508870124817,\n      0.5615507364273071,\n      0.12094032764434814\n    ],\n    [\n      0.6170580983161926,\n      0.6768963932991028,\n      0.742318868637085\n    ],\n    [\n      -0.1199045330286026,\n      0.13261021673679352,\n      0.3690446615219116\n    ],\n    [\n      -0.17684566974639893,\n      -0.17434300482273102,\n      -0.1744946539402008\n    ],\n    [\n      -0.4894859194755554,\n      -0.35281237959861755,\n      -0.558021605014801\n    ],\n    [\n      0.10339447855949402,\n      -0.20046383142471313,\n      -0.7734662890434265\n    ],\n    [\n      0.8841200470924377,\n      0.8832088708877563,\n      0.8791232109069824\n    ],\n    [\n      0.1341663897037506,\n      0.5238715410232544,\n      -0.2299637794494629\n    ],\n    [\n      0.18523065745830536,\n      -0.04618392512202263,\n      -0.10783310979604721\n    ],\n    [\n      -0.47945553064346313,\n      -0.31917500495910645,\n      -0.23796002566814423\n    ],\n    [\n      -0.06797277182340622,\n      0.35138362646102905,\n      0.7296305298805237\n    ],\n    [\n      -0.06990627199411392,\n      -0.08354364335536957,\n      -0.13758940994739532\n    ],\n    [\n      -0.5663723945617676,\n      -0.44837072491645813,\n      -0.5650995969772339\n    ],\n    [\n      -0.20074671506881714,\n      -0.30797284841537476,\n      -0.451373815536499\n    ],\n    [\n      0.4359857141971588,\n      0.4774211645126343,\n      0.5535441040992737\n    ],\n    [\n      -0.5688455104827881,\n      -0.5204092264175415,\n      -0.6640347242355347\n    ],\n    [\n      0.2390112578868866,\n      -0.8670171499252319,\n      -0.8696901202201843\n    ],\n    [\n      -0.6326277256011963,\n      -0.7116203904151917,\n      -0.7878476977348328\n    ],\n    [\n      0.2262098342180252,\n      0.3781503140926361,\n      0.514397919178009\n    ],\n    [\n      0.7280123829841614,\n      0.8368320465087891,\n      0.9328539967536926\n    ],\n    [\n      -0.7567948698997498,\n      -0.7465658187866211,\n      -0.7405295968055725\n    ],\n    [\n      0.8170334100723267,\n      0.08413780480623245,\n      -0.48214709758758545\n    ],\n    [\n      0.862877368927002,\n      0.5352585315704346,\n      -0.7991546988487244\n    ],\n    [\n      -0.621928870677948,\n      -0.562061071395874,\n      -0.7660283446311951\n    ],\n    [\n      -0.6628718972206116,\n      -0.5574901103973389,\n      -0.046710383147001266\n    ],\n    [\n      0.4059176445007324,\n      -0.22110991179943085,\n      -0.5631029605865479\n    ],\n    [\n      -0.2655342221260071,\n      -0.10063542425632477,\n      -0.15453915297985077\n    ],\n    [\n      -0.6882926821708679,\n      -0.5326656699180603,\n      -0.3910406231880188\n    ],\n    [\n      -0.3209667205810547,\n      -0.26197776198387146,\n      -0.43213561177253723\n    ],\n    [\n      0.4604199230670929,\n      0.38297465443611145,\n      0.165588840842247\n    ],\n    [\n      -0.789753258228302,\n      -0.7486531138420105,\n      -0.8991166353225708\n    ],\n    [\n      -0.14251157641410828,\n      0.21082474291324615,\n      0.8753480315208435\n    ],\n    [\n      -0.17588567733764648,\n      -0.7455897331237793,\n      -0.7437286376953125\n    ],\n    [\n      0.15619508922100067,\n      -0.11082154512405396,\n      -0.33546683192253113\n    ],\n    [\n      0.0566534698009491,\n      -0.06090889498591423,\n      -0.2844159007072449\n    ],\n    [\n      -0.35421425104141235,\n      -0.1077323853969574,\n      0.1446550190448761\n    ],\n    [\n      -0.410139799118042,\n      -0.41112881898880005,\n      -0.4146181344985962\n    ],\n    [\n      0.45235970616340637,\n      -0.1573840230703354,\n      -0.834283709526062\n    ],\n    [\n      0.17508824169635773,\n      0.2110530585050583,\n      -0.3586375415325165\n    ],\n    [\n      -0.34698259830474854,\n      -0.21341188251972198,\n      -0.09654439240694046\n    ],\n    [\n      -0.5389053821563721,\n      -0.6091872453689575,\n      -0.7163283824920654\n    ],\n    [\n      0.07956509292125702,\n      -0.031822409480810165,\n      -0.15940652787685394\n    ],\n    [\n      -0.3426502048969269,\n      0.09453719109296799,\n      0.549526572227478\n    ],\n    [\n      0.3917296528816223,\n      0.008907724171876907,\n      -0.30424365401268005\n    ],\n    [\n      0.6411649584770203,\n      0.6219286322593689,\n      0.6035862565040588\n    ],\n    [\n      0.6803315877914429,\n      0.1710834503173828,\n      -0.2590431869029999\n    ],\n    [\n      0.3507155478000641,\n      0.18933378159999847,\n      0.010193992406129837\n    ],\n    [\n      0.36329159140586853,\n      0.16937659680843353,\n      -0.391919881105423\n    ],\n    [\n      -0.2764776051044464,\n      -0.347095787525177,\n      -0.40577244758605957\n    ],\n    [\n      0.0063696615397930145,\n      0.3818424940109253,\n      0.905337393283844\n    ],\n    [\n      0.15251892805099487,\n      0.4211327135562897,\n      0.022407291457057\n    ],\n    [\n      0.25898444652557373,\n      -0.08948460966348648,\n      -0.6144158244132996\n    ],\n    [\n      -0.0749160647392273,\n      -0.1953003704547882,\n      -0.33285605907440186\n    ],\n    [\n      -0.8303108811378479,\n      -0.3902731239795685,\n      -0.3073550760746002\n    ],\n    [\n      -0.08750402927398682,\n      -0.07856182754039764,\n      -0.05715752765536308\n    ],\n    [\n      -0.5891665816307068,\n      -0.2873663902282715,\n      -0.1156381368637085\n    ],\n    [\n      0.052701372653245926,\n      0.38162222504615784,\n      0.5678205490112305\n    ],\n    [\n      0.5728093385696411,\n      0.4326959252357483,\n      0.17818894982337952\n    ],\n    [\n      0.033164869993925095,\n      -0.16302891075611115,\n      -0.3282933235168457\n    ],\n    [\n      -0.26090341806411743,\n      -0.0005510819610208273,\n      -0.6438092589378357\n    ],\n    [\n      -0.14958596229553223,\n      -0.3920140266418457,\n      -0.6836188435554504\n    ],\n    [\n      -0.22344645857810974,\n      -0.1870509684085846,\n      -0.44519248604774475\n    ],\n    [\n      -0.7314428687095642,\n      -0.6415193676948547,\n      -0.30459868907928467\n    ],\n    [\n      0.6686636805534363,\n      0.4304346442222595,\n      -0.011660866439342499\n    ],\n    [\n      0.847905695438385,\n      0.6147153377532959,\n      0.655009925365448\n    ],\n    [\n      0.5191642642021179,\n      0.537932813167572,\n      0.5333459377288818\n    ],\n    [\n      -0.1298946589231491,\n      -0.25259557366371155,\n      -0.40116971731185913\n    ],\n    [\n      0.4965935945510864,\n      0.839232861995697,\n      0.9532268643379211\n    ],\n    [\n      0.25265082716941833,\n      0.26634716987609863,\n      0.26437729597091675\n    ],\n    [\n      0.5717523097991943,\n      0.5832701921463013,\n      0.5809952616691589\n    ],\n    [\n      -0.36550402641296387,\n      -0.3588101863861084,\n      -0.3724764585494995\n    ],\n    [\n      0.09444736689329147,\n      0.2112719565629959,\n      0.3880409896373749\n    ],\n    [\n      -0.6985506415367126,\n      -0.4201357960700989,\n      0.16628441214561462\n    ],\n    [\n      0.809805154800415,\n      0.6982276439666748,\n      0.5141733288764954\n    ],\n    [\n      -0.29925593733787537,\n      -0.17094896733760834,\n      -0.2989594340324402\n    ],\n    [\n      -0.033775947988033295,\n      -0.310159832239151,\n      -0.34480294585227966\n    ],\n    [\n      0.6758798956871033,\n      0.441753625869751,\n      0.24923746287822723\n    ],\n    [\n      -0.35855764150619507,\n      -0.2657393515110016,\n      -0.21003057062625885\n    ],\n    [\n      -0.4930666387081146,\n      -0.4461483359336853,\n      -0.3960783779621124\n    ],\n    [\n      -0.5915629267692566,\n      -0.14166218042373657,\n      0.2893812358379364\n    ],\n    [\n      0.5480598211288452,\n      -0.02691347897052765,\n      -0.5984203815460205\n    ],\n    [\n      0.8868749141693115,\n      0.8473175764083862,\n      0.8030847907066345\n    ],\n    [\n      0.08557762950658798,\n      0.4244401156902313,\n      0.7516128420829773\n    ],\n    [\n      0.10233782231807709,\n      0.274545818567276,\n      0.256741464138031\n    ],\n    [\n      -0.581525444984436,\n      -0.8821192979812622,\n      -0.9228616952896118\n    ],\n    [\n      0.029020698741078377,\n      0.21658559143543243,\n      0.12602707743644714\n    ],\n    [\n      -0.30120235681533813,\n      -0.1533181369304657,\n      -0.5427955985069275\n    ],\n    [\n      0.5009274482727051,\n      0.48171597719192505,\n      0.47619250416755676\n    ],\n    [\n      0.47403761744499207,\n      0.6451749205589294,\n      0.6711832284927368\n    ],\n    [\n      -0.3786222040653229,\n      -0.4587174355983734,\n      -0.5131866931915283\n    ],\n    [\n      -0.8491628766059875,\n      -0.9399452805519104,\n      -0.9578626751899719\n    ],\n    [\n      -0.5960239768028259,\n      -0.4241867959499359,\n      -0.7643530964851379\n    ],\n    [\n      -0.37123870849609375,\n      -0.3528949022293091,\n      -0.49114760756492615\n    ],\n    [\n      -0.5194482207298279,\n      -0.7201964855194092,\n      -0.8779999613761902\n    ],\n    [\n      -0.6902539730072021,\n      -0.7959086894989014,\n      -0.6496112942695618\n    ],\n    [\n      -0.07562510669231415,\n      0.024504806846380234,\n      -0.46301695704460144\n    ],\n    [\n      -0.877565324306488,\n      -0.430828332901001,\n      0.006420488469302654\n    ],\n    [\n      0.25796210765838623,\n      0.259445458650589,\n      0.47693929076194763\n    ],\n    [\n      -0.19203978776931763,\n      0.4261242747306824,\n      0.5270705223083496\n    ],\n    [\n      -0.3844175636768341,\n      -0.020532142370939255,\n      0.4136267602443695\n    ],\n    [\n      -0.6947348713874817,\n      -0.7752019762992859,\n      -0.7874815464019775\n    ],\n    [\n      0.8658393025398254,\n      0.7921077609062195,\n      0.7075756788253784\n    ],\n    [\n      -0.03359358012676239,\n      -0.0032838641200214624,\n      -0.21726182103157043\n    ],\n    [\n      0.13497254252433777,\n      -0.08375006914138794,\n      -0.45929840207099915\n    ],\n    [\n      -0.26721513271331787,\n      0.38139304518699646,\n      0.8757712841033936\n    ],\n    [\n      0.11953038722276688,\n      0.5874934792518616,\n      0.6712079048156738\n    ],\n    [\n      -0.7307054996490479,\n      -0.710096001625061,\n      -0.8239564299583435\n    ],\n    [\n      0.8117648363113403,\n      -0.05080314725637436,\n      -0.004829954821616411\n    ],\n    [\n      -0.589617133140564,\n      -0.5743433237075806,\n      -0.5764443874359131\n    ],\n    [\n      -0.5585607290267944,\n      -0.7995380163192749,\n      -0.7973589897155762\n    ],\n    [\n      -0.45065435767173767,\n      -0.4013029932975769,\n      -0.31873971223831177\n    ],\n    [\n      0.10054251551628113,\n      0.2636285722255707,\n      0.6881422996520996\n    ],\n    [\n      0.8072077631950378,\n      -0.5508065819740295,\n      -0.5025964379310608\n    ],\n    [\n      -0.35233694314956665,\n      -0.12778159976005554,\n      -0.8346442580223083\n    ],\n    [\n      -0.23788896203041077,\n      -0.2491414099931717,\n      -0.6852221488952637\n    ],\n    [\n      0.5601637363433838,\n      0.33189404010772705,\n      0.09012506157159805\n    ],\n    [\n      -0.5904211401939392,\n      -0.46565353870391846,\n      -0.43466705083847046\n    ],\n    [\n      -0.8602998852729797,\n      -0.5717481374740601,\n      -0.44156646728515625\n    ],\n    [\n      -0.30724796652793884,\n      -0.3099612295627594,\n      -0.32398149371147156\n    ],\n    [\n      0.3014434576034546,\n      0.5753018260002136,\n      0.9307978749275208\n    ],\n    [\n      -0.901679277420044,\n      -0.7673903703689575,\n      -0.38350850343704224\n    ],\n    [\n      -0.24826869368553162,\n      -0.49758121371269226,\n      -0.7222003936767578\n    ],\n    [\n      -0.02858002856373787,\n      0.26874157786369324,\n      0.4140278100967407\n    ],\n    [\n      -0.687764585018158,\n      -0.538379430770874,\n      -0.534829318523407\n    ],\n    [\n      0.5000979900360107,\n      0.49794813990592957,\n      0.03327731415629387\n    ],\n    [\n      0.14014378190040588,\n      0.512022852897644,\n      0.9017723202705383\n    ],\n    [\n      -0.17659704387187958,\n      -0.35234323143959045,\n      -0.3527551293373108\n    ],\n    [\n      0.5163330435752869,\n      -0.8715240955352783,\n      -0.8461443781852722\n    ],\n    [\n      0.9597784280776978,\n      0.9349061846733093,\n      0.8404857516288757\n    ],\n    [\n      0.40271055698394775,\n      0.5679798126220703,\n      -0.31350722908973694\n    ],\n    [\n      -0.6535230875015259,\n      -0.6329662203788757,\n      -0.8829557299613953\n    ],\n    [\n      -0.12881648540496826,\n      0.02529139816761017,\n      -0.10633862018585205\n    ],\n    [\n      -0.5647919178009033,\n      -0.7014521360397339,\n      -0.675957441329956\n    ],\n    [\n      0.15704724192619324,\n      0.6973430514335632,\n      0.9305424690246582\n    ],\n    [\n      0.3878478407859802,\n      0.5417211055755615,\n      0.6238986253738403\n    ],\n    [\n      0.31486886739730835,\n      0.23276633024215698,\n      -0.22907160222530365\n    ],\n    [\n      0.2343786507844925,\n      0.07411810755729675,\n      0.26075926423072815\n    ],\n    [\n      -0.8265745639801025,\n      0.1276153177022934,\n      0.059393130242824554\n    ],\n    [\n      0.43371477723121643,\n      0.14048443734645844,\n      -0.7748559713363647\n    ],\n    [\n      -0.2692457139492035,\n      0.013620681129395962,\n      0.25875985622406006\n    ],\n    [\n      -0.02501986362040043,\n      0.318763792514801,\n      -0.16803474724292755\n    ],\n    [\n      0.18032605946063995,\n      0.26465755701065063,\n      -0.5663284659385681\n    ],\n    [\n      0.5424352884292603,\n      0.7160876393318176,\n      0.8182350993156433\n    ],\n    [\n      -0.11874964833259583,\n      -0.11564076691865921,\n      -0.43408188223838806\n    ],\n    [\n      0.4049621820449829,\n      0.4641309678554535,\n      0.27158793807029724\n    ],\n    [\n      0.8023068904876709,\n      -0.3528258502483368,\n      0.4783160388469696\n    ],\n    [\n      -0.27317172288894653,\n      0.09456677734851837,\n      0.07421348243951797\n    ],\n    [\n      -0.1390434056520462,\n      0.004617467522621155,\n      0.17979542911052704\n    ],\n    [\n      0.39985713362693787,\n      0.6359505653381348,\n      0.812467098236084\n    ],\n    [\n      0.024408796802163124,\n      -0.5953179001808167,\n      -0.8567085266113281\n    ],\n    [\n      -0.5011078119277954,\n      -0.5504330396652222,\n      -0.6019151210784912\n    ],\n    [\n      0.2526206076145172,\n      -0.2878299653530121,\n      -0.6804863810539246\n    ],\n    [\n      -0.6287853717803955,\n      -0.6565880179405212,\n      -0.7183127403259277\n    ],\n    [\n      0.5216560363769531,\n      -0.42906203866004944,\n      -0.4035843014717102\n    ],\n    [\n      -0.17172972857952118,\n      -0.14767029881477356,\n      -0.5951231122016907\n    ],\n    [\n      -0.542864203453064,\n      -0.6117892861366272,\n      -0.6314513087272644\n    ],\n    [\n      -0.3827812969684601,\n      -0.29156258702278137,\n      -0.7587236762046814\n    ],\n    [\n      0.47409379482269287,\n      0.6714364290237427,\n      0.9321048855781555\n    ],\n    [\n      -0.5917093753814697,\n      -0.3855935335159302,\n      -0.3170311152935028\n    ],\n    [\n      0.30367207527160645,\n      -0.7085203528404236,\n      -0.6884373426437378\n    ],\n    [\n      0.607463002204895,\n      0.44477027654647827,\n      0.37944188714027405\n    ],\n    [\n      -0.5434997081756592,\n      -0.6743095517158508,\n      -0.779110312461853\n    ],\n    [\n      0.5268216133117676,\n      0.2740236222743988,\n      -0.3307431936264038\n    ],\n    [\n      0.2641393542289734,\n      -0.03398425504565239,\n      -0.37289056181907654\n    ],\n    [\n      -0.11731287091970444,\n      -0.24595773220062256,\n      -0.5200735926628113\n    ],\n    [\n      0.7649475932121277,\n      0.760320782661438,\n      0.7578855156898499\n    ],\n    [\n      -0.6559750437736511,\n      -0.7789433598518372,\n      -0.8842822909355164\n    ],\n    [\n      0.886038064956665,\n      0.6564491391181946,\n      0.1891615241765976\n    ],\n    [\n      -0.6598775386810303,\n      -0.302301824092865,\n      0.39183127880096436\n    ],\n    [\n      0.10474222898483276,\n      0.11633803695440292,\n      0.1397334337234497\n    ],\n    [\n      0.29360753297805786,\n      0.36898332834243774,\n      0.4225856363773346\n    ],\n    [\n      0.4249189496040344,\n      0.6796203255653381,\n      0.36297664046287537\n    ],\n    [\n      0.6751871109008789,\n      0.5418874025344849,\n      0.41607919335365295\n    ],\n    [\n      -0.37373998761177063,\n      -0.348294198513031,\n      -0.26444029808044434\n    ],\n    [\n      -0.20876768231391907,\n      -0.04786171764135361,\n      -0.5082888007164001\n    ],\n    [\n      0.07575385272502899,\n      0.07186414301395416,\n      -0.22131963074207306\n    ],\n    [\n      0.20403233170509338,\n      0.05782639980316162,\n      -0.1642524152994156\n    ],\n    [\n      0.8547954559326172,\n      0.36743852496147156,\n      -0.4031407833099365\n    ],\n    [\n      -0.140174999833107,\n      -0.12597081065177917,\n      -0.11109901964664459\n    ],\n    [\n      0.0036428782623261213,\n      0.01705816388130188,\n      0.029841415584087372\n    ],\n    [\n      0.5402044057846069,\n      0.07432081550359726,\n      -0.3797238767147064\n    ],\n    [\n      0.004338869825005531,\n      -0.1010223850607872,\n      -0.20412594079971313\n    ],\n    [\n      -0.29378676414489746,\n      -0.4300309419631958,\n      -0.5475382804870605\n    ],\n    [\n      0.6545546054840088,\n      0.5585492253303528,\n      0.30747750401496887\n    ],\n    [\n      0.6188711524009705,\n      0.6035498976707458,\n      0.48929306864738464\n    ],\n    [\n      0.29986414313316345,\n      0.4980831444263458,\n      0.5015079975128174\n    ],\n    [\n      -0.22464066743850708,\n      -0.17657655477523804,\n      -0.07300838083028793\n    ],\n    [\n      0.3251692056655884,\n      0.3183857202529907,\n      0.2722066044807434\n    ],\n    [\n      0.8105982542037964,\n      0.8071480989456177,\n      0.8013849258422852\n    ],\n    [\n      -0.8247439861297607,\n      -0.8224160671234131,\n      -0.7605470418930054\n    ],\n    [\n      0.4926680028438568,\n      0.7364184260368347,\n      -0.018585635349154472\n    ]\n  ],\n  \"do_color_quantize\": true,\n  \"do_normalize\": true,\n  \"do_resize\": true,\n  \"image_processor_type\": \"ImageGPTImageProcessor\",\n  \"resample\": 2,\n  \"size\": {\n    \"height\": 32,\n    \"width\": 32\n  }\n}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_processor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:55:29.221858380Z",
     "start_time": "2023-12-06T09:55:29.134878386Z"
    }
   },
   "id": "7f8d764433d8c65"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "inputs = image_processor(images=image['img'], return_tensors=\"pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:57:02.677422653Z",
     "start_time": "2023-12-06T09:57:02.630371950Z"
    }
   },
   "id": "3dde12943b57a860"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[226, 226, 226,  ..., 369, 369, 369]])}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T09:57:09.661191976Z",
     "start_time": "2023-12-06T09:57:09.658480654Z"
    }
   },
   "id": "cd43a8ce9cc3f31d"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='data/', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='data/', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T10:41:11.897101588Z",
     "start_time": "2023-12-06T10:41:10.786043609Z"
    }
   },
   "id": "de0cb60408ae6e2d"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T10:41:14.503995796Z",
     "start_time": "2023-12-06T10:41:14.461737176Z"
    }
   },
   "id": "5fc6414009794e74"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from hybrid_transformer.evaluation.inception import InceptionV3\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T10:51:23.164099031Z",
     "start_time": "2023-12-06T10:51:23.128689964Z"
    }
   },
   "id": "425ca5d91ea51197"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "DIMS = 2048\n",
    "\n",
    "\n",
    "def load_fid_score_model(device: torch.device) -> torch.nn.Module:\n",
    "    block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[DIMS]\n",
    "    model = InceptionV3([block_idx]).to(device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return lambda batch: model(batch)[0]\n",
    "\n",
    "@torch.no_grad()\n",
    "def calculate_test_distribution(loader, device):\n",
    "    \n",
    "    score_model = load_fid_score_model(device)    \n",
    "    \n",
    "    distribution = []\n",
    "    \n",
    "    for idx, batch in enumerate(loader):\n",
    "        x, y = batch\n",
    "        distribution.append(score_model(x.to(device)).cpu().detach().numpy())\n",
    "        if idx > 10:\n",
    "            break\n",
    "            \n",
    "    distribution_orig = np.array(np.concatenate(distribution)).reshape(-1, DIMS)\n",
    "    \n",
    "    return distribution_orig\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def calculate_model_distribution(image_processor, model, batch_size, num_images_to_generate, device):\n",
    "    \n",
    "    context = torch.full((batch_size, 1), model.config.vocab_size - 1)\n",
    "    context = context.to(device)\n",
    "    output = model.generate(\n",
    "        input_ids=context, max_length=model.config.n_positions + 1, temperature=1.0, do_sample=True, top_k=40\n",
    "    )\n",
    "\n",
    "    clusters = image_processor.clusters\n",
    "    height = image_processor.size[\"height\"]\n",
    "    width = image_processor.size[\"width\"]\n",
    "    \n",
    "    samples = output[:, 1:].cpu().detach().numpy()\n",
    "    samples_img = [\n",
    "        np.reshape(np.rint(127.5 * (clusters[s] + 1.0)), [height, width, 3]).astype(np.uint8) for s in samples\n",
    "    ]  # convert color cluster tokens back to pixels\n",
    "            \n",
    "    return samples_img\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T10:57:41.610086757Z",
     "start_time": "2023-12-06T10:57:41.524293941Z"
    }
   },
   "id": "59e9d0173dcf18f3"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_processor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[62], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m test_distribution \u001B[38;5;241m=\u001B[39m calculate_test_distribution(testloader, device)\n\u001B[0;32m----> 3\u001B[0m generated_distribution \u001B[38;5;241m=\u001B[39m calculate_test_distribution(image_processor\u001B[38;5;241m=\u001B[39m\u001B[43mimage_processor\u001B[49m, model\u001B[38;5;241m=\u001B[39mmodel, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, num_images_to_generate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'image_processor' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_distribution = calculate_test_distribution(testloader, device)\n",
    "generated_distribution = calculate_test_distribution(image_processor=image_processor, model=model, batch_size=2, num_images_to_generate=2, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T10:58:43.281839846Z",
     "start_time": "2023-12-06T10:58:40.562220860Z"
    }
   },
   "id": "11ca04654ce37a36"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "examples, _ = train_loop.generate_examples(total_num_exapmles=n_generated_examples,\n",
    "                                           max_classes=self.n_classes,\n",
    "                                           batch_size=batch_size)\n",
    "examples_to_generate = n_generated_examples\n",
    "i = 0\n",
    "while examples_to_generate > 0:\n",
    "    print(examples_to_generate)\n",
    "    example = examples[i * batch_size:min(n_generated_examples, (i + 1) * batch_size)].to(\n",
    "        self.score_model_device)\n",
    "    if dataset.lower() in [\"fashionmnist\", \"doublemnist\"]:\n",
    "        example = example.repeat([1, 3, 1, 1])\n",
    "    distribution_gen.append(self.score_model_func(example).cpu().detach())  # .numpy().reshape(-1, self.dims))\n",
    "    examples_to_generate -= batch_size\n",
    "    i += 1\n",
    "    # distribution_gen = self.score_model_func(example).cpu().numpy().reshape(-1, self.dims)\n",
    "\n",
    "distribution_gen = torch.cat(distribution_gen).numpy().reshape(-1, self.dims)\n",
    "# distribution_gen = np.array(np.concatenate(distribution_gen)).reshape(-1, self.dims)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96ec45b8a1a1c457"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 1 (590744615.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[42], line 2\u001B[0;36m\u001B[0m\n\u001B[0;31m    print(idx, len(test_loader))\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m expected an indented block after 'if' statement on line 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  \n",
    "calculate_frechet_distance(distribution_gen, distribution_orig)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-06T10:46:59.233576824Z"
    }
   },
   "id": "429909f88f3e3007"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f4f4c7fcfa40d370"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
